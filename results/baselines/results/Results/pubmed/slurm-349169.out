/home/he.1773/miniconda2/envs/FairGraph
/home/he.1773/miniconda2/envs/FairGraph/bin/python
gpu18
*********baselines pubmed*********
2021-08-04 22:16:46,180 import time, argparse, os, json
2021-08-04 22:16:46,180 set no gpu for use in tensorflow
2021-08-04 22:16:46.295737: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-08-04 22:16:48,273 From /home/he.1773/miniconda2/envs/FairGraph/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
2021-08-04 22:16:48,273 import tensorflow.compat.v1
2021-08-04 22:16:48,293 import numpy, scipy, singledispatch
2021-08-04 22:16:48,675 import sklearn
/home/he.1773/miniconda2/envs/FairGraph/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.
  warnings.warn(msg)
2021-08-04 22:16:49,075 import baseline methods
2021-08-04 22:16:49,075 import networkx, entropy, cosine_similarity
2021-08-04 22:16:49,078 import metrics, preprocess.read_data
2021-08-04 22:16:49,080 get_data function selected
2021-08-04 22:16:51,134 get_data
2021-08-04 22:17:10,369 gae: get fold
2021-08-04 22:17:11,921 From /home/he.1773/miniconda2/envs/FairGraph/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2021-08-04 22:17:12,153 From /home/he.1773/miniconda2/envs/FairGraph/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201: calling weighted_cross_entropy_with_logits (from tensorflow.python.ops.nn_impl) with targets is deprecated and will be removed in a future version.
Instructions for updating:
targets is deprecated, use labels instead
2021-08-04 22:17:12.354325: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-08-04 22:17:12.355975: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-08-04 22:17:17.158167: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2021-08-04 22:17:17.158218: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: gpu18.cluster
2021-08-04 22:17:17.158230: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: gpu18.cluster
2021-08-04 22:17:17.158394: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3
2021-08-04 22:17:17.158444: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3
2021-08-04 22:17:17.158454: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3
2021-08-04 22:17:17.158911: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-08-04 22:17:17.160429: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-08-04 22:17:17.166308: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)
2021-08-04 22:17:17.171994: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2400075000 Hz
2021-08-04 22:26:04,186 gae: run_gae
2021-08-04 22:26:19,518 gae: get fold
2021-08-04 22:26:21.641158: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-08-04 22:35:13,214 gae: run_gae
2021-08-04 22:35:28,585 gae: get fold
2021-08-04 22:35:30.695887: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-08-04 22:44:18,157 gae: run_gae
2021-08-04 22:44:33,748 gae: get fold
2021-08-04 22:44:35.729795: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-08-04 22:53:22,251 gae: run_gae
2021-08-04 22:53:38,194 gae: get fold
2021-08-04 22:53:40.664924: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-08-04 23:02:33,195 gae: run_gae
2021-08-04 23:02:33,243 embed_baselines
2021-08-04 23:02:35,295 get_data
2021-08-04 23:02:54,177 gae: get fold
2021-08-04 23:02:56.318833: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-08-04 23:12:25,483 gae: run_gae
2021-08-04 23:12:41,364 gae: get fold
2021-08-04 23:12:43.673890: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-08-04 23:22:16,571 gae: run_gae
2021-08-04 23:22:32,139 gae: get fold
2021-08-04 23:22:34.420779: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-08-04 23:32:02,266 gae: run_gae
2021-08-04 23:32:18,122 gae: get fold
2021-08-04 23:32:20.259860: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-08-04 23:41:46,629 gae: run_gae
2021-08-04 23:42:02,059 gae: get fold
2021-08-04 23:42:04.709344: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-08-04 23:51:35,407 gae: run_gae
2021-08-04 23:51:35,443 embed_baselines
2021-08-04 23:51:37,490 get_data
2021-08-04 23:51:56,500 fairwalk: initialize
make: Entering directory `/home/he.1773/workplace/FairGraphs/baselines/FairWalk/fast-random-walk'
rm -f *.o walk
make -C unit_tests clean
make[1]: Entering directory `/home/he.1773/workplace/FairGraphs/baselines/FairWalk/fast-random-walk/unit_tests'
rm -f *.o Graph HelperFunctions WeightedGraph
make[1]: Leaving directory `/home/he.1773/workplace/FairGraphs/baselines/FairWalk/fast-random-walk/unit_tests'
make: Leaving directory `/home/he.1773/workplace/FairGraphs/baselines/FairWalk/fast-random-walk'
make: Entering directory `/home/he.1773/workplace/FairGraphs/baselines/FairWalk/fast-random-walk'
g++ -Wall -std=c++11 -g -O2  -c Graph.cpp
g++ -Wall -std=c++11 -g -O2  -c HelperFunctions.cpp
g++ -Wall -std=c++11 -g -O2  -c walk.cpp
g++ -Wall -std=c++11 -g -O2  -c WeightedGraph.cpp
echo "Sources: " Graph.cpp HelperFunctions.cpp walk.cpp WeightedGraph.cpp
Sources:  Graph.cpp HelperFunctions.cpp walk.cpp WeightedGraph.cpp
echo Graph.o HelperFunctions.o walk.o WeightedGraph.o
Graph.o HelperFunctions.o walk.o WeightedGraph.o
g++ -Wall -std=c++11 -g -O2 -o walk Graph.o HelperFunctions.o walk.o WeightedGraph.o
make: Leaving directory `/home/he.1773/workplace/FairGraphs/baselines/FairWalk/fast-random-walk'
2021-08-04 23:52:08,675 collecting all words and their counts
2021-08-04 23:52:08,675 PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2021-08-04 23:52:08,828 PROGRESS: at sentence #10000, processed 800000 words, keeping 10908 word types
2021-08-04 23:52:08,988 PROGRESS: at sentence #20000, processed 1600000 words, keeping 10908 word types
2021-08-04 23:52:09,150 PROGRESS: at sentence #30000, processed 2400000 words, keeping 10908 word types
2021-08-04 23:52:09,312 PROGRESS: at sentence #40000, processed 3200000 words, keeping 10908 word types
2021-08-04 23:52:09,472 PROGRESS: at sentence #50000, processed 4000000 words, keeping 10908 word types
2021-08-04 23:52:09,633 PROGRESS: at sentence #60000, processed 4800000 words, keeping 10908 word types
2021-08-04 23:52:09,796 PROGRESS: at sentence #70000, processed 5600000 words, keeping 10908 word types
2021-08-04 23:52:09,958 PROGRESS: at sentence #80000, processed 6400000 words, keeping 10908 word types
2021-08-04 23:52:10,121 PROGRESS: at sentence #90000, processed 7200000 words, keeping 10908 word types
2021-08-04 23:52:10,283 PROGRESS: at sentence #100000, processed 8000000 words, keeping 10908 word types
2021-08-04 23:52:10,445 PROGRESS: at sentence #110000, processed 8800000 words, keeping 10908 word types
2021-08-04 23:52:10,607 PROGRESS: at sentence #120000, processed 9600000 words, keeping 10908 word types
2021-08-04 23:52:10,768 PROGRESS: at sentence #130000, processed 10400000 words, keeping 10908 word types
2021-08-04 23:52:10,928 PROGRESS: at sentence #140000, processed 11200000 words, keeping 10908 word types
2021-08-04 23:52:11,088 PROGRESS: at sentence #150000, processed 12000000 words, keeping 10908 word types
2021-08-04 23:52:11,247 PROGRESS: at sentence #160000, processed 12800000 words, keeping 10908 word types
2021-08-04 23:52:11,406 PROGRESS: at sentence #170000, processed 13600000 words, keeping 10908 word types
2021-08-04 23:52:11,565 PROGRESS: at sentence #180000, processed 14400000 words, keeping 10908 word types
2021-08-04 23:52:11,723 PROGRESS: at sentence #190000, processed 15200000 words, keeping 10908 word types
2021-08-04 23:52:11,882 PROGRESS: at sentence #200000, processed 16000000 words, keeping 10908 word types
2021-08-04 23:52:12,041 PROGRESS: at sentence #210000, processed 16800000 words, keeping 10908 word types
2021-08-04 23:52:12,170 collected 10908 word types from a corpus of 17452800 raw words and 218160 sentences
2021-08-04 23:52:12,170 Creating a fresh vocabulary
2021-08-04 23:52:12,365 Word2Vec lifecycle event {'msg': 'effective_min_count=10 retains 10908 unique words (100.0%% of original 10908, drops 0)', 'datetime': '2021-08-04T23:52:12.200832', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}
2021-08-04 23:52:12,365 Word2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 17452800 word corpus (100.0%% of original 17452800, drops 0)', 'datetime': '2021-08-04T23:52:12.365886', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}
2021-08-04 23:52:12,414 deleting the raw counts dictionary of 10908 items
2021-08-04 23:52:12,415 sample=0.001 downsamples 2 most-common words
2021-08-04 23:52:12,415 Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 17443360.043728303 word corpus (99.9%% of prior 17452800)', 'datetime': '2021-08-04T23:52:12.415122', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}
2021-08-04 23:52:12,506 estimated required memory for 10908 words and 128 dimensions: 16623792 bytes
2021-08-04 23:52:12,506 resetting layer weights
2021-08-04 23:52:12,513 Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-08-04T23:52:12.513503', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'build_vocab'}
2021-08-04 23:52:12,513 Word2Vec lifecycle event {'msg': 'training model with 28 workers on 10908 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=5 window=10', 'datetime': '2021-08-04T23:52:12.513597', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'train'}
2021-08-04 23:52:13,523 EPOCH 1 - PROGRESS: at 2.75% examples, 479658 words/s, in_qsize 55, out_qsize 0
2021-08-04 23:52:14,526 EPOCH 1 - PROGRESS: at 7.91% examples, 688354 words/s, in_qsize 55, out_qsize 0
2021-08-04 23:52:15,545 EPOCH 1 - PROGRESS: at 13.41% examples, 773767 words/s, in_qsize 56, out_qsize 3
2021-08-04 23:52:16,554 EPOCH 1 - PROGRESS: at 19.54% examples, 845504 words/s, in_qsize 54, out_qsize 1
2021-08-04 23:52:17,562 EPOCH 1 - PROGRESS: at 26.13% examples, 904465 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:52:18,568 EPOCH 1 - PROGRESS: at 32.43% examples, 935988 words/s, in_qsize 54, out_qsize 1
2021-08-04 23:52:19,572 EPOCH 1 - PROGRESS: at 38.90% examples, 962721 words/s, in_qsize 56, out_qsize 1
2021-08-04 23:52:20,578 EPOCH 1 - PROGRESS: at 45.49% examples, 985211 words/s, in_qsize 55, out_qsize 0
2021-08-04 23:52:21,587 EPOCH 1 - PROGRESS: at 52.03% examples, 1001241 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:52:22,610 EPOCH 1 - PROGRESS: at 58.44% examples, 1010588 words/s, in_qsize 55, out_qsize 0
2021-08-04 23:52:23,611 EPOCH 1 - PROGRESS: at 64.75% examples, 1018554 words/s, in_qsize 54, out_qsize 1
2021-08-04 23:52:24,622 EPOCH 1 - PROGRESS: at 71.34% examples, 1028460 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:52:25,629 EPOCH 1 - PROGRESS: at 78.21% examples, 1040938 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:52:26,632 EPOCH 1 - PROGRESS: at 85.03% examples, 1051253 words/s, in_qsize 56, out_qsize 1
2021-08-04 23:52:27,647 EPOCH 1 - PROGRESS: at 91.79% examples, 1058682 words/s, in_qsize 56, out_qsize 1
2021-08-04 23:52:28,591 worker thread finished; awaiting finish of 27 more threads
2021-08-04 23:52:28,604 worker thread finished; awaiting finish of 26 more threads
2021-08-04 23:52:28,609 worker thread finished; awaiting finish of 25 more threads
2021-08-04 23:52:28,615 worker thread finished; awaiting finish of 24 more threads
2021-08-04 23:52:28,619 worker thread finished; awaiting finish of 23 more threads
2021-08-04 23:52:28,623 worker thread finished; awaiting finish of 22 more threads
2021-08-04 23:52:28,629 worker thread finished; awaiting finish of 21 more threads
2021-08-04 23:52:28,631 worker thread finished; awaiting finish of 20 more threads
2021-08-04 23:52:28,636 worker thread finished; awaiting finish of 19 more threads
2021-08-04 23:52:28,639 worker thread finished; awaiting finish of 18 more threads
2021-08-04 23:52:28,643 worker thread finished; awaiting finish of 17 more threads
2021-08-04 23:52:28,653 EPOCH 1 - PROGRESS: at 99.08% examples, 1071529 words/s, in_qsize 16, out_qsize 1
2021-08-04 23:52:28,653 worker thread finished; awaiting finish of 16 more threads
2021-08-04 23:52:28,657 worker thread finished; awaiting finish of 15 more threads
2021-08-04 23:52:28,661 worker thread finished; awaiting finish of 14 more threads
2021-08-04 23:52:28,663 worker thread finished; awaiting finish of 13 more threads
2021-08-04 23:52:28,664 worker thread finished; awaiting finish of 12 more threads
2021-08-04 23:52:28,674 worker thread finished; awaiting finish of 11 more threads
2021-08-04 23:52:28,678 worker thread finished; awaiting finish of 10 more threads
2021-08-04 23:52:28,680 worker thread finished; awaiting finish of 9 more threads
2021-08-04 23:52:28,683 worker thread finished; awaiting finish of 8 more threads
2021-08-04 23:52:28,687 worker thread finished; awaiting finish of 7 more threads
2021-08-04 23:52:28,692 worker thread finished; awaiting finish of 6 more threads
2021-08-04 23:52:28,694 worker thread finished; awaiting finish of 5 more threads
2021-08-04 23:52:28,703 worker thread finished; awaiting finish of 4 more threads
2021-08-04 23:52:28,710 worker thread finished; awaiting finish of 3 more threads
2021-08-04 23:52:28,713 worker thread finished; awaiting finish of 2 more threads
2021-08-04 23:52:28,721 worker thread finished; awaiting finish of 1 more threads
2021-08-04 23:52:28,731 worker thread finished; awaiting finish of 0 more threads
2021-08-04 23:52:28,731 EPOCH - 1 : training on 17452800 raw words (17443487 effective words) took 16.2s, 1076206 effective words/s
2021-08-04 23:52:29,763 EPOCH 2 - PROGRESS: at 5.96% examples, 1015439 words/s, in_qsize 55, out_qsize 1
2021-08-04 23:52:30,772 EPOCH 2 - PROGRESS: at 13.01% examples, 1116289 words/s, in_qsize 55, out_qsize 0
2021-08-04 23:52:31,807 EPOCH 2 - PROGRESS: at 20.00% examples, 1137285 words/s, in_qsize 51, out_qsize 4
2021-08-04 23:52:32,811 EPOCH 2 - PROGRESS: at 27.27% examples, 1168566 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:52:33,851 EPOCH 2 - PROGRESS: at 34.44% examples, 1175281 words/s, in_qsize 55, out_qsize 6
2021-08-04 23:52:34,858 EPOCH 2 - PROGRESS: at 41.83% examples, 1192576 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:52:35,863 EPOCH 2 - PROGRESS: at 49.16% examples, 1203919 words/s, in_qsize 55, out_qsize 0
2021-08-04 23:52:36,878 EPOCH 2 - PROGRESS: at 56.61% examples, 1213323 words/s, in_qsize 55, out_qsize 2
2021-08-04 23:52:37,880 EPOCH 2 - PROGRESS: at 64.12% examples, 1223647 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:52:38,895 EPOCH 2 - PROGRESS: at 71.51% examples, 1228235 words/s, in_qsize 55, out_qsize 2
2021-08-04 23:52:39,896 EPOCH 2 - PROGRESS: at 78.96% examples, 1234496 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:52:40,897 EPOCH 2 - PROGRESS: at 86.40% examples, 1239741 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:52:41,900 EPOCH 2 - PROGRESS: at 93.74% examples, 1242519 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:52:42,551 worker thread finished; awaiting finish of 27 more threads
2021-08-04 23:52:42,557 worker thread finished; awaiting finish of 26 more threads
2021-08-04 23:52:42,558 worker thread finished; awaiting finish of 25 more threads
2021-08-04 23:52:42,562 worker thread finished; awaiting finish of 24 more threads
2021-08-04 23:52:42,569 worker thread finished; awaiting finish of 23 more threads
2021-08-04 23:52:42,572 worker thread finished; awaiting finish of 22 more threads
2021-08-04 23:52:42,577 worker thread finished; awaiting finish of 21 more threads
2021-08-04 23:52:42,580 worker thread finished; awaiting finish of 20 more threads
2021-08-04 23:52:42,589 worker thread finished; awaiting finish of 19 more threads
2021-08-04 23:52:42,590 worker thread finished; awaiting finish of 18 more threads
2021-08-04 23:52:42,592 worker thread finished; awaiting finish of 17 more threads
2021-08-04 23:52:42,594 worker thread finished; awaiting finish of 16 more threads
2021-08-04 23:52:42,609 worker thread finished; awaiting finish of 15 more threads
2021-08-04 23:52:42,615 worker thread finished; awaiting finish of 14 more threads
2021-08-04 23:52:42,617 worker thread finished; awaiting finish of 13 more threads
2021-08-04 23:52:42,635 worker thread finished; awaiting finish of 12 more threads
2021-08-04 23:52:42,642 worker thread finished; awaiting finish of 11 more threads
2021-08-04 23:52:42,643 worker thread finished; awaiting finish of 10 more threads
2021-08-04 23:52:42,645 worker thread finished; awaiting finish of 9 more threads
2021-08-04 23:52:42,648 worker thread finished; awaiting finish of 8 more threads
2021-08-04 23:52:42,653 worker thread finished; awaiting finish of 7 more threads
2021-08-04 23:52:42,657 worker thread finished; awaiting finish of 6 more threads
2021-08-04 23:52:42,662 worker thread finished; awaiting finish of 5 more threads
2021-08-04 23:52:42,665 worker thread finished; awaiting finish of 4 more threads
2021-08-04 23:52:42,669 worker thread finished; awaiting finish of 3 more threads
2021-08-04 23:52:42,674 worker thread finished; awaiting finish of 2 more threads
2021-08-04 23:52:42,679 worker thread finished; awaiting finish of 1 more threads
2021-08-04 23:52:42,683 worker thread finished; awaiting finish of 0 more threads
2021-08-04 23:52:42,683 EPOCH - 2 : training on 17452800 raw words (17443473 effective words) took 13.9s, 1251049 effective words/s
2021-08-04 23:52:43,703 EPOCH 3 - PROGRESS: at 5.44% examples, 939240 words/s, in_qsize 55, out_qsize 1
2021-08-04 23:52:44,713 EPOCH 3 - PROGRESS: at 12.55% examples, 1083928 words/s, in_qsize 56, out_qsize 3
2021-08-04 23:52:45,717 EPOCH 3 - PROGRESS: at 20.00% examples, 1153114 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:52:46,721 EPOCH 3 - PROGRESS: at 27.45% examples, 1188254 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:52:47,745 EPOCH 3 - PROGRESS: at 35.30% examples, 1218435 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:52:48,750 EPOCH 3 - PROGRESS: at 42.69% examples, 1229132 words/s, in_qsize 56, out_qsize 3
2021-08-04 23:52:49,756 EPOCH 3 - PROGRESS: at 50.31% examples, 1242265 words/s, in_qsize 56, out_qsize 3
2021-08-04 23:52:50,762 EPOCH 3 - PROGRESS: at 58.21% examples, 1258313 words/s, in_qsize 55, out_qsize 0
2021-08-04 23:52:51,783 EPOCH 3 - PROGRESS: at 65.61% examples, 1258799 words/s, in_qsize 55, out_qsize 6
2021-08-04 23:52:52,791 EPOCH 3 - PROGRESS: at 73.57% examples, 1270709 words/s, in_qsize 54, out_qsize 2
2021-08-04 23:52:53,796 EPOCH 3 - PROGRESS: at 81.25% examples, 1276331 words/s, in_qsize 54, out_qsize 4
2021-08-04 23:52:54,796 EPOCH 3 - PROGRESS: at 89.21% examples, 1285660 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:52:55,830 EPOCH 3 - PROGRESS: at 96.89% examples, 1286426 words/s, in_qsize 51, out_qsize 4
2021-08-04 23:52:55,982 worker thread finished; awaiting finish of 27 more threads
2021-08-04 23:52:56,001 worker thread finished; awaiting finish of 26 more threads
2021-08-04 23:52:56,002 worker thread finished; awaiting finish of 25 more threads
2021-08-04 23:52:56,021 worker thread finished; awaiting finish of 24 more threads
2021-08-04 23:52:56,027 worker thread finished; awaiting finish of 23 more threads
2021-08-04 23:52:56,028 worker thread finished; awaiting finish of 22 more threads
2021-08-04 23:52:56,031 worker thread finished; awaiting finish of 21 more threads
2021-08-04 23:52:56,032 worker thread finished; awaiting finish of 20 more threads
2021-08-04 23:52:56,036 worker thread finished; awaiting finish of 19 more threads
2021-08-04 23:52:56,039 worker thread finished; awaiting finish of 18 more threads
2021-08-04 23:52:56,050 worker thread finished; awaiting finish of 17 more threads
2021-08-04 23:52:56,055 worker thread finished; awaiting finish of 16 more threads
2021-08-04 23:52:56,057 worker thread finished; awaiting finish of 15 more threads
2021-08-04 23:52:56,061 worker thread finished; awaiting finish of 14 more threads
2021-08-04 23:52:56,063 worker thread finished; awaiting finish of 13 more threads
2021-08-04 23:52:56,071 worker thread finished; awaiting finish of 12 more threads
2021-08-04 23:52:56,073 worker thread finished; awaiting finish of 11 more threads
2021-08-04 23:52:56,090 worker thread finished; awaiting finish of 10 more threads
2021-08-04 23:52:56,091 worker thread finished; awaiting finish of 9 more threads
2021-08-04 23:52:56,094 worker thread finished; awaiting finish of 8 more threads
2021-08-04 23:52:56,099 worker thread finished; awaiting finish of 7 more threads
2021-08-04 23:52:56,101 worker thread finished; awaiting finish of 6 more threads
2021-08-04 23:52:56,107 worker thread finished; awaiting finish of 5 more threads
2021-08-04 23:52:56,110 worker thread finished; awaiting finish of 4 more threads
2021-08-04 23:52:56,112 worker thread finished; awaiting finish of 3 more threads
2021-08-04 23:52:56,116 worker thread finished; awaiting finish of 2 more threads
2021-08-04 23:52:56,120 worker thread finished; awaiting finish of 1 more threads
2021-08-04 23:52:56,123 worker thread finished; awaiting finish of 0 more threads
2021-08-04 23:52:56,123 EPOCH - 3 : training on 17452800 raw words (17443217 effective words) took 13.4s, 1298701 effective words/s
2021-08-04 23:52:57,137 EPOCH 4 - PROGRESS: at 6.59% examples, 1147500 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:52:58,137 EPOCH 4 - PROGRESS: at 14.15% examples, 1233230 words/s, in_qsize 52, out_qsize 3
2021-08-04 23:52:59,139 EPOCH 4 - PROGRESS: at 21.94% examples, 1274291 words/s, in_qsize 55, out_qsize 0
2021-08-04 23:53:00,141 EPOCH 4 - PROGRESS: at 29.22% examples, 1272529 words/s, in_qsize 55, out_qsize 1
2021-08-04 23:53:01,160 EPOCH 4 - PROGRESS: at 36.73% examples, 1274990 words/s, in_qsize 55, out_qsize 0
2021-08-04 23:53:02,184 EPOCH 4 - PROGRESS: at 44.41% examples, 1280581 words/s, in_qsize 55, out_qsize 3
2021-08-04 23:53:03,196 EPOCH 4 - PROGRESS: at 52.03% examples, 1285296 words/s, in_qsize 56, out_qsize 1
2021-08-04 23:53:04,201 EPOCH 4 - PROGRESS: at 59.99% examples, 1297618 words/s, in_qsize 56, out_qsize 2
2021-08-04 23:53:05,201 EPOCH 4 - PROGRESS: at 67.95% examples, 1307477 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:53:06,214 EPOCH 4 - PROGRESS: at 75.52% examples, 1307007 words/s, in_qsize 55, out_qsize 6
2021-08-04 23:53:07,237 EPOCH 4 - PROGRESS: at 83.83% examples, 1317022 words/s, in_qsize 56, out_qsize 2
2021-08-04 23:53:08,238 EPOCH 4 - PROGRESS: at 91.91% examples, 1324554 words/s, in_qsize 55, out_qsize 0
2021-08-04 23:53:09,061 worker thread finished; awaiting finish of 27 more threads
2021-08-04 23:53:09,063 worker thread finished; awaiting finish of 26 more threads
2021-08-04 23:53:09,064 worker thread finished; awaiting finish of 25 more threads
2021-08-04 23:53:09,076 worker thread finished; awaiting finish of 24 more threads
2021-08-04 23:53:09,091 worker thread finished; awaiting finish of 23 more threads
2021-08-04 23:53:09,094 worker thread finished; awaiting finish of 22 more threads
2021-08-04 23:53:09,103 worker thread finished; awaiting finish of 21 more threads
2021-08-04 23:53:09,103 worker thread finished; awaiting finish of 20 more threads
2021-08-04 23:53:09,103 worker thread finished; awaiting finish of 19 more threads
2021-08-04 23:53:09,107 worker thread finished; awaiting finish of 18 more threads
2021-08-04 23:53:09,116 worker thread finished; awaiting finish of 17 more threads
2021-08-04 23:53:09,117 worker thread finished; awaiting finish of 16 more threads
2021-08-04 23:53:09,120 worker thread finished; awaiting finish of 15 more threads
2021-08-04 23:53:09,126 worker thread finished; awaiting finish of 14 more threads
2021-08-04 23:53:09,130 worker thread finished; awaiting finish of 13 more threads
2021-08-04 23:53:09,136 worker thread finished; awaiting finish of 12 more threads
2021-08-04 23:53:09,144 worker thread finished; awaiting finish of 11 more threads
2021-08-04 23:53:09,164 worker thread finished; awaiting finish of 10 more threads
2021-08-04 23:53:09,165 worker thread finished; awaiting finish of 9 more threads
2021-08-04 23:53:09,168 worker thread finished; awaiting finish of 8 more threads
2021-08-04 23:53:09,173 worker thread finished; awaiting finish of 7 more threads
2021-08-04 23:53:09,179 worker thread finished; awaiting finish of 6 more threads
2021-08-04 23:53:09,183 worker thread finished; awaiting finish of 5 more threads
2021-08-04 23:53:09,184 worker thread finished; awaiting finish of 4 more threads
2021-08-04 23:53:09,185 worker thread finished; awaiting finish of 3 more threads
2021-08-04 23:53:09,190 worker thread finished; awaiting finish of 2 more threads
2021-08-04 23:53:09,196 worker thread finished; awaiting finish of 1 more threads
2021-08-04 23:53:09,199 worker thread finished; awaiting finish of 0 more threads
2021-08-04 23:53:09,199 EPOCH - 4 : training on 17452800 raw words (17443399 effective words) took 13.1s, 1335169 effective words/s
2021-08-04 23:53:10,229 EPOCH 5 - PROGRESS: at 6.19% examples, 1057634 words/s, in_qsize 54, out_qsize 1
2021-08-04 23:53:11,243 EPOCH 5 - PROGRESS: at 13.81% examples, 1183862 words/s, in_qsize 54, out_qsize 1
2021-08-04 23:53:12,244 EPOCH 5 - PROGRESS: at 21.60% examples, 1241282 words/s, in_qsize 55, out_qsize 0
2021-08-04 23:53:13,262 EPOCH 5 - PROGRESS: at 29.05% examples, 1250060 words/s, in_qsize 55, out_qsize 2
2021-08-04 23:53:14,297 EPOCH 5 - PROGRESS: at 36.78% examples, 1260964 words/s, in_qsize 56, out_qsize 2
2021-08-04 23:53:15,304 EPOCH 5 - PROGRESS: at 43.95% examples, 1257604 words/s, in_qsize 52, out_qsize 0
2021-08-04 23:53:16,311 EPOCH 5 - PROGRESS: at 51.05% examples, 1253746 words/s, in_qsize 55, out_qsize 3
2021-08-04 23:53:17,329 EPOCH 5 - PROGRESS: at 58.27% examples, 1251694 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:53:18,338 EPOCH 5 - PROGRESS: at 65.49% examples, 1251243 words/s, in_qsize 55, out_qsize 2
2021-08-04 23:53:19,364 EPOCH 5 - PROGRESS: at 72.65% examples, 1247877 words/s, in_qsize 55, out_qsize 4
2021-08-04 23:53:20,370 EPOCH 5 - PROGRESS: at 80.10% examples, 1251751 words/s, in_qsize 55, out_qsize 0
2021-08-04 23:53:21,392 EPOCH 5 - PROGRESS: at 87.32% examples, 1250306 words/s, in_qsize 55, out_qsize 0
2021-08-04 23:53:22,391 EPOCH 5 - PROGRESS: at 94.14% examples, 1245663 words/s, in_qsize 56, out_qsize 2
2021-08-04 23:53:22,964 worker thread finished; awaiting finish of 27 more threads
2021-08-04 23:53:22,979 worker thread finished; awaiting finish of 26 more threads
2021-08-04 23:53:22,981 worker thread finished; awaiting finish of 25 more threads
2021-08-04 23:53:22,987 worker thread finished; awaiting finish of 24 more threads
2021-08-04 23:53:23,002 worker thread finished; awaiting finish of 23 more threads
2021-08-04 23:53:23,003 worker thread finished; awaiting finish of 22 more threads
2021-08-04 23:53:23,012 worker thread finished; awaiting finish of 21 more threads
2021-08-04 23:53:23,018 worker thread finished; awaiting finish of 20 more threads
2021-08-04 23:53:23,020 worker thread finished; awaiting finish of 19 more threads
2021-08-04 23:53:23,031 worker thread finished; awaiting finish of 18 more threads
2021-08-04 23:53:23,038 worker thread finished; awaiting finish of 17 more threads
2021-08-04 23:53:23,041 worker thread finished; awaiting finish of 16 more threads
2021-08-04 23:53:23,059 worker thread finished; awaiting finish of 15 more threads
2021-08-04 23:53:23,060 worker thread finished; awaiting finish of 14 more threads
2021-08-04 23:53:23,063 worker thread finished; awaiting finish of 13 more threads
2021-08-04 23:53:23,066 worker thread finished; awaiting finish of 12 more threads
2021-08-04 23:53:23,072 worker thread finished; awaiting finish of 11 more threads
2021-08-04 23:53:23,075 worker thread finished; awaiting finish of 10 more threads
2021-08-04 23:53:23,080 worker thread finished; awaiting finish of 9 more threads
2021-08-04 23:53:23,082 worker thread finished; awaiting finish of 8 more threads
2021-08-04 23:53:23,088 worker thread finished; awaiting finish of 7 more threads
2021-08-04 23:53:23,090 worker thread finished; awaiting finish of 6 more threads
2021-08-04 23:53:23,096 worker thread finished; awaiting finish of 5 more threads
2021-08-04 23:53:23,099 worker thread finished; awaiting finish of 4 more threads
2021-08-04 23:53:23,104 worker thread finished; awaiting finish of 3 more threads
2021-08-04 23:53:23,108 worker thread finished; awaiting finish of 2 more threads
2021-08-04 23:53:23,111 worker thread finished; awaiting finish of 1 more threads
2021-08-04 23:53:23,111 worker thread finished; awaiting finish of 0 more threads
2021-08-04 23:53:23,111 EPOCH - 5 : training on 17452800 raw words (17443325 effective words) took 13.9s, 1254618 effective words/s
2021-08-04 23:53:23,112 Word2Vec lifecycle event {'msg': 'training on 87264000 raw words (87216901 effective words) took 70.6s, 1235396 effective words/s', 'datetime': '2021-08-04T23:53:23.112046', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'train'}
2021-08-04 23:53:23,112 Word2Vec lifecycle event {'params': 'Word2Vec(vocab=10908, vector_size=128, alpha=0.025)', 'datetime': '2021-08-04T23:53:23.112228', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'created'}
2021-08-04 23:53:24,047 fairwalk: embed
2021-08-04 23:54:45,566 fairwalk: result
2021-08-04 23:55:01,144 fairwalk: initialize
make: Entering directory `/home/he.1773/workplace/FairGraphs/baselines/FairWalk/fast-random-walk'
rm -f *.o walk
make -C unit_tests clean
make[1]: Entering directory `/home/he.1773/workplace/FairGraphs/baselines/FairWalk/fast-random-walk/unit_tests'
rm -f *.o Graph HelperFunctions WeightedGraph
make[1]: Leaving directory `/home/he.1773/workplace/FairGraphs/baselines/FairWalk/fast-random-walk/unit_tests'
make: Leaving directory `/home/he.1773/workplace/FairGraphs/baselines/FairWalk/fast-random-walk'
make: Entering directory `/home/he.1773/workplace/FairGraphs/baselines/FairWalk/fast-random-walk'
g++ -Wall -std=c++11 -g -O2  -c Graph.cpp
g++ -Wall -std=c++11 -g -O2  -c HelperFunctions.cpp
g++ -Wall -std=c++11 -g -O2  -c walk.cpp
g++ -Wall -std=c++11 -g -O2  -c WeightedGraph.cpp
echo "Sources: " Graph.cpp HelperFunctions.cpp walk.cpp WeightedGraph.cpp
Sources:  Graph.cpp HelperFunctions.cpp walk.cpp WeightedGraph.cpp
echo Graph.o HelperFunctions.o walk.o WeightedGraph.o
Graph.o HelperFunctions.o walk.o WeightedGraph.o
g++ -Wall -std=c++11 -g -O2 -o walk Graph.o HelperFunctions.o walk.o WeightedGraph.o
make: Leaving directory `/home/he.1773/workplace/FairGraphs/baselines/FairWalk/fast-random-walk'
2021-08-04 23:55:13,921 collecting all words and their counts
2021-08-04 23:55:13,922 PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2021-08-04 23:55:14,070 PROGRESS: at sentence #10000, processed 800000 words, keeping 10957 word types
2021-08-04 23:55:14,222 PROGRESS: at sentence #20000, processed 1600000 words, keeping 10958 word types
2021-08-04 23:55:14,376 PROGRESS: at sentence #30000, processed 2400000 words, keeping 10958 word types
2021-08-04 23:55:14,532 PROGRESS: at sentence #40000, processed 3200000 words, keeping 10958 word types
2021-08-04 23:55:14,689 PROGRESS: at sentence #50000, processed 4000000 words, keeping 10958 word types
2021-08-04 23:55:14,847 PROGRESS: at sentence #60000, processed 4800000 words, keeping 10958 word types
2021-08-04 23:55:15,005 PROGRESS: at sentence #70000, processed 5600000 words, keeping 10958 word types
2021-08-04 23:55:15,162 PROGRESS: at sentence #80000, processed 6400000 words, keeping 10958 word types
2021-08-04 23:55:15,321 PROGRESS: at sentence #90000, processed 7200000 words, keeping 10958 word types
2021-08-04 23:55:15,480 PROGRESS: at sentence #100000, processed 8000000 words, keeping 10958 word types
2021-08-04 23:55:15,638 PROGRESS: at sentence #110000, processed 8800000 words, keeping 10958 word types
2021-08-04 23:55:15,796 PROGRESS: at sentence #120000, processed 9600000 words, keeping 10958 word types
2021-08-04 23:55:15,953 PROGRESS: at sentence #130000, processed 10400000 words, keeping 10958 word types
2021-08-04 23:55:16,108 PROGRESS: at sentence #140000, processed 11200000 words, keeping 10958 word types
2021-08-04 23:55:16,263 PROGRESS: at sentence #150000, processed 12000000 words, keeping 10958 word types
2021-08-04 23:55:16,418 PROGRESS: at sentence #160000, processed 12800000 words, keeping 10958 word types
2021-08-04 23:55:16,575 PROGRESS: at sentence #170000, processed 13600000 words, keeping 10958 word types
2021-08-04 23:55:16,731 PROGRESS: at sentence #180000, processed 14400000 words, keeping 10958 word types
2021-08-04 23:55:16,887 PROGRESS: at sentence #190000, processed 15200000 words, keeping 10958 word types
2021-08-04 23:55:17,043 PROGRESS: at sentence #200000, processed 16000000 words, keeping 10958 word types
2021-08-04 23:55:17,198 PROGRESS: at sentence #210000, processed 16800000 words, keeping 10958 word types
2021-08-04 23:55:17,340 collected 10958 word types from a corpus of 17532800 raw words and 219160 sentences
2021-08-04 23:55:17,340 Creating a fresh vocabulary
2021-08-04 23:55:17,370 Word2Vec lifecycle event {'msg': 'effective_min_count=10 retains 10958 unique words (100.0%% of original 10958, drops 0)', 'datetime': '2021-08-04T23:55:17.370278', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}
2021-08-04 23:55:17,370 Word2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 17532800 word corpus (100.0%% of original 17532800, drops 0)', 'datetime': '2021-08-04T23:55:17.370387', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}
2021-08-04 23:55:17,416 deleting the raw counts dictionary of 10958 items
2021-08-04 23:55:17,416 sample=0.001 downsamples 1 most-common words
2021-08-04 23:55:17,416 Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 17528691.83089254 word corpus (100.0%% of prior 17532800)', 'datetime': '2021-08-04T23:55:17.416915', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}
2021-08-04 23:55:17,509 estimated required memory for 10958 words and 128 dimensions: 16699992 bytes
2021-08-04 23:55:17,510 resetting layer weights
2021-08-04 23:55:17,518 Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-08-04T23:55:17.518109', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'build_vocab'}
2021-08-04 23:55:17,518 Word2Vec lifecycle event {'msg': 'training model with 28 workers on 10958 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=5 window=10', 'datetime': '2021-08-04T23:55:17.518208', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'train'}
2021-08-04 23:55:18,564 EPOCH 1 - PROGRESS: at 3.94% examples, 682340 words/s, in_qsize 55, out_qsize 0
2021-08-04 23:55:19,567 EPOCH 1 - PROGRESS: at 9.87% examples, 858508 words/s, in_qsize 56, out_qsize 3
2021-08-04 23:55:20,598 EPOCH 1 - PROGRESS: at 16.60% examples, 955190 words/s, in_qsize 53, out_qsize 2
2021-08-04 23:55:21,606 EPOCH 1 - PROGRESS: at 23.38% examples, 1011235 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:55:22,607 EPOCH 1 - PROGRESS: at 31.60% examples, 1095974 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:55:23,608 EPOCH 1 - PROGRESS: at 40.15% examples, 1162577 words/s, in_qsize 54, out_qsize 3
2021-08-04 23:55:24,620 EPOCH 1 - PROGRESS: at 49.68% examples, 1232196 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:55:25,649 EPOCH 1 - PROGRESS: at 58.58% examples, 1268229 words/s, in_qsize 54, out_qsize 2
2021-08-04 23:55:26,674 EPOCH 1 - PROGRESS: at 67.70% examples, 1301085 words/s, in_qsize 56, out_qsize 1
2021-08-04 23:55:27,674 EPOCH 1 - PROGRESS: at 76.43% examples, 1323667 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:55:28,679 EPOCH 1 - PROGRESS: at 85.04% examples, 1339726 words/s, in_qsize 54, out_qsize 1
2021-08-04 23:55:29,685 EPOCH 1 - PROGRESS: at 93.42% examples, 1350078 words/s, in_qsize 55, out_qsize 0
2021-08-04 23:55:30,273 worker thread finished; awaiting finish of 27 more threads
2021-08-04 23:55:30,275 worker thread finished; awaiting finish of 26 more threads
2021-08-04 23:55:30,287 worker thread finished; awaiting finish of 25 more threads
2021-08-04 23:55:30,289 worker thread finished; awaiting finish of 24 more threads
2021-08-04 23:55:30,290 worker thread finished; awaiting finish of 23 more threads
2021-08-04 23:55:30,295 worker thread finished; awaiting finish of 22 more threads
2021-08-04 23:55:30,305 worker thread finished; awaiting finish of 21 more threads
2021-08-04 23:55:30,310 worker thread finished; awaiting finish of 20 more threads
2021-08-04 23:55:30,313 worker thread finished; awaiting finish of 19 more threads
2021-08-04 23:55:30,313 worker thread finished; awaiting finish of 18 more threads
2021-08-04 23:55:30,315 worker thread finished; awaiting finish of 17 more threads
2021-08-04 23:55:30,322 worker thread finished; awaiting finish of 16 more threads
2021-08-04 23:55:30,329 worker thread finished; awaiting finish of 15 more threads
2021-08-04 23:55:30,334 worker thread finished; awaiting finish of 14 more threads
2021-08-04 23:55:30,339 worker thread finished; awaiting finish of 13 more threads
2021-08-04 23:55:30,343 worker thread finished; awaiting finish of 12 more threads
2021-08-04 23:55:30,354 worker thread finished; awaiting finish of 11 more threads
2021-08-04 23:55:30,356 worker thread finished; awaiting finish of 10 more threads
2021-08-04 23:55:30,358 worker thread finished; awaiting finish of 9 more threads
2021-08-04 23:55:30,358 worker thread finished; awaiting finish of 8 more threads
2021-08-04 23:55:30,367 worker thread finished; awaiting finish of 7 more threads
2021-08-04 23:55:30,370 worker thread finished; awaiting finish of 6 more threads
2021-08-04 23:55:30,379 worker thread finished; awaiting finish of 5 more threads
2021-08-04 23:55:30,379 worker thread finished; awaiting finish of 4 more threads
2021-08-04 23:55:30,386 worker thread finished; awaiting finish of 3 more threads
2021-08-04 23:55:30,397 worker thread finished; awaiting finish of 2 more threads
2021-08-04 23:55:30,405 worker thread finished; awaiting finish of 1 more threads
2021-08-04 23:55:30,408 worker thread finished; awaiting finish of 0 more threads
2021-08-04 23:55:30,408 EPOCH - 1 : training on 17532800 raw words (17528686 effective words) took 12.9s, 1363481 effective words/s
2021-08-04 23:55:31,461 EPOCH 2 - PROGRESS: at 6.67% examples, 1121397 words/s, in_qsize 55, out_qsize 11
2021-08-04 23:55:32,461 EPOCH 2 - PROGRESS: at 16.20% examples, 1389470 words/s, in_qsize 55, out_qsize 0
2021-08-04 23:55:33,461 EPOCH 2 - PROGRESS: at 25.27% examples, 1455192 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:55:34,465 EPOCH 2 - PROGRESS: at 34.28% examples, 1484576 words/s, in_qsize 56, out_qsize 3
2021-08-04 23:55:35,506 EPOCH 2 - PROGRESS: at 43.63% examples, 1503193 words/s, in_qsize 52, out_qsize 7
2021-08-04 23:55:36,511 EPOCH 2 - PROGRESS: at 53.27% examples, 1532430 words/s, in_qsize 55, out_qsize 2
2021-08-04 23:55:37,513 EPOCH 2 - PROGRESS: at 62.63% examples, 1547246 words/s, in_qsize 55, out_qsize 3
2021-08-04 23:55:38,513 EPOCH 2 - PROGRESS: at 72.15% examples, 1562353 words/s, in_qsize 55, out_qsize 0
2021-08-04 23:55:39,520 EPOCH 2 - PROGRESS: at 81.62% examples, 1571742 words/s, in_qsize 56, out_qsize 1
2021-08-04 23:55:40,535 EPOCH 2 - PROGRESS: at 91.14% examples, 1579187 words/s, in_qsize 56, out_qsize 1
2021-08-04 23:55:41,285 worker thread finished; awaiting finish of 27 more threads
2021-08-04 23:55:41,289 worker thread finished; awaiting finish of 26 more threads
2021-08-04 23:55:41,294 worker thread finished; awaiting finish of 25 more threads
2021-08-04 23:55:41,299 worker thread finished; awaiting finish of 24 more threads
2021-08-04 23:55:41,306 worker thread finished; awaiting finish of 23 more threads
2021-08-04 23:55:41,311 worker thread finished; awaiting finish of 22 more threads
2021-08-04 23:55:41,320 worker thread finished; awaiting finish of 21 more threads
2021-08-04 23:55:41,321 worker thread finished; awaiting finish of 20 more threads
2021-08-04 23:55:41,326 worker thread finished; awaiting finish of 19 more threads
2021-08-04 23:55:41,326 worker thread finished; awaiting finish of 18 more threads
2021-08-04 23:55:41,331 worker thread finished; awaiting finish of 17 more threads
2021-08-04 23:55:41,334 worker thread finished; awaiting finish of 16 more threads
2021-08-04 23:55:41,338 worker thread finished; awaiting finish of 15 more threads
2021-08-04 23:55:41,338 worker thread finished; awaiting finish of 14 more threads
2021-08-04 23:55:41,349 worker thread finished; awaiting finish of 13 more threads
2021-08-04 23:55:41,359 worker thread finished; awaiting finish of 12 more threads
2021-08-04 23:55:41,363 worker thread finished; awaiting finish of 11 more threads
2021-08-04 23:55:41,374 worker thread finished; awaiting finish of 10 more threads
2021-08-04 23:55:41,376 worker thread finished; awaiting finish of 9 more threads
2021-08-04 23:55:41,379 worker thread finished; awaiting finish of 8 more threads
2021-08-04 23:55:41,382 worker thread finished; awaiting finish of 7 more threads
2021-08-04 23:55:41,389 worker thread finished; awaiting finish of 6 more threads
2021-08-04 23:55:41,403 worker thread finished; awaiting finish of 5 more threads
2021-08-04 23:55:41,403 worker thread finished; awaiting finish of 4 more threads
2021-08-04 23:55:41,408 worker thread finished; awaiting finish of 3 more threads
2021-08-04 23:55:41,412 worker thread finished; awaiting finish of 2 more threads
2021-08-04 23:55:41,417 worker thread finished; awaiting finish of 1 more threads
2021-08-04 23:55:41,420 worker thread finished; awaiting finish of 0 more threads
2021-08-04 23:55:41,420 EPOCH - 2 : training on 17532800 raw words (17528705 effective words) took 11.0s, 1593204 effective words/s
2021-08-04 23:55:42,433 EPOCH 3 - PROGRESS: at 7.53% examples, 1313735 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:55:43,439 EPOCH 3 - PROGRESS: at 17.05% examples, 1487403 words/s, in_qsize 55, out_qsize 1
2021-08-04 23:55:44,449 EPOCH 3 - PROGRESS: at 26.52% examples, 1539453 words/s, in_qsize 53, out_qsize 0
2021-08-04 23:55:45,462 EPOCH 3 - PROGRESS: at 36.16% examples, 1571723 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:55:46,472 EPOCH 3 - PROGRESS: at 45.80% examples, 1591978 words/s, in_qsize 54, out_qsize 1
2021-08-04 23:55:47,473 EPOCH 3 - PROGRESS: at 54.98% examples, 1594454 words/s, in_qsize 54, out_qsize 1
2021-08-04 23:55:48,491 EPOCH 3 - PROGRESS: at 64.39% examples, 1598334 words/s, in_qsize 52, out_qsize 3
2021-08-04 23:55:49,495 EPOCH 3 - PROGRESS: at 73.58% examples, 1598850 words/s, in_qsize 56, out_qsize 5
2021-08-04 23:55:50,503 EPOCH 3 - PROGRESS: at 83.16% examples, 1606460 words/s, in_qsize 55, out_qsize 0
2021-08-04 23:55:51,505 EPOCH 3 - PROGRESS: at 92.46% examples, 1608359 words/s, in_qsize 52, out_qsize 1
2021-08-04 23:55:52,148 worker thread finished; awaiting finish of 27 more threads
2021-08-04 23:55:52,153 worker thread finished; awaiting finish of 26 more threads
2021-08-04 23:55:52,158 worker thread finished; awaiting finish of 25 more threads
2021-08-04 23:55:52,162 worker thread finished; awaiting finish of 24 more threads
2021-08-04 23:55:52,169 worker thread finished; awaiting finish of 23 more threads
2021-08-04 23:55:52,175 worker thread finished; awaiting finish of 22 more threads
2021-08-04 23:55:52,176 worker thread finished; awaiting finish of 21 more threads
2021-08-04 23:55:52,182 worker thread finished; awaiting finish of 20 more threads
2021-08-04 23:55:52,182 worker thread finished; awaiting finish of 19 more threads
2021-08-04 23:55:52,189 worker thread finished; awaiting finish of 18 more threads
2021-08-04 23:55:52,196 worker thread finished; awaiting finish of 17 more threads
2021-08-04 23:55:52,199 worker thread finished; awaiting finish of 16 more threads
2021-08-04 23:55:52,212 worker thread finished; awaiting finish of 15 more threads
2021-08-04 23:55:52,213 worker thread finished; awaiting finish of 14 more threads
2021-08-04 23:55:52,214 worker thread finished; awaiting finish of 13 more threads
2021-08-04 23:55:52,219 worker thread finished; awaiting finish of 12 more threads
2021-08-04 23:55:52,223 worker thread finished; awaiting finish of 11 more threads
2021-08-04 23:55:52,227 worker thread finished; awaiting finish of 10 more threads
2021-08-04 23:55:52,232 worker thread finished; awaiting finish of 9 more threads
2021-08-04 23:55:52,232 worker thread finished; awaiting finish of 8 more threads
2021-08-04 23:55:52,247 worker thread finished; awaiting finish of 7 more threads
2021-08-04 23:55:52,257 worker thread finished; awaiting finish of 6 more threads
2021-08-04 23:55:52,259 worker thread finished; awaiting finish of 5 more threads
2021-08-04 23:55:52,264 worker thread finished; awaiting finish of 4 more threads
2021-08-04 23:55:52,264 worker thread finished; awaiting finish of 3 more threads
2021-08-04 23:55:52,271 worker thread finished; awaiting finish of 2 more threads
2021-08-04 23:55:52,273 worker thread finished; awaiting finish of 1 more threads
2021-08-04 23:55:52,274 worker thread finished; awaiting finish of 0 more threads
2021-08-04 23:55:52,274 EPOCH - 3 : training on 17532800 raw words (17528685 effective words) took 10.8s, 1616194 effective words/s
2021-08-04 23:55:53,315 EPOCH 4 - PROGRESS: at 7.41% examples, 1262370 words/s, in_qsize 51, out_qsize 7
2021-08-04 23:55:54,353 EPOCH 4 - PROGRESS: at 17.05% examples, 1444403 words/s, in_qsize 56, out_qsize 11
2021-08-04 23:55:55,358 EPOCH 4 - PROGRESS: at 27.09% examples, 1544555 words/s, in_qsize 56, out_qsize 1
2021-08-04 23:55:56,359 EPOCH 4 - PROGRESS: at 36.56% examples, 1572231 words/s, in_qsize 55, out_qsize 2
2021-08-04 23:55:57,374 EPOCH 4 - PROGRESS: at 46.14% examples, 1588844 words/s, in_qsize 53, out_qsize 2
2021-08-04 23:55:58,386 EPOCH 4 - PROGRESS: at 55.78% examples, 1602142 words/s, in_qsize 52, out_qsize 3
2021-08-04 23:55:59,402 EPOCH 4 - PROGRESS: at 65.19% examples, 1605716 words/s, in_qsize 54, out_qsize 4
2021-08-04 23:56:00,419 EPOCH 4 - PROGRESS: at 74.83% examples, 1612151 words/s, in_qsize 56, out_qsize 4
2021-08-04 23:56:01,421 EPOCH 4 - PROGRESS: at 84.36% examples, 1618216 words/s, in_qsize 54, out_qsize 0
2021-08-04 23:56:02,430 EPOCH 4 - PROGRESS: at 93.65% examples, 1617897 words/s, in_qsize 55, out_qsize 2
2021-08-04 23:56:02,937 worker thread finished; awaiting finish of 27 more threads
2021-08-04 23:56:02,937 worker thread finished; awaiting finish of 26 more threads
2021-08-04 23:56:02,947 worker thread finished; awaiting finish of 25 more threads
2021-08-04 23:56:02,950 worker thread finished; awaiting finish of 24 more threads
2021-08-04 23:56:02,957 worker thread finished; awaiting finish of 23 more threads
2021-08-04 23:56:02,961 worker thread finished; awaiting finish of 22 more threads
2021-08-04 23:56:02,971 worker thread finished; awaiting finish of 21 more threads
2021-08-04 23:56:02,972 worker thread finished; awaiting finish of 20 more threads
2021-08-04 23:56:02,975 worker thread finished; awaiting finish of 19 more threads
2021-08-04 23:56:02,986 worker thread finished; awaiting finish of 18 more threads
2021-08-04 23:56:02,986 worker thread finished; awaiting finish of 17 more threads
2021-08-04 23:56:02,988 worker thread finished; awaiting finish of 16 more threads
2021-08-04 23:56:02,996 worker thread finished; awaiting finish of 15 more threads
2021-08-04 23:56:02,997 worker thread finished; awaiting finish of 14 more threads
2021-08-04 23:56:03,006 worker thread finished; awaiting finish of 13 more threads
2021-08-04 23:56:03,014 worker thread finished; awaiting finish of 12 more threads
2021-08-04 23:56:03,018 worker thread finished; awaiting finish of 11 more threads
2021-08-04 23:56:03,026 worker thread finished; awaiting finish of 10 more threads
2021-08-04 23:56:03,028 worker thread finished; awaiting finish of 9 more threads
2021-08-04 23:56:03,028 worker thread finished; awaiting finish of 8 more threads
2021-08-04 23:56:03,038 worker thread finished; awaiting finish of 7 more threads
2021-08-04 23:56:03,045 worker thread finished; awaiting finish of 6 more threads
2021-08-04 23:56:03,046 worker thread finished; awaiting finish of 5 more threads
2021-08-04 23:56:03,048 worker thread finished; awaiting finish of 4 more threads
2021-08-04 23:56:03,058 worker thread finished; awaiting finish of 3 more threads
2021-08-04 23:56:03,058 worker thread finished; awaiting finish of 2 more threads
2021-08-04 23:56:03,062 worker thread finished; awaiting finish of 1 more threads
2021-08-04 23:56:03,064 worker thread finished; awaiting finish of 0 more threads
2021-08-04 23:56:03,064 EPOCH - 4 : training on 17532800 raw words (17528668 effective words) took 10.8s, 1625939 effective words/s
2021-08-04 23:56:04,079 EPOCH 5 - PROGRESS: at 7.59% examples, 1321032 words/s, in_qsize 54, out_qsize 1
2021-08-04 23:56:05,083 EPOCH 5 - PROGRESS: at 16.83% examples, 1466976 words/s, in_qsize 54, out_qsize 1
2021-08-04 23:56:06,088 EPOCH 5 - PROGRESS: at 26.41% examples, 1535085 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:56:07,088 EPOCH 5 - PROGRESS: at 35.82% examples, 1563481 words/s, in_qsize 55, out_qsize 0
2021-08-04 23:56:08,103 EPOCH 5 - PROGRESS: at 45.17% examples, 1574025 words/s, in_qsize 56, out_qsize 1
2021-08-04 23:56:09,134 EPOCH 5 - PROGRESS: at 54.81% examples, 1585052 words/s, in_qsize 52, out_qsize 3
2021-08-04 23:56:10,135 EPOCH 5 - PROGRESS: at 64.56% examples, 1602439 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:56:11,140 EPOCH 5 - PROGRESS: at 73.80% examples, 1603547 words/s, in_qsize 55, out_qsize 1
2021-08-04 23:56:12,162 EPOCH 5 - PROGRESS: at 83.16% examples, 1603678 words/s, in_qsize 56, out_qsize 6
2021-08-04 23:56:13,171 EPOCH 5 - PROGRESS: at 92.68% examples, 1608703 words/s, in_qsize 49, out_qsize 5
2021-08-04 23:56:13,749 worker thread finished; awaiting finish of 27 more threads
2021-08-04 23:56:13,749 worker thread finished; awaiting finish of 26 more threads
2021-08-04 23:56:13,759 worker thread finished; awaiting finish of 25 more threads
2021-08-04 23:56:13,766 worker thread finished; awaiting finish of 24 more threads
2021-08-04 23:56:13,777 worker thread finished; awaiting finish of 23 more threads
2021-08-04 23:56:13,784 worker thread finished; awaiting finish of 22 more threads
2021-08-04 23:56:13,784 worker thread finished; awaiting finish of 21 more threads
2021-08-04 23:56:13,788 worker thread finished; awaiting finish of 20 more threads
2021-08-04 23:56:13,802 worker thread finished; awaiting finish of 19 more threads
2021-08-04 23:56:13,803 worker thread finished; awaiting finish of 18 more threads
2021-08-04 23:56:13,806 worker thread finished; awaiting finish of 17 more threads
2021-08-04 23:56:13,815 worker thread finished; awaiting finish of 16 more threads
2021-08-04 23:56:13,819 worker thread finished; awaiting finish of 15 more threads
2021-08-04 23:56:13,823 worker thread finished; awaiting finish of 14 more threads
2021-08-04 23:56:13,827 worker thread finished; awaiting finish of 13 more threads
2021-08-04 23:56:13,832 worker thread finished; awaiting finish of 12 more threads
2021-08-04 23:56:13,836 worker thread finished; awaiting finish of 11 more threads
2021-08-04 23:56:13,840 worker thread finished; awaiting finish of 10 more threads
2021-08-04 23:56:13,843 worker thread finished; awaiting finish of 9 more threads
2021-08-04 23:56:13,843 worker thread finished; awaiting finish of 8 more threads
2021-08-04 23:56:13,851 worker thread finished; awaiting finish of 7 more threads
2021-08-04 23:56:13,861 worker thread finished; awaiting finish of 6 more threads
2021-08-04 23:56:13,868 worker thread finished; awaiting finish of 5 more threads
2021-08-04 23:56:13,872 worker thread finished; awaiting finish of 4 more threads
2021-08-04 23:56:13,872 worker thread finished; awaiting finish of 3 more threads
2021-08-04 23:56:13,876 worker thread finished; awaiting finish of 2 more threads
2021-08-04 23:56:13,879 worker thread finished; awaiting finish of 1 more threads
2021-08-04 23:56:13,881 worker thread finished; awaiting finish of 0 more threads
2021-08-04 23:56:13,881 EPOCH - 5 : training on 17532800 raw words (17528732 effective words) took 10.8s, 1621659 effective words/s
2021-08-04 23:56:13,882 Word2Vec lifecycle event {'msg': 'training on 87664000 raw words (87643476 effective words) took 56.4s, 1554964 effective words/s', 'datetime': '2021-08-04T23:56:13.881988', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'train'}
2021-08-04 23:56:13,882 Word2Vec lifecycle event {'params': 'Word2Vec(vocab=10958, vector_size=128, alpha=0.025)', 'datetime': '2021-08-04T23:56:13.882154', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'created'}
2021-08-04 23:56:15,202 fairwalk: embed
2021-08-04 23:57:38,978 fairwalk: result
2021-08-04 23:57:54,703 fairwalk: initialize
make: Entering directory `/home/he.1773/workplace/FairGraphs/baselines/FairWalk/fast-random-walk'
rm -f *.o walk
make -C unit_tests clean
make[1]: Entering directory `/home/he.1773/workplace/FairGraphs/baselines/FairWalk/fast-random-walk/unit_tests'
rm -f *.o Graph HelperFunctions WeightedGraph
make[1]: Leaving directory `/home/he.1773/workplace/FairGraphs/baselines/FairWalk/fast-random-walk/unit_tests'
make: Leaving directory `/home/he.1773/workplace/FairGraphs/baselines/FairWalk/fast-random-walk'
make: Entering directory `/home/he.1773/workplace/FairGraphs/baselines/FairWalk/fast-random-walk'
g++ -Wall -std=c++11 -g -O2  -c Graph.cpp
g++ -Wall -std=c++11 -g -O2  -c HelperFunctions.cpp
g++ -Wall -std=c++11 -g -O2  -c walk.cpp
g++ -Wall -std=c++11 -g -O2  -c WeightedGraph.cpp
echo "Sources: " Graph.cpp HelperFunctions.cpp walk.cpp WeightedGraph.cpp
Sources:  Graph.cpp HelperFunctions.cpp walk.cpp WeightedGraph.cpp
echo Graph.o HelperFunctions.o walk.o WeightedGraph.o
Graph.o HelperFunctions.o walk.o WeightedGraph.o
g++ -Wall -std=c++11 -g -O2 -o walk Graph.o HelperFunctions.o walk.o WeightedGraph.o
make: Leaving directory `/home/he.1773/workplace/FairGraphs/baselines/FairWalk/fast-random-walk'
2021-08-04 23:58:07,456 collecting all words and their counts
2021-08-04 23:58:07,457 PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2021-08-04 23:58:07,616 PROGRESS: at sentence #10000, processed 800000 words, keeping 10886 word types
2021-08-04 23:58:07,780 PROGRESS: at sentence #20000, processed 1600000 words, keeping 10886 word types
2021-08-04 23:58:07,945 PROGRESS: at sentence #30000, processed 2400000 words, keeping 10886 word types
2021-08-04 23:58:08,110 PROGRESS: at sentence #40000, processed 3200000 words, keeping 10886 word types
2021-08-04 23:58:08,275 PROGRESS: at sentence #50000, processed 4000000 words, keeping 10886 word types
2021-08-04 23:58:08,442 PROGRESS: at sentence #60000, processed 4800000 words, keeping 10886 word types
2021-08-04 23:58:08,607 PROGRESS: at sentence #70000, processed 5600000 words, keeping 10886 word types
2021-08-04 23:58:08,776 PROGRESS: at sentence #80000, processed 6400000 words, keeping 10886 word types
2021-08-04 23:58:08,943 PROGRESS: at sentence #90000, processed 7200000 words, keeping 10886 word types
2021-08-04 23:58:09,111 PROGRESS: at sentence #100000, processed 8000000 words, keeping 10886 word types
2021-08-04 23:58:09,280 PROGRESS: at sentence #110000, processed 8800000 words, keeping 10886 word types
2021-08-04 23:58:09,448 PROGRESS: at sentence #120000, processed 9600000 words, keeping 10886 word types
2021-08-04 23:58:09,616 PROGRESS: at sentence #130000, processed 10400000 words, keeping 10886 word types
2021-08-04 23:58:09,786 PROGRESS: at sentence #140000, processed 11200000 words, keeping 10886 word types
2021-08-04 23:58:09,955 PROGRESS: at sentence #150000, processed 12000000 words, keeping 10886 word types
2021-08-04 23:58:10,123 PROGRESS: at sentence #160000, processed 12800000 words, keeping 10886 word types
2021-08-04 23:58:10,291 PROGRESS: at sentence #170000, processed 13600000 words, keeping 10886 word types
2021-08-04 23:58:10,461 PROGRESS: at sentence #180000, processed 14400000 words, keeping 10886 word types
2021-08-04 23:58:10,629 PROGRESS: at sentence #190000, processed 15200000 words, keeping 10886 word types
2021-08-04 23:58:10,797 PROGRESS: at sentence #200000, processed 16000000 words, keeping 10886 word types
2021-08-04 23:58:10,966 PROGRESS: at sentence #210000, processed 16800000 words, keeping 10886 word types
2021-08-04 23:58:11,099 collected 10886 word types from a corpus of 17417600 raw words and 217720 sentences
2021-08-04 23:58:11,099 Creating a fresh vocabulary
2021-08-04 23:58:11,130 Word2Vec lifecycle event {'msg': 'effective_min_count=10 retains 10886 unique words (100.0%% of original 10886, drops 0)', 'datetime': '2021-08-04T23:58:11.130160', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}
2021-08-04 23:58:11,130 Word2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 17417600 word corpus (100.0%% of original 17417600, drops 0)', 'datetime': '2021-08-04T23:58:11.130390', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}
2021-08-04 23:58:11,177 deleting the raw counts dictionary of 10886 items
2021-08-04 23:58:11,177 sample=0.001 downsamples 2 most-common words
2021-08-04 23:58:11,177 Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 17392859.519847833 word corpus (99.9%% of prior 17417600)', 'datetime': '2021-08-04T23:58:11.177497', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}
2021-08-04 23:58:11,269 estimated required memory for 10886 words and 128 dimensions: 16590264 bytes
2021-08-04 23:58:11,269 resetting layer weights
2021-08-04 23:58:11,284 Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-08-04T23:58:11.284973', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'build_vocab'}
2021-08-04 23:58:11,285 Word2Vec lifecycle event {'msg': 'training model with 28 workers on 10886 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=5 window=10', 'datetime': '2021-08-04T23:58:11.285101', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'train'}
2021-08-04 23:58:12,306 EPOCH 1 - PROGRESS: at 3.62% examples, 622561 words/s, in_qsize 54, out_qsize 1
2021-08-04 23:58:13,343 EPOCH 1 - PROGRESS: at 10.05% examples, 853145 words/s, in_qsize 54, out_qsize 1
2021-08-04 23:58:14,362 EPOCH 1 - PROGRESS: at 16.31% examples, 924785 words/s, in_qsize 56, out_qsize 2
2021-08-04 23:58:15,377 EPOCH 1 - PROGRESS: at 22.56% examples, 961492 words/s, in_qsize 54, out_qsize 1
2021-08-04 23:58:16,379 EPOCH 1 - PROGRESS: at 31.23% examples, 1068503 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:58:17,417 EPOCH 1 - PROGRESS: at 39.96% examples, 1135362 words/s, in_qsize 54, out_qsize 4
2021-08-04 23:58:18,422 EPOCH 1 - PROGRESS: at 49.03% examples, 1196546 words/s, in_qsize 56, out_qsize 1
2021-08-04 23:58:19,423 EPOCH 1 - PROGRESS: at 57.87% examples, 1238427 words/s, in_qsize 55, out_qsize 0
2021-08-04 23:58:20,425 EPOCH 1 - PROGRESS: at 66.83% examples, 1273147 words/s, in_qsize 56, out_qsize 2
2021-08-04 23:58:21,430 EPOCH 1 - PROGRESS: at 75.90% examples, 1302553 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:58:22,439 EPOCH 1 - PROGRESS: at 85.03% examples, 1327124 words/s, in_qsize 54, out_qsize 1
2021-08-04 23:58:23,456 EPOCH 1 - PROGRESS: at 94.22% examples, 1347509 words/s, in_qsize 54, out_qsize 1
2021-08-04 23:58:23,899 worker thread finished; awaiting finish of 27 more threads
2021-08-04 23:58:23,908 worker thread finished; awaiting finish of 26 more threads
2021-08-04 23:58:23,909 worker thread finished; awaiting finish of 25 more threads
2021-08-04 23:58:23,924 worker thread finished; awaiting finish of 24 more threads
2021-08-04 23:58:23,924 worker thread finished; awaiting finish of 23 more threads
2021-08-04 23:58:23,932 worker thread finished; awaiting finish of 22 more threads
2021-08-04 23:58:23,940 worker thread finished; awaiting finish of 21 more threads
2021-08-04 23:58:23,946 worker thread finished; awaiting finish of 20 more threads
2021-08-04 23:58:23,946 worker thread finished; awaiting finish of 19 more threads
2021-08-04 23:58:23,950 worker thread finished; awaiting finish of 18 more threads
2021-08-04 23:58:23,953 worker thread finished; awaiting finish of 17 more threads
2021-08-04 23:58:23,970 worker thread finished; awaiting finish of 16 more threads
2021-08-04 23:58:23,971 worker thread finished; awaiting finish of 15 more threads
2021-08-04 23:58:23,977 worker thread finished; awaiting finish of 14 more threads
2021-08-04 23:58:23,983 worker thread finished; awaiting finish of 13 more threads
2021-08-04 23:58:23,991 worker thread finished; awaiting finish of 12 more threads
2021-08-04 23:58:23,998 worker thread finished; awaiting finish of 11 more threads
2021-08-04 23:58:24,003 worker thread finished; awaiting finish of 10 more threads
2021-08-04 23:58:24,010 worker thread finished; awaiting finish of 9 more threads
2021-08-04 23:58:24,013 worker thread finished; awaiting finish of 8 more threads
2021-08-04 23:58:24,014 worker thread finished; awaiting finish of 7 more threads
2021-08-04 23:58:24,015 worker thread finished; awaiting finish of 6 more threads
2021-08-04 23:58:24,023 worker thread finished; awaiting finish of 5 more threads
2021-08-04 23:58:24,025 worker thread finished; awaiting finish of 4 more threads
2021-08-04 23:58:24,027 worker thread finished; awaiting finish of 3 more threads
2021-08-04 23:58:24,034 worker thread finished; awaiting finish of 2 more threads
2021-08-04 23:58:24,037 worker thread finished; awaiting finish of 1 more threads
2021-08-04 23:58:24,041 worker thread finished; awaiting finish of 0 more threads
2021-08-04 23:58:24,041 EPOCH - 1 : training on 17417600 raw words (17392843 effective words) took 12.7s, 1364572 effective words/s
2021-08-04 23:58:25,060 EPOCH 2 - PROGRESS: at 7.75% examples, 1335192 words/s, in_qsize 55, out_qsize 1
2021-08-04 23:58:26,060 EPOCH 2 - PROGRESS: at 17.28% examples, 1495038 words/s, in_qsize 54, out_qsize 1
2021-08-04 23:58:27,088 EPOCH 2 - PROGRESS: at 27.04% examples, 1548324 words/s, in_qsize 55, out_qsize 3
2021-08-04 23:58:28,096 EPOCH 2 - PROGRESS: at 36.86% examples, 1584492 words/s, in_qsize 53, out_qsize 2
2021-08-04 23:58:29,099 EPOCH 2 - PROGRESS: at 46.45% examples, 1599922 words/s, in_qsize 54, out_qsize 1
2021-08-04 23:58:30,109 EPOCH 2 - PROGRESS: at 56.15% examples, 1611833 words/s, in_qsize 52, out_qsize 2
2021-08-04 23:58:31,110 EPOCH 2 - PROGRESS: at 65.85% examples, 1622377 words/s, in_qsize 54, out_qsize 1
2021-08-04 23:58:32,126 EPOCH 2 - PROGRESS: at 75.56% examples, 1627235 words/s, in_qsize 54, out_qsize 1
2021-08-04 23:58:33,133 EPOCH 2 - PROGRESS: at 85.32% examples, 1633635 words/s, in_qsize 54, out_qsize 1
2021-08-04 23:58:34,168 EPOCH 2 - PROGRESS: at 94.90% examples, 1631428 words/s, in_qsize 53, out_qsize 2
2021-08-04 23:58:34,518 worker thread finished; awaiting finish of 27 more threads
2021-08-04 23:58:34,520 worker thread finished; awaiting finish of 26 more threads
2021-08-04 23:58:34,525 worker thread finished; awaiting finish of 25 more threads
2021-08-04 23:58:34,532 worker thread finished; awaiting finish of 24 more threads
2021-08-04 23:58:34,537 worker thread finished; awaiting finish of 23 more threads
2021-08-04 23:58:34,548 worker thread finished; awaiting finish of 22 more threads
2021-08-04 23:58:34,555 worker thread finished; awaiting finish of 21 more threads
2021-08-04 23:58:34,560 worker thread finished; awaiting finish of 20 more threads
2021-08-04 23:58:34,564 worker thread finished; awaiting finish of 19 more threads
2021-08-04 23:58:34,568 worker thread finished; awaiting finish of 18 more threads
2021-08-04 23:58:34,577 worker thread finished; awaiting finish of 17 more threads
2021-08-04 23:58:34,580 worker thread finished; awaiting finish of 16 more threads
2021-08-04 23:58:34,580 worker thread finished; awaiting finish of 15 more threads
2021-08-04 23:58:34,586 worker thread finished; awaiting finish of 14 more threads
2021-08-04 23:58:34,590 worker thread finished; awaiting finish of 13 more threads
2021-08-04 23:58:34,598 worker thread finished; awaiting finish of 12 more threads
2021-08-04 23:58:34,599 worker thread finished; awaiting finish of 11 more threads
2021-08-04 23:58:34,606 worker thread finished; awaiting finish of 10 more threads
2021-08-04 23:58:34,610 worker thread finished; awaiting finish of 9 more threads
2021-08-04 23:58:34,616 worker thread finished; awaiting finish of 8 more threads
2021-08-04 23:58:34,618 worker thread finished; awaiting finish of 7 more threads
2021-08-04 23:58:34,622 worker thread finished; awaiting finish of 6 more threads
2021-08-04 23:58:34,626 worker thread finished; awaiting finish of 5 more threads
2021-08-04 23:58:34,630 worker thread finished; awaiting finish of 4 more threads
2021-08-04 23:58:34,635 worker thread finished; awaiting finish of 3 more threads
2021-08-04 23:58:34,640 worker thread finished; awaiting finish of 2 more threads
2021-08-04 23:58:34,644 worker thread finished; awaiting finish of 1 more threads
2021-08-04 23:58:34,648 worker thread finished; awaiting finish of 0 more threads
2021-08-04 23:58:34,648 EPOCH - 2 : training on 17417600 raw words (17392966 effective words) took 10.6s, 1641151 effective words/s
2021-08-04 23:58:35,660 EPOCH 3 - PROGRESS: at 7.87% examples, 1364053 words/s, in_qsize 56, out_qsize 1
2021-08-04 23:58:36,664 EPOCH 3 - PROGRESS: at 17.63% examples, 1527563 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:58:37,666 EPOCH 3 - PROGRESS: at 27.27% examples, 1576110 words/s, in_qsize 55, out_qsize 0
2021-08-04 23:58:38,679 EPOCH 3 - PROGRESS: at 36.80% examples, 1591609 words/s, in_qsize 56, out_qsize 1
2021-08-04 23:58:39,680 EPOCH 3 - PROGRESS: at 46.45% examples, 1608400 words/s, in_qsize 56, out_qsize 1
2021-08-04 23:58:40,681 EPOCH 3 - PROGRESS: at 56.26% examples, 1624488 words/s, in_qsize 54, out_qsize 0
2021-08-04 23:58:41,686 EPOCH 3 - PROGRESS: at 65.80% examples, 1628015 words/s, in_qsize 56, out_qsize 2
2021-08-04 23:58:42,714 EPOCH 3 - PROGRESS: at 75.61% examples, 1632214 words/s, in_qsize 56, out_qsize 3
2021-08-04 23:58:43,737 EPOCH 3 - PROGRESS: at 85.37% examples, 1635360 words/s, in_qsize 54, out_qsize 6
2021-08-04 23:58:44,754 EPOCH 3 - PROGRESS: at 95.48% examples, 1644649 words/s, in_qsize 56, out_qsize 2
2021-08-04 23:58:45,037 worker thread finished; awaiting finish of 27 more threads
2021-08-04 23:58:45,043 worker thread finished; awaiting finish of 26 more threads
2021-08-04 23:58:45,052 worker thread finished; awaiting finish of 25 more threads
2021-08-04 23:58:45,053 worker thread finished; awaiting finish of 24 more threads
2021-08-04 23:58:45,065 worker thread finished; awaiting finish of 23 more threads
2021-08-04 23:58:45,079 worker thread finished; awaiting finish of 22 more threads
2021-08-04 23:58:45,083 worker thread finished; awaiting finish of 21 more threads
2021-08-04 23:58:45,085 worker thread finished; awaiting finish of 20 more threads
2021-08-04 23:58:45,089 worker thread finished; awaiting finish of 19 more threads
2021-08-04 23:58:45,095 worker thread finished; awaiting finish of 18 more threads
2021-08-04 23:58:45,100 worker thread finished; awaiting finish of 17 more threads
2021-08-04 23:58:45,105 worker thread finished; awaiting finish of 16 more threads
2021-08-04 23:58:45,110 worker thread finished; awaiting finish of 15 more threads
2021-08-04 23:58:45,114 worker thread finished; awaiting finish of 14 more threads
2021-08-04 23:58:45,119 worker thread finished; awaiting finish of 13 more threads
2021-08-04 23:58:45,123 worker thread finished; awaiting finish of 12 more threads
2021-08-04 23:58:45,127 worker thread finished; awaiting finish of 11 more threads
2021-08-04 23:58:45,139 worker thread finished; awaiting finish of 10 more threads
2021-08-04 23:58:45,141 worker thread finished; awaiting finish of 9 more threads
2021-08-04 23:58:45,149 worker thread finished; awaiting finish of 8 more threads
2021-08-04 23:58:45,151 worker thread finished; awaiting finish of 7 more threads
2021-08-04 23:58:45,151 worker thread finished; awaiting finish of 6 more threads
2021-08-04 23:58:45,159 worker thread finished; awaiting finish of 5 more threads
2021-08-04 23:58:45,161 worker thread finished; awaiting finish of 4 more threads
2021-08-04 23:58:45,168 worker thread finished; awaiting finish of 3 more threads
2021-08-04 23:58:45,172 worker thread finished; awaiting finish of 2 more threads
2021-08-04 23:58:45,175 worker thread finished; awaiting finish of 1 more threads
2021-08-04 23:58:45,178 worker thread finished; awaiting finish of 0 more threads
2021-08-04 23:58:45,178 EPOCH - 3 : training on 17417600 raw words (17392555 effective words) took 10.5s, 1653077 effective words/s
2021-08-04 23:58:46,203 EPOCH 4 - PROGRESS: at 7.75% examples, 1332186 words/s, in_qsize 55, out_qsize 0
2021-08-04 23:58:47,222 EPOCH 4 - PROGRESS: at 16.94% examples, 1450604 words/s, in_qsize 46, out_qsize 4
2021-08-04 23:58:48,229 EPOCH 4 - PROGRESS: at 26.58% examples, 1522903 words/s, in_qsize 51, out_qsize 4
2021-08-04 23:58:49,237 EPOCH 4 - PROGRESS: at 36.34% examples, 1562324 words/s, in_qsize 54, out_qsize 2
2021-08-04 23:58:50,240 EPOCH 4 - PROGRESS: at 46.05% examples, 1586018 words/s, in_qsize 53, out_qsize 1
2021-08-04 23:58:51,254 EPOCH 4 - PROGRESS: at 55.40% examples, 1589364 words/s, in_qsize 56, out_qsize 5
2021-08-04 23:58:52,261 EPOCH 4 - PROGRESS: at 65.39% examples, 1609122 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:58:53,266 EPOCH 4 - PROGRESS: at 74.92% examples, 1613803 words/s, in_qsize 55, out_qsize 0
2021-08-04 23:58:54,272 EPOCH 4 - PROGRESS: at 84.45% examples, 1617570 words/s, in_qsize 55, out_qsize 1
2021-08-04 23:58:55,283 EPOCH 4 - PROGRESS: at 94.10% examples, 1621763 words/s, in_qsize 56, out_qsize 0
2021-08-04 23:58:55,730 worker thread finished; awaiting finish of 27 more threads
2021-08-04 23:58:55,731 worker thread finished; awaiting finish of 26 more threads
2021-08-04 23:58:55,738 worker thread finished; awaiting finish of 25 more threads
2021-08-04 23:58:55,745 worker thread finished; awaiting finish of 24 more threads
2021-08-04 23:58:55,752 worker thread finished; awaiting finish of 23 more threads
2021-08-04 23:58:55,759 worker thread finished; awaiting finish of 22 more threads
2021-08-04 23:58:55,766 worker thread finished; awaiting finish of 21 more threads
2021-08-04 23:58:55,768 worker thread finished; awaiting finish of 20 more threads
2021-08-04 23:58:55,771 worker thread finished; awaiting finish of 19 more threads
2021-08-04 23:58:55,781 worker thread finished; awaiting finish of 18 more threads
2021-08-04 23:58:55,786 worker thread finished; awaiting finish of 17 more threads
2021-08-04 23:58:55,788 worker thread finished; awaiting finish of 16 more threads
2021-08-04 23:58:55,788 worker thread finished; awaiting finish of 15 more threads
2021-08-04 23:58:55,799 worker thread finished; awaiting finish of 14 more threads
2021-08-04 23:58:55,802 worker thread finished; awaiting finish of 13 more threads
2021-08-04 23:58:55,809 worker thread finished; awaiting finish of 12 more threads
2021-08-04 23:58:55,819 worker thread finished; awaiting finish of 11 more threads
2021-08-04 23:58:55,832 worker thread finished; awaiting finish of 10 more threads
2021-08-04 23:58:55,835 worker thread finished; awaiting finish of 9 more threads
2021-08-04 23:58:55,838 worker thread finished; awaiting finish of 8 more threads
2021-08-04 23:58:55,841 worker thread finished; awaiting finish of 7 more threads
2021-08-04 23:58:55,842 worker thread finished; awaiting finish of 6 more threads
2021-08-04 23:58:55,847 worker thread finished; awaiting finish of 5 more threads
2021-08-04 23:58:55,855 worker thread finished; awaiting finish of 4 more threads
2021-08-04 23:58:55,856 worker thread finished; awaiting finish of 3 more threads
2021-08-04 23:58:55,858 worker thread finished; awaiting finish of 2 more threads
2021-08-04 23:58:55,860 worker thread finished; awaiting finish of 1 more threads
2021-08-04 23:58:55,863 worker thread finished; awaiting finish of 0 more threads
2021-08-04 23:58:55,863 EPOCH - 4 : training on 17417600 raw words (17393065 effective words) took 10.7s, 1629747 effective words/s
2021-08-04 23:58:56,873 EPOCH 5 - PROGRESS: at 7.64% examples, 1326770 words/s, in_qsize 51, out_qsize 0
2021-08-04 23:58:57,880 EPOCH 5 - PROGRESS: at 17.28% examples, 1496395 words/s, in_qsize 55, out_qsize 0
2021-08-04 23:58:58,890 EPOCH 5 - PROGRESS: at 26.47% examples, 1525241 words/s, in_qsize 56, out_qsize 3
2021-08-04 23:58:59,909 EPOCH 5 - PROGRESS: at 36.11% examples, 1555573 words/s, in_qsize 55, out_qsize 3
2021-08-04 23:59:00,916 EPOCH 5 - PROGRESS: at 45.64% examples, 1573675 words/s, in_qsize 56, out_qsize 2
2021-08-04 23:59:01,929 EPOCH 5 - PROGRESS: at 55.06% examples, 1580910 words/s, in_qsize 51, out_qsize 4
2021-08-04 23:59:02,967 EPOCH 5 - PROGRESS: at 64.76% examples, 1587514 words/s, in_qsize 54, out_qsize 3
2021-08-04 23:59:03,981 EPOCH 5 - PROGRESS: at 74.41% examples, 1596276 words/s, in_qsize 53, out_qsize 2
2021-08-04 23:59:04,994 EPOCH 5 - PROGRESS: at 83.65% examples, 1594854 words/s, in_qsize 56, out_qsize 8
2021-08-04 23:59:06,015 EPOCH 5 - PROGRESS: at 93.47% examples, 1602717 words/s, in_qsize 54, out_qsize 1
2021-08-04 23:59:06,529 worker thread finished; awaiting finish of 27 more threads
2021-08-04 23:59:06,543 worker thread finished; awaiting finish of 26 more threads
2021-08-04 23:59:06,549 worker thread finished; awaiting finish of 25 more threads
2021-08-04 23:59:06,553 worker thread finished; awaiting finish of 24 more threads
2021-08-04 23:59:06,557 worker thread finished; awaiting finish of 23 more threads
2021-08-04 23:59:06,573 worker thread finished; awaiting finish of 22 more threads
2021-08-04 23:59:06,582 worker thread finished; awaiting finish of 21 more threads
2021-08-04 23:59:06,582 worker thread finished; awaiting finish of 20 more threads
2021-08-04 23:59:06,587 worker thread finished; awaiting finish of 19 more threads
2021-08-04 23:59:06,602 worker thread finished; awaiting finish of 18 more threads
2021-08-04 23:59:06,603 worker thread finished; awaiting finish of 17 more threads
2021-08-04 23:59:06,603 worker thread finished; awaiting finish of 16 more threads
2021-08-04 23:59:06,609 worker thread finished; awaiting finish of 15 more threads
2021-08-04 23:59:06,614 worker thread finished; awaiting finish of 14 more threads
2021-08-04 23:59:06,616 worker thread finished; awaiting finish of 13 more threads
2021-08-04 23:59:06,625 worker thread finished; awaiting finish of 12 more threads
2021-08-04 23:59:06,626 worker thread finished; awaiting finish of 11 more threads
2021-08-04 23:59:06,633 worker thread finished; awaiting finish of 10 more threads
2021-08-04 23:59:06,637 worker thread finished; awaiting finish of 9 more threads
2021-08-04 23:59:06,644 worker thread finished; awaiting finish of 8 more threads
2021-08-04 23:59:06,645 worker thread finished; awaiting finish of 7 more threads
2021-08-04 23:59:06,646 worker thread finished; awaiting finish of 6 more threads
2021-08-04 23:59:06,653 worker thread finished; awaiting finish of 5 more threads
2021-08-04 23:59:06,654 worker thread finished; awaiting finish of 4 more threads
2021-08-04 23:59:06,657 worker thread finished; awaiting finish of 3 more threads
2021-08-04 23:59:06,659 worker thread finished; awaiting finish of 2 more threads
2021-08-04 23:59:06,665 worker thread finished; awaiting finish of 1 more threads
2021-08-04 23:59:06,668 worker thread finished; awaiting finish of 0 more threads
2021-08-04 23:59:06,668 EPOCH - 5 : training on 17417600 raw words (17392689 effective words) took 10.8s, 1610941 effective words/s
2021-08-04 23:59:06,668 Word2Vec lifecycle event {'msg': 'training on 87088000 raw words (86964118 effective words) took 55.4s, 1570213 effective words/s', 'datetime': '2021-08-04T23:59:06.668874', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'train'}
2021-08-04 23:59:06,669 Word2Vec lifecycle event {'params': 'Word2Vec(vocab=10886, vector_size=128, alpha=0.025)', 'datetime': '2021-08-04T23:59:06.669019', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'created'}
2021-08-04 23:59:07,689 fairwalk: embed
2021-08-05 00:00:29,567 fairwalk: result
2021-08-05 00:00:45,545 fairwalk: initialize
make: Entering directory `/home/he.1773/workplace/FairGraphs/baselines/FairWalk/fast-random-walk'
rm -f *.o walk
make -C unit_tests clean
make[1]: Entering directory `/home/he.1773/workplace/FairGraphs/baselines/FairWalk/fast-random-walk/unit_tests'
rm -f *.o Graph HelperFunctions WeightedGraph
make[1]: Leaving directory `/home/he.1773/workplace/FairGraphs/baselines/FairWalk/fast-random-walk/unit_tests'
make: Leaving directory `/home/he.1773/workplace/FairGraphs/baselines/FairWalk/fast-random-walk'
make: Entering directory `/home/he.1773/workplace/FairGraphs/baselines/FairWalk/fast-random-walk'
g++ -Wall -std=c++11 -g -O2  -c Graph.cpp
g++ -Wall -std=c++11 -g -O2  -c HelperFunctions.cpp
g++ -Wall -std=c++11 -g -O2  -c walk.cpp
g++ -Wall -std=c++11 -g -O2  -c WeightedGraph.cpp
echo "Sources: " Graph.cpp HelperFunctions.cpp walk.cpp WeightedGraph.cpp
Sources:  Graph.cpp HelperFunctions.cpp walk.cpp WeightedGraph.cpp
echo Graph.o HelperFunctions.o walk.o WeightedGraph.o
Graph.o HelperFunctions.o walk.o WeightedGraph.o
g++ -Wall -std=c++11 -g -O2 -o walk Graph.o HelperFunctions.o walk.o WeightedGraph.o
make: Leaving directory `/home/he.1773/workplace/FairGraphs/baselines/FairWalk/fast-random-walk'
2021-08-05 00:00:58,749 collecting all words and their counts
2021-08-05 00:00:58,749 PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2021-08-05 00:00:58,897 PROGRESS: at sentence #10000, processed 800000 words, keeping 10892 word types
2021-08-05 00:00:59,049 PROGRESS: at sentence #20000, processed 1600000 words, keeping 10892 word types
2021-08-05 00:00:59,210 PROGRESS: at sentence #30000, processed 2400000 words, keeping 10892 word types
2021-08-05 00:00:59,369 PROGRESS: at sentence #40000, processed 3200000 words, keeping 10892 word types
2021-08-05 00:00:59,528 PROGRESS: at sentence #50000, processed 4000000 words, keeping 10892 word types
2021-08-05 00:00:59,687 PROGRESS: at sentence #60000, processed 4800000 words, keeping 10892 word types
2021-08-05 00:00:59,846 PROGRESS: at sentence #70000, processed 5600000 words, keeping 10892 word types
2021-08-05 00:01:00,005 PROGRESS: at sentence #80000, processed 6400000 words, keeping 10892 word types
2021-08-05 00:01:00,165 PROGRESS: at sentence #90000, processed 7200000 words, keeping 10892 word types
2021-08-05 00:01:00,325 PROGRESS: at sentence #100000, processed 8000000 words, keeping 10892 word types
2021-08-05 00:01:00,484 PROGRESS: at sentence #110000, processed 8800000 words, keeping 10892 word types
2021-08-05 00:01:00,643 PROGRESS: at sentence #120000, processed 9600000 words, keeping 10892 word types
2021-08-05 00:01:00,803 PROGRESS: at sentence #130000, processed 10400000 words, keeping 10892 word types
2021-08-05 00:01:00,963 PROGRESS: at sentence #140000, processed 11200000 words, keeping 10892 word types
2021-08-05 00:01:01,123 PROGRESS: at sentence #150000, processed 12000000 words, keeping 10892 word types
2021-08-05 00:01:01,282 PROGRESS: at sentence #160000, processed 12800000 words, keeping 10892 word types
2021-08-05 00:01:01,441 PROGRESS: at sentence #170000, processed 13600000 words, keeping 10892 word types
2021-08-05 00:01:01,601 PROGRESS: at sentence #180000, processed 14400000 words, keeping 10892 word types
2021-08-05 00:01:01,765 PROGRESS: at sentence #190000, processed 15200000 words, keeping 10892 word types
2021-08-05 00:01:01,929 PROGRESS: at sentence #200000, processed 16000000 words, keeping 10892 word types
2021-08-05 00:01:02,088 PROGRESS: at sentence #210000, processed 16800000 words, keeping 10892 word types
2021-08-05 00:01:02,212 collected 10892 word types from a corpus of 17427200 raw words and 217840 sentences
2021-08-05 00:01:02,212 Creating a fresh vocabulary
2021-08-05 00:01:02,242 Word2Vec lifecycle event {'msg': 'effective_min_count=10 retains 10892 unique words (100.0%% of original 10892, drops 0)', 'datetime': '2021-08-05T00:01:02.242624', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}
2021-08-05 00:01:02,242 Word2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 17427200 word corpus (100.0%% of original 17427200, drops 0)', 'datetime': '2021-08-05T00:01:02.242740', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}
2021-08-05 00:01:02,288 deleting the raw counts dictionary of 10892 items
2021-08-05 00:01:02,288 sample=0.001 downsamples 1 most-common words
2021-08-05 00:01:02,289 Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 17418037.766928837 word corpus (99.9%% of prior 17427200)', 'datetime': '2021-08-05T00:01:02.289041', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}
2021-08-05 00:01:02,380 estimated required memory for 10892 words and 128 dimensions: 16599408 bytes
2021-08-05 00:01:02,380 resetting layer weights
2021-08-05 00:01:02,388 Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-08-05T00:01:02.388453', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'build_vocab'}
2021-08-05 00:01:02,388 Word2Vec lifecycle event {'msg': 'training model with 28 workers on 10892 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=5 window=10', 'datetime': '2021-08-05T00:01:02.388548', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'train'}
2021-08-05 00:01:03,411 EPOCH 1 - PROGRESS: at 5.16% examples, 887568 words/s, in_qsize 55, out_qsize 6
2021-08-05 00:01:04,415 EPOCH 1 - PROGRESS: at 13.20% examples, 1139147 words/s, in_qsize 56, out_qsize 3
2021-08-05 00:01:05,418 EPOCH 1 - PROGRESS: at 21.80% examples, 1257269 words/s, in_qsize 55, out_qsize 0
2021-08-05 00:01:06,423 EPOCH 1 - PROGRESS: at 30.47% examples, 1318397 words/s, in_qsize 55, out_qsize 0
2021-08-05 00:01:07,431 EPOCH 1 - PROGRESS: at 39.77% examples, 1376067 words/s, in_qsize 55, out_qsize 0
2021-08-05 00:01:08,438 EPOCH 1 - PROGRESS: at 49.58% examples, 1429603 words/s, in_qsize 54, out_qsize 1
2021-08-05 00:01:09,443 EPOCH 1 - PROGRESS: at 58.82% examples, 1454086 words/s, in_qsize 54, out_qsize 1
2021-08-05 00:01:10,453 EPOCH 1 - PROGRESS: at 68.34% examples, 1477696 words/s, in_qsize 56, out_qsize 5
2021-08-05 00:01:11,453 EPOCH 1 - PROGRESS: at 78.04% examples, 1501010 words/s, in_qsize 56, out_qsize 0
2021-08-05 00:01:12,469 EPOCH 1 - PROGRESS: at 87.91% examples, 1520274 words/s, in_qsize 55, out_qsize 0
2021-08-05 00:01:13,471 EPOCH 1 - PROGRESS: at 97.61% examples, 1535258 words/s, in_qsize 42, out_qsize 0
2021-08-05 00:01:13,565 worker thread finished; awaiting finish of 27 more threads
2021-08-05 00:01:13,576 worker thread finished; awaiting finish of 26 more threads
2021-08-05 00:01:13,580 worker thread finished; awaiting finish of 25 more threads
2021-08-05 00:01:13,591 worker thread finished; awaiting finish of 24 more threads
2021-08-05 00:01:13,593 worker thread finished; awaiting finish of 23 more threads
2021-08-05 00:01:13,605 worker thread finished; awaiting finish of 22 more threads
2021-08-05 00:01:13,609 worker thread finished; awaiting finish of 21 more threads
2021-08-05 00:01:13,612 worker thread finished; awaiting finish of 20 more threads
2021-08-05 00:01:13,612 worker thread finished; awaiting finish of 19 more threads
2021-08-05 00:01:13,618 worker thread finished; awaiting finish of 18 more threads
2021-08-05 00:01:13,624 worker thread finished; awaiting finish of 17 more threads
2021-08-05 00:01:13,628 worker thread finished; awaiting finish of 16 more threads
2021-08-05 00:01:13,633 worker thread finished; awaiting finish of 15 more threads
2021-08-05 00:01:13,635 worker thread finished; awaiting finish of 14 more threads
2021-08-05 00:01:13,636 worker thread finished; awaiting finish of 13 more threads
2021-08-05 00:01:13,646 worker thread finished; awaiting finish of 12 more threads
2021-08-05 00:01:13,646 worker thread finished; awaiting finish of 11 more threads
2021-08-05 00:01:13,649 worker thread finished; awaiting finish of 10 more threads
2021-08-05 00:01:13,652 worker thread finished; awaiting finish of 9 more threads
2021-08-05 00:01:13,658 worker thread finished; awaiting finish of 8 more threads
2021-08-05 00:01:13,659 worker thread finished; awaiting finish of 7 more threads
2021-08-05 00:01:13,662 worker thread finished; awaiting finish of 6 more threads
2021-08-05 00:01:13,667 worker thread finished; awaiting finish of 5 more threads
2021-08-05 00:01:13,677 worker thread finished; awaiting finish of 4 more threads
2021-08-05 00:01:13,677 worker thread finished; awaiting finish of 3 more threads
2021-08-05 00:01:13,688 worker thread finished; awaiting finish of 2 more threads
2021-08-05 00:01:13,688 worker thread finished; awaiting finish of 1 more threads
2021-08-05 00:01:13,693 worker thread finished; awaiting finish of 0 more threads
2021-08-05 00:01:13,693 EPOCH - 1 : training on 17427200 raw words (17418021 effective words) took 11.3s, 1542029 effective words/s
2021-08-05 00:01:14,710 EPOCH 2 - PROGRESS: at 8.15% examples, 1410281 words/s, in_qsize 54, out_qsize 1
2021-08-05 00:01:15,721 EPOCH 2 - PROGRESS: at 17.90% examples, 1544385 words/s, in_qsize 54, out_qsize 1
2021-08-05 00:01:16,724 EPOCH 2 - PROGRESS: at 27.60% examples, 1590501 words/s, in_qsize 56, out_qsize 1
2021-08-05 00:01:17,732 EPOCH 2 - PROGRESS: at 37.24% examples, 1609666 words/s, in_qsize 53, out_qsize 2
2021-08-05 00:01:18,737 EPOCH 2 - PROGRESS: at 46.94% examples, 1623930 words/s, in_qsize 55, out_qsize 1
2021-08-05 00:01:19,744 EPOCH 2 - PROGRESS: at 56.29% examples, 1623278 words/s, in_qsize 55, out_qsize 2
2021-08-05 00:01:20,747 EPOCH 2 - PROGRESS: at 65.93% examples, 1630061 words/s, in_qsize 55, out_qsize 0
2021-08-05 00:01:21,773 EPOCH 2 - PROGRESS: at 75.34% examples, 1625988 words/s, in_qsize 56, out_qsize 3
2021-08-05 00:01:22,776 EPOCH 2 - PROGRESS: at 85.04% examples, 1632446 words/s, in_qsize 54, out_qsize 1
2021-08-05 00:01:23,787 EPOCH 2 - PROGRESS: at 94.68% examples, 1635280 words/s, in_qsize 56, out_qsize 3
2021-08-05 00:01:24,164 worker thread finished; awaiting finish of 27 more threads
2021-08-05 00:01:24,166 worker thread finished; awaiting finish of 26 more threads
2021-08-05 00:01:24,173 worker thread finished; awaiting finish of 25 more threads
2021-08-05 00:01:24,175 worker thread finished; awaiting finish of 24 more threads
2021-08-05 00:01:24,180 worker thread finished; awaiting finish of 23 more threads
2021-08-05 00:01:24,189 worker thread finished; awaiting finish of 22 more threads
2021-08-05 00:01:24,189 worker thread finished; awaiting finish of 21 more threads
2021-08-05 00:01:24,192 worker thread finished; awaiting finish of 20 more threads
2021-08-05 00:01:24,201 worker thread finished; awaiting finish of 19 more threads
2021-08-05 00:01:24,207 worker thread finished; awaiting finish of 18 more threads
2021-08-05 00:01:24,213 worker thread finished; awaiting finish of 17 more threads
2021-08-05 00:01:24,218 worker thread finished; awaiting finish of 16 more threads
2021-08-05 00:01:24,221 worker thread finished; awaiting finish of 15 more threads
2021-08-05 00:01:24,226 worker thread finished; awaiting finish of 14 more threads
2021-08-05 00:01:24,233 worker thread finished; awaiting finish of 13 more threads
2021-08-05 00:01:24,236 worker thread finished; awaiting finish of 12 more threads
2021-08-05 00:01:24,242 worker thread finished; awaiting finish of 11 more threads
2021-08-05 00:01:24,244 worker thread finished; awaiting finish of 10 more threads
2021-08-05 00:01:24,253 worker thread finished; awaiting finish of 9 more threads
2021-08-05 00:01:24,260 worker thread finished; awaiting finish of 8 more threads
2021-08-05 00:01:24,265 worker thread finished; awaiting finish of 7 more threads
2021-08-05 00:01:24,269 worker thread finished; awaiting finish of 6 more threads
2021-08-05 00:01:24,272 worker thread finished; awaiting finish of 5 more threads
2021-08-05 00:01:24,280 worker thread finished; awaiting finish of 4 more threads
2021-08-05 00:01:24,281 worker thread finished; awaiting finish of 3 more threads
2021-08-05 00:01:24,283 worker thread finished; awaiting finish of 2 more threads
2021-08-05 00:01:24,289 worker thread finished; awaiting finish of 1 more threads
2021-08-05 00:01:24,293 worker thread finished; awaiting finish of 0 more threads
2021-08-05 00:01:24,293 EPOCH - 2 : training on 17427200 raw words (17418304 effective words) took 10.6s, 1644533 effective words/s
2021-08-05 00:01:25,319 EPOCH 3 - PROGRESS: at 7.86% examples, 1346445 words/s, in_qsize 56, out_qsize 3
2021-08-05 00:01:26,322 EPOCH 3 - PROGRESS: at 17.44% examples, 1504536 words/s, in_qsize 54, out_qsize 1
2021-08-05 00:01:27,339 EPOCH 3 - PROGRESS: at 27.08% examples, 1553659 words/s, in_qsize 54, out_qsize 1
2021-08-05 00:01:28,342 EPOCH 3 - PROGRESS: at 36.78% examples, 1586179 words/s, in_qsize 55, out_qsize 0
2021-08-05 00:01:29,345 EPOCH 3 - PROGRESS: at 46.25% examples, 1597638 words/s, in_qsize 55, out_qsize 2
2021-08-05 00:01:30,353 EPOCH 3 - PROGRESS: at 55.95% examples, 1610681 words/s, in_qsize 56, out_qsize 2
2021-08-05 00:01:31,354 EPOCH 3 - PROGRESS: at 65.76% examples, 1624262 words/s, in_qsize 56, out_qsize 0
2021-08-05 00:01:32,361 EPOCH 3 - PROGRESS: at 75.34% examples, 1628545 words/s, in_qsize 56, out_qsize 1
2021-08-05 00:01:33,369 EPOCH 3 - PROGRESS: at 84.98% examples, 1632709 words/s, in_qsize 54, out_qsize 1
2021-08-05 00:01:34,371 EPOCH 3 - PROGRESS: at 94.74% examples, 1638873 words/s, in_qsize 56, out_qsize 0
2021-08-05 00:01:34,759 worker thread finished; awaiting finish of 27 more threads
2021-08-05 00:01:34,766 worker thread finished; awaiting finish of 26 more threads
2021-08-05 00:01:34,771 worker thread finished; awaiting finish of 25 more threads
2021-08-05 00:01:34,774 worker thread finished; awaiting finish of 24 more threads
2021-08-05 00:01:34,784 worker thread finished; awaiting finish of 23 more threads
2021-08-05 00:01:34,793 worker thread finished; awaiting finish of 22 more threads
2021-08-05 00:01:34,798 worker thread finished; awaiting finish of 21 more threads
2021-08-05 00:01:34,800 worker thread finished; awaiting finish of 20 more threads
2021-08-05 00:01:34,801 worker thread finished; awaiting finish of 19 more threads
2021-08-05 00:01:34,802 worker thread finished; awaiting finish of 18 more threads
2021-08-05 00:01:34,806 worker thread finished; awaiting finish of 17 more threads
2021-08-05 00:01:34,816 worker thread finished; awaiting finish of 16 more threads
2021-08-05 00:01:34,817 worker thread finished; awaiting finish of 15 more threads
2021-08-05 00:01:34,821 worker thread finished; awaiting finish of 14 more threads
2021-08-05 00:01:34,825 worker thread finished; awaiting finish of 13 more threads
2021-08-05 00:01:34,831 worker thread finished; awaiting finish of 12 more threads
2021-08-05 00:01:34,843 worker thread finished; awaiting finish of 11 more threads
2021-08-05 00:01:34,844 worker thread finished; awaiting finish of 10 more threads
2021-08-05 00:01:34,846 worker thread finished; awaiting finish of 9 more threads
2021-08-05 00:01:34,850 worker thread finished; awaiting finish of 8 more threads
2021-08-05 00:01:34,856 worker thread finished; awaiting finish of 7 more threads
2021-08-05 00:01:34,864 worker thread finished; awaiting finish of 6 more threads
2021-08-05 00:01:34,866 worker thread finished; awaiting finish of 5 more threads
2021-08-05 00:01:34,870 worker thread finished; awaiting finish of 4 more threads
2021-08-05 00:01:34,877 worker thread finished; awaiting finish of 3 more threads
2021-08-05 00:01:34,887 worker thread finished; awaiting finish of 2 more threads
2021-08-05 00:01:34,890 worker thread finished; awaiting finish of 1 more threads
2021-08-05 00:01:34,893 worker thread finished; awaiting finish of 0 more threads
2021-08-05 00:01:34,893 EPOCH - 3 : training on 17427200 raw words (17418143 effective words) took 10.6s, 1644692 effective words/s
2021-08-05 00:01:35,903 EPOCH 4 - PROGRESS: at 7.98% examples, 1388070 words/s, in_qsize 56, out_qsize 0
2021-08-05 00:01:36,905 EPOCH 4 - PROGRESS: at 17.56% examples, 1528070 words/s, in_qsize 56, out_qsize 0
2021-08-05 00:01:37,911 EPOCH 4 - PROGRESS: at 27.20% examples, 1574473 words/s, in_qsize 56, out_qsize 1
2021-08-05 00:01:38,918 EPOCH 4 - PROGRESS: at 36.38% examples, 1577998 words/s, in_qsize 56, out_qsize 11
2021-08-05 00:01:39,934 EPOCH 4 - PROGRESS: at 46.82% examples, 1620748 words/s, in_qsize 55, out_qsize 3
2021-08-05 00:01:40,959 EPOCH 4 - PROGRESS: at 56.64% examples, 1628763 words/s, in_qsize 50, out_qsize 3
2021-08-05 00:01:41,972 EPOCH 4 - PROGRESS: at 66.45% examples, 1637196 words/s, in_qsize 56, out_qsize 3
2021-08-05 00:01:42,997 EPOCH 4 - PROGRESS: at 76.26% examples, 1640973 words/s, in_qsize 56, out_qsize 2
2021-08-05 00:01:44,025 EPOCH 4 - PROGRESS: at 86.19% examples, 1645564 words/s, in_qsize 56, out_qsize 3
2021-08-05 00:01:45,031 EPOCH 4 - PROGRESS: at 96.11% examples, 1652851 words/s, in_qsize 55, out_qsize 0
2021-08-05 00:01:45,258 worker thread finished; awaiting finish of 27 more threads
2021-08-05 00:01:45,261 worker thread finished; awaiting finish of 26 more threads
2021-08-05 00:01:45,287 worker thread finished; awaiting finish of 25 more threads
2021-08-05 00:01:45,290 worker thread finished; awaiting finish of 24 more threads
2021-08-05 00:01:45,294 worker thread finished; awaiting finish of 23 more threads
2021-08-05 00:01:45,304 worker thread finished; awaiting finish of 22 more threads
2021-08-05 00:01:45,306 worker thread finished; awaiting finish of 21 more threads
2021-08-05 00:01:45,312 worker thread finished; awaiting finish of 20 more threads
2021-08-05 00:01:45,314 worker thread finished; awaiting finish of 19 more threads
2021-08-05 00:01:45,322 worker thread finished; awaiting finish of 18 more threads
2021-08-05 00:01:45,329 worker thread finished; awaiting finish of 17 more threads
2021-08-05 00:01:45,335 worker thread finished; awaiting finish of 16 more threads
2021-08-05 00:01:45,340 worker thread finished; awaiting finish of 15 more threads
2021-08-05 00:01:45,341 worker thread finished; awaiting finish of 14 more threads
2021-08-05 00:01:45,347 worker thread finished; awaiting finish of 13 more threads
2021-08-05 00:01:45,349 worker thread finished; awaiting finish of 12 more threads
2021-08-05 00:01:45,351 worker thread finished; awaiting finish of 11 more threads
2021-08-05 00:01:45,362 worker thread finished; awaiting finish of 10 more threads
2021-08-05 00:01:45,366 worker thread finished; awaiting finish of 9 more threads
2021-08-05 00:01:45,368 worker thread finished; awaiting finish of 8 more threads
2021-08-05 00:01:45,371 worker thread finished; awaiting finish of 7 more threads
2021-08-05 00:01:45,373 worker thread finished; awaiting finish of 6 more threads
2021-08-05 00:01:45,383 worker thread finished; awaiting finish of 5 more threads
2021-08-05 00:01:45,385 worker thread finished; awaiting finish of 4 more threads
2021-08-05 00:01:45,390 worker thread finished; awaiting finish of 3 more threads
2021-08-05 00:01:45,392 worker thread finished; awaiting finish of 2 more threads
2021-08-05 00:01:45,397 worker thread finished; awaiting finish of 1 more threads
2021-08-05 00:01:45,399 worker thread finished; awaiting finish of 0 more threads
2021-08-05 00:01:45,399 EPOCH - 4 : training on 17427200 raw words (17418009 effective words) took 10.5s, 1659276 effective words/s
2021-08-05 00:01:46,415 EPOCH 5 - PROGRESS: at 7.69% examples, 1331044 words/s, in_qsize 55, out_qsize 1
2021-08-05 00:01:47,418 EPOCH 5 - PROGRESS: at 17.39% examples, 1506761 words/s, in_qsize 54, out_qsize 1
2021-08-05 00:01:48,420 EPOCH 5 - PROGRESS: at 27.20% examples, 1573114 words/s, in_qsize 52, out_qsize 0
2021-08-05 00:01:49,424 EPOCH 5 - PROGRESS: at 36.90% examples, 1600332 words/s, in_qsize 55, out_qsize 2
2021-08-05 00:01:50,430 EPOCH 5 - PROGRESS: at 46.65% examples, 1618202 words/s, in_qsize 55, out_qsize 2
2021-08-05 00:01:51,471 EPOCH 5 - PROGRESS: at 56.46% examples, 1622230 words/s, in_qsize 52, out_qsize 6
2021-08-05 00:01:52,479 EPOCH 5 - PROGRESS: at 66.51% examples, 1638292 words/s, in_qsize 54, out_qsize 1
2021-08-05 00:01:53,492 EPOCH 5 - PROGRESS: at 76.32% examples, 1644347 words/s, in_qsize 56, out_qsize 1
2021-08-05 00:01:54,512 EPOCH 5 - PROGRESS: at 86.07% examples, 1646901 words/s, in_qsize 55, out_qsize 2
2021-08-05 00:01:55,520 EPOCH 5 - PROGRESS: at 95.71% examples, 1648785 words/s, in_qsize 55, out_qsize 5
2021-08-05 00:01:55,780 worker thread finished; awaiting finish of 27 more threads
2021-08-05 00:01:55,786 worker thread finished; awaiting finish of 26 more threads
2021-08-05 00:01:55,792 worker thread finished; awaiting finish of 25 more threads
2021-08-05 00:01:55,794 worker thread finished; awaiting finish of 24 more threads
2021-08-05 00:01:55,796 worker thread finished; awaiting finish of 23 more threads
2021-08-05 00:01:55,804 worker thread finished; awaiting finish of 22 more threads
2021-08-05 00:01:55,806 worker thread finished; awaiting finish of 21 more threads
2021-08-05 00:01:55,808 worker thread finished; awaiting finish of 20 more threads
2021-08-05 00:01:55,812 worker thread finished; awaiting finish of 19 more threads
2021-08-05 00:01:55,820 worker thread finished; awaiting finish of 18 more threads
2021-08-05 00:01:55,824 worker thread finished; awaiting finish of 17 more threads
2021-08-05 00:01:55,827 worker thread finished; awaiting finish of 16 more threads
2021-08-05 00:01:55,830 worker thread finished; awaiting finish of 15 more threads
2021-08-05 00:01:55,835 worker thread finished; awaiting finish of 14 more threads
2021-08-05 00:01:55,851 worker thread finished; awaiting finish of 13 more threads
2021-08-05 00:01:55,853 worker thread finished; awaiting finish of 12 more threads
2021-08-05 00:01:55,860 worker thread finished; awaiting finish of 11 more threads
2021-08-05 00:01:55,861 worker thread finished; awaiting finish of 10 more threads
2021-08-05 00:01:55,870 worker thread finished; awaiting finish of 9 more threads
2021-08-05 00:01:55,870 worker thread finished; awaiting finish of 8 more threads
2021-08-05 00:01:55,875 worker thread finished; awaiting finish of 7 more threads
2021-08-05 00:01:55,879 worker thread finished; awaiting finish of 6 more threads
2021-08-05 00:01:55,883 worker thread finished; awaiting finish of 5 more threads
2021-08-05 00:01:55,886 worker thread finished; awaiting finish of 4 more threads
2021-08-05 00:01:55,886 worker thread finished; awaiting finish of 3 more threads
2021-08-05 00:01:55,892 worker thread finished; awaiting finish of 2 more threads
2021-08-05 00:01:55,901 worker thread finished; awaiting finish of 1 more threads
2021-08-05 00:01:55,902 worker thread finished; awaiting finish of 0 more threads
2021-08-05 00:01:55,902 EPOCH - 5 : training on 17427200 raw words (17417947 effective words) took 10.5s, 1659798 effective words/s
2021-08-05 00:01:55,903 Word2Vec lifecycle event {'msg': 'training on 87136000 raw words (87090424 effective words) took 53.5s, 1627416 effective words/s', 'datetime': '2021-08-05T00:01:55.903189', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'train'}
2021-08-05 00:01:55,903 Word2Vec lifecycle event {'params': 'Word2Vec(vocab=10892, vector_size=128, alpha=0.025)', 'datetime': '2021-08-05T00:01:55.903358', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'created'}
2021-08-05 00:01:57,005 fairwalk: embed
2021-08-05 00:03:18,508 fairwalk: result
2021-08-05 00:03:34,205 fairwalk: initialize
make: Entering directory `/home/he.1773/workplace/FairGraphs/baselines/FairWalk/fast-random-walk'
rm -f *.o walk
make -C unit_tests clean
make[1]: Entering directory `/home/he.1773/workplace/FairGraphs/baselines/FairWalk/fast-random-walk/unit_tests'
rm -f *.o Graph HelperFunctions WeightedGraph
make[1]: Leaving directory `/home/he.1773/workplace/FairGraphs/baselines/FairWalk/fast-random-walk/unit_tests'
make: Leaving directory `/home/he.1773/workplace/FairGraphs/baselines/FairWalk/fast-random-walk'
make: Entering directory `/home/he.1773/workplace/FairGraphs/baselines/FairWalk/fast-random-walk'
g++ -Wall -std=c++11 -g -O2  -c Graph.cpp
g++ -Wall -std=c++11 -g -O2  -c HelperFunctions.cpp
g++ -Wall -std=c++11 -g -O2  -c walk.cpp
g++ -Wall -std=c++11 -g -O2  -c WeightedGraph.cpp
echo "Sources: " Graph.cpp HelperFunctions.cpp walk.cpp WeightedGraph.cpp
Sources:  Graph.cpp HelperFunctions.cpp walk.cpp WeightedGraph.cpp
echo Graph.o HelperFunctions.o walk.o WeightedGraph.o
Graph.o HelperFunctions.o walk.o WeightedGraph.o
g++ -Wall -std=c++11 -g -O2 -o walk Graph.o HelperFunctions.o walk.o WeightedGraph.o
make: Leaving directory `/home/he.1773/workplace/FairGraphs/baselines/FairWalk/fast-random-walk'
2021-08-05 00:03:46,893 collecting all words and their counts
2021-08-05 00:03:46,893 PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2021-08-05 00:03:47,044 PROGRESS: at sentence #10000, processed 800000 words, keeping 10910 word types
2021-08-05 00:03:47,201 PROGRESS: at sentence #20000, processed 1600000 words, keeping 10913 word types
2021-08-05 00:03:47,359 PROGRESS: at sentence #30000, processed 2400000 words, keeping 10913 word types
2021-08-05 00:03:47,517 PROGRESS: at sentence #40000, processed 3200000 words, keeping 10913 word types
2021-08-05 00:03:47,676 PROGRESS: at sentence #50000, processed 4000000 words, keeping 10913 word types
2021-08-05 00:03:47,834 PROGRESS: at sentence #60000, processed 4800000 words, keeping 10913 word types
2021-08-05 00:03:47,991 PROGRESS: at sentence #70000, processed 5600000 words, keeping 10913 word types
2021-08-05 00:03:48,150 PROGRESS: at sentence #80000, processed 6400000 words, keeping 10913 word types
2021-08-05 00:03:48,309 PROGRESS: at sentence #90000, processed 7200000 words, keeping 10913 word types
2021-08-05 00:03:48,470 PROGRESS: at sentence #100000, processed 8000000 words, keeping 10913 word types
2021-08-05 00:03:48,628 PROGRESS: at sentence #110000, processed 8800000 words, keeping 10913 word types
2021-08-05 00:03:48,787 PROGRESS: at sentence #120000, processed 9600000 words, keeping 10913 word types
2021-08-05 00:03:48,946 PROGRESS: at sentence #130000, processed 10400000 words, keeping 10913 word types
2021-08-05 00:03:49,105 PROGRESS: at sentence #140000, processed 11200000 words, keeping 10913 word types
2021-08-05 00:03:49,263 PROGRESS: at sentence #150000, processed 12000000 words, keeping 10913 word types
2021-08-05 00:03:49,423 PROGRESS: at sentence #160000, processed 12800000 words, keeping 10913 word types
2021-08-05 00:03:49,582 PROGRESS: at sentence #170000, processed 13600000 words, keeping 10913 word types
2021-08-05 00:03:49,741 PROGRESS: at sentence #180000, processed 14400000 words, keeping 10913 word types
2021-08-05 00:03:49,900 PROGRESS: at sentence #190000, processed 15200000 words, keeping 10913 word types
2021-08-05 00:03:50,063 PROGRESS: at sentence #200000, processed 16000000 words, keeping 10913 word types
2021-08-05 00:03:50,222 PROGRESS: at sentence #210000, processed 16800000 words, keeping 10913 word types
2021-08-05 00:03:50,353 collected 10913 word types from a corpus of 17460800 raw words and 218260 sentences
2021-08-05 00:03:50,353 Creating a fresh vocabulary
2021-08-05 00:03:50,383 Word2Vec lifecycle event {'msg': 'effective_min_count=10 retains 10913 unique words (100.0%% of original 10913, drops 0)', 'datetime': '2021-08-05T00:03:50.383270', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}
2021-08-05 00:03:50,383 Word2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 17460800 word corpus (100.0%% of original 17460800, drops 0)', 'datetime': '2021-08-05T00:03:50.383377', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}
2021-08-05 00:03:50,430 deleting the raw counts dictionary of 10913 items
2021-08-05 00:03:50,430 sample=0.001 downsamples 2 most-common words
2021-08-05 00:03:50,430 Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 17426757.788875982 word corpus (99.8%% of prior 17460800)', 'datetime': '2021-08-05T00:03:50.430331', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}
2021-08-05 00:03:50,523 estimated required memory for 10913 words and 128 dimensions: 16631412 bytes
2021-08-05 00:03:50,523 resetting layer weights
2021-08-05 00:03:50,534 Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-08-05T00:03:50.534559', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'build_vocab'}
2021-08-05 00:03:50,534 Word2Vec lifecycle event {'msg': 'training model with 28 workers on 10913 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=5 window=10', 'datetime': '2021-08-05T00:03:50.534656', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'train'}
2021-08-05 00:03:51,546 EPOCH 1 - PROGRESS: at 3.49% examples, 607287 words/s, in_qsize 55, out_qsize 1
2021-08-05 00:03:52,587 EPOCH 1 - PROGRESS: at 9.74% examples, 830308 words/s, in_qsize 56, out_qsize 0
2021-08-05 00:03:53,602 EPOCH 1 - PROGRESS: at 16.09% examples, 916997 words/s, in_qsize 53, out_qsize 2
2021-08-05 00:03:54,616 EPOCH 1 - PROGRESS: at 22.51% examples, 963112 words/s, in_qsize 53, out_qsize 2
2021-08-05 00:03:55,627 EPOCH 1 - PROGRESS: at 30.53% examples, 1046483 words/s, in_qsize 55, out_qsize 6
2021-08-05 00:03:56,633 EPOCH 1 - PROGRESS: at 39.52% examples, 1130934 words/s, in_qsize 55, out_qsize 2
2021-08-05 00:03:57,636 EPOCH 1 - PROGRESS: at 48.39% examples, 1189017 words/s, in_qsize 55, out_qsize 2
2021-08-05 00:03:58,638 EPOCH 1 - PROGRESS: at 57.67% examples, 1241656 words/s, in_qsize 52, out_qsize 2
2021-08-05 00:03:59,648 EPOCH 1 - PROGRESS: at 67.18% examples, 1285853 words/s, in_qsize 56, out_qsize 2
2021-08-05 00:04:00,648 EPOCH 1 - PROGRESS: at 76.80% examples, 1324465 words/s, in_qsize 54, out_qsize 1
2021-08-05 00:04:01,676 EPOCH 1 - PROGRESS: at 86.25% examples, 1350151 words/s, in_qsize 51, out_qsize 4
2021-08-05 00:04:02,679 EPOCH 1 - PROGRESS: at 95.53% examples, 1371789 words/s, in_qsize 52, out_qsize 3
2021-08-05 00:04:02,984 worker thread finished; awaiting finish of 27 more threads
2021-08-05 00:04:02,988 worker thread finished; awaiting finish of 26 more threads
2021-08-05 00:04:02,991 worker thread finished; awaiting finish of 25 more threads
2021-08-05 00:04:02,996 worker thread finished; awaiting finish of 24 more threads
2021-08-05 00:04:02,997 worker thread finished; awaiting finish of 23 more threads
2021-08-05 00:04:03,004 worker thread finished; awaiting finish of 22 more threads
2021-08-05 00:04:03,004 worker thread finished; awaiting finish of 21 more threads
2021-08-05 00:04:03,008 worker thread finished; awaiting finish of 20 more threads
2021-08-05 00:04:03,029 worker thread finished; awaiting finish of 19 more threads
2021-08-05 00:04:03,030 worker thread finished; awaiting finish of 18 more threads
2021-08-05 00:04:03,030 worker thread finished; awaiting finish of 17 more threads
2021-08-05 00:04:03,031 worker thread finished; awaiting finish of 16 more threads
2021-08-05 00:04:03,034 worker thread finished; awaiting finish of 15 more threads
2021-08-05 00:04:03,037 worker thread finished; awaiting finish of 14 more threads
2021-08-05 00:04:03,048 worker thread finished; awaiting finish of 13 more threads
2021-08-05 00:04:03,065 worker thread finished; awaiting finish of 12 more threads
2021-08-05 00:04:03,075 worker thread finished; awaiting finish of 11 more threads
2021-08-05 00:04:03,076 worker thread finished; awaiting finish of 10 more threads
2021-08-05 00:04:03,085 worker thread finished; awaiting finish of 9 more threads
2021-08-05 00:04:03,088 worker thread finished; awaiting finish of 8 more threads
2021-08-05 00:04:03,089 worker thread finished; awaiting finish of 7 more threads
2021-08-05 00:04:03,093 worker thread finished; awaiting finish of 6 more threads
2021-08-05 00:04:03,098 worker thread finished; awaiting finish of 5 more threads
2021-08-05 00:04:03,105 worker thread finished; awaiting finish of 4 more threads
2021-08-05 00:04:03,109 worker thread finished; awaiting finish of 3 more threads
2021-08-05 00:04:03,110 worker thread finished; awaiting finish of 2 more threads
2021-08-05 00:04:03,124 worker thread finished; awaiting finish of 1 more threads
2021-08-05 00:04:03,126 worker thread finished; awaiting finish of 0 more threads
2021-08-05 00:04:03,126 EPOCH - 1 : training on 17460800 raw words (17426744 effective words) took 12.6s, 1384960 effective words/s
2021-08-05 00:04:04,139 EPOCH 2 - PROGRESS: at 7.50% examples, 1307218 words/s, in_qsize 55, out_qsize 2
2021-08-05 00:04:05,148 EPOCH 2 - PROGRESS: at 16.84% examples, 1460699 words/s, in_qsize 51, out_qsize 3
2021-08-05 00:04:06,166 EPOCH 2 - PROGRESS: at 26.46% examples, 1523391 words/s, in_qsize 55, out_qsize 0
2021-08-05 00:04:07,189 EPOCH 2 - PROGRESS: at 36.14% examples, 1555069 words/s, in_qsize 53, out_qsize 2
2021-08-05 00:04:08,195 EPOCH 2 - PROGRESS: at 45.87% examples, 1581182 words/s, in_qsize 56, out_qsize 0
2021-08-05 00:04:09,202 EPOCH 2 - PROGRESS: at 55.32% examples, 1590198 words/s, in_qsize 54, out_qsize 1
2021-08-05 00:04:10,257 EPOCH 2 - PROGRESS: at 64.95% examples, 1590289 words/s, in_qsize 54, out_qsize 5
2021-08-05 00:04:11,263 EPOCH 2 - PROGRESS: at 74.80% examples, 1604367 words/s, in_qsize 56, out_qsize 0
2021-08-05 00:04:12,264 EPOCH 2 - PROGRESS: at 84.07% examples, 1605649 words/s, in_qsize 55, out_qsize 0
2021-08-05 00:04:13,282 EPOCH 2 - PROGRESS: at 93.41% examples, 1604881 words/s, in_qsize 56, out_qsize 0
2021-08-05 00:04:13,824 worker thread finished; awaiting finish of 27 more threads
2021-08-05 00:04:13,832 worker thread finished; awaiting finish of 26 more threads
2021-08-05 00:04:13,837 worker thread finished; awaiting finish of 25 more threads
2021-08-05 00:04:13,837 worker thread finished; awaiting finish of 24 more threads
2021-08-05 00:04:13,838 worker thread finished; awaiting finish of 23 more threads
2021-08-05 00:04:13,844 worker thread finished; awaiting finish of 22 more threads
2021-08-05 00:04:13,852 worker thread finished; awaiting finish of 21 more threads
2021-08-05 00:04:13,853 worker thread finished; awaiting finish of 20 more threads
2021-08-05 00:04:13,860 worker thread finished; awaiting finish of 19 more threads
2021-08-05 00:04:13,864 worker thread finished; awaiting finish of 18 more threads
2021-08-05 00:04:13,866 worker thread finished; awaiting finish of 17 more threads
2021-08-05 00:04:13,873 worker thread finished; awaiting finish of 16 more threads
2021-08-05 00:04:13,876 worker thread finished; awaiting finish of 15 more threads
2021-08-05 00:04:13,879 worker thread finished; awaiting finish of 14 more threads
2021-08-05 00:04:13,885 worker thread finished; awaiting finish of 13 more threads
2021-08-05 00:04:13,890 worker thread finished; awaiting finish of 12 more threads
2021-08-05 00:04:13,893 worker thread finished; awaiting finish of 11 more threads
2021-08-05 00:04:13,898 worker thread finished; awaiting finish of 10 more threads
2021-08-05 00:04:13,904 worker thread finished; awaiting finish of 9 more threads
2021-08-05 00:04:13,914 worker thread finished; awaiting finish of 8 more threads
2021-08-05 00:04:13,917 worker thread finished; awaiting finish of 7 more threads
2021-08-05 00:04:13,917 worker thread finished; awaiting finish of 6 more threads
2021-08-05 00:04:13,922 worker thread finished; awaiting finish of 5 more threads
2021-08-05 00:04:13,925 worker thread finished; awaiting finish of 4 more threads
2021-08-05 00:04:13,926 worker thread finished; awaiting finish of 3 more threads
2021-08-05 00:04:13,953 worker thread finished; awaiting finish of 2 more threads
2021-08-05 00:04:13,959 worker thread finished; awaiting finish of 1 more threads
2021-08-05 00:04:13,960 worker thread finished; awaiting finish of 0 more threads
2021-08-05 00:04:13,960 EPOCH - 2 : training on 17460800 raw words (17426790 effective words) took 10.8s, 1610348 effective words/s
2021-08-05 00:04:14,970 EPOCH 3 - PROGRESS: at 7.39% examples, 1287288 words/s, in_qsize 56, out_qsize 0
2021-08-05 00:04:15,985 EPOCH 3 - PROGRESS: at 16.55% examples, 1431373 words/s, in_qsize 56, out_qsize 2
2021-08-05 00:04:16,995 EPOCH 3 - PROGRESS: at 25.60% examples, 1474791 words/s, in_qsize 54, out_qsize 1
2021-08-05 00:04:18,001 EPOCH 3 - PROGRESS: at 34.42% examples, 1488069 words/s, in_qsize 55, out_qsize 0
2021-08-05 00:04:19,011 EPOCH 3 - PROGRESS: at 42.72% examples, 1476938 words/s, in_qsize 54, out_qsize 2
2021-08-05 00:04:20,014 EPOCH 3 - PROGRESS: at 51.14% examples, 1474588 words/s, in_qsize 56, out_qsize 2
2021-08-05 00:04:21,026 EPOCH 3 - PROGRESS: at 60.02% examples, 1482354 words/s, in_qsize 55, out_qsize 0
2021-08-05 00:04:22,033 EPOCH 3 - PROGRESS: at 68.55% examples, 1481561 words/s, in_qsize 56, out_qsize 1
2021-08-05 00:04:23,040 EPOCH 3 - PROGRESS: at 76.86% examples, 1476697 words/s, in_qsize 54, out_qsize 2
2021-08-05 00:04:24,043 EPOCH 3 - PROGRESS: at 85.10% examples, 1472323 words/s, in_qsize 55, out_qsize 1
2021-08-05 00:04:25,044 EPOCH 3 - PROGRESS: at 93.52% examples, 1471685 words/s, in_qsize 56, out_qsize 0
2021-08-05 00:04:25,652 worker thread finished; awaiting finish of 27 more threads
2021-08-05 00:04:25,652 worker thread finished; awaiting finish of 26 more threads
2021-08-05 00:04:25,660 worker thread finished; awaiting finish of 25 more threads
2021-08-05 00:04:25,662 worker thread finished; awaiting finish of 24 more threads
2021-08-05 00:04:25,669 worker thread finished; awaiting finish of 23 more threads
2021-08-05 00:04:25,675 worker thread finished; awaiting finish of 22 more threads
2021-08-05 00:04:25,684 worker thread finished; awaiting finish of 21 more threads
2021-08-05 00:04:25,685 worker thread finished; awaiting finish of 20 more threads
2021-08-05 00:04:25,695 worker thread finished; awaiting finish of 19 more threads
2021-08-05 00:04:25,696 worker thread finished; awaiting finish of 18 more threads
2021-08-05 00:04:25,698 worker thread finished; awaiting finish of 17 more threads
2021-08-05 00:04:25,700 worker thread finished; awaiting finish of 16 more threads
2021-08-05 00:04:25,725 worker thread finished; awaiting finish of 15 more threads
2021-08-05 00:04:25,734 worker thread finished; awaiting finish of 14 more threads
2021-08-05 00:04:25,743 worker thread finished; awaiting finish of 13 more threads
2021-08-05 00:04:25,748 worker thread finished; awaiting finish of 12 more threads
2021-08-05 00:04:25,750 worker thread finished; awaiting finish of 11 more threads
2021-08-05 00:04:25,752 worker thread finished; awaiting finish of 10 more threads
2021-08-05 00:04:25,759 worker thread finished; awaiting finish of 9 more threads
2021-08-05 00:04:25,760 worker thread finished; awaiting finish of 8 more threads
2021-08-05 00:04:25,761 worker thread finished; awaiting finish of 7 more threads
2021-08-05 00:04:25,767 worker thread finished; awaiting finish of 6 more threads
2021-08-05 00:04:25,771 worker thread finished; awaiting finish of 5 more threads
2021-08-05 00:04:25,777 worker thread finished; awaiting finish of 4 more threads
2021-08-05 00:04:25,778 worker thread finished; awaiting finish of 3 more threads
2021-08-05 00:04:25,780 worker thread finished; awaiting finish of 2 more threads
2021-08-05 00:04:25,786 worker thread finished; awaiting finish of 1 more threads
2021-08-05 00:04:25,790 worker thread finished; awaiting finish of 0 more threads
2021-08-05 00:04:25,791 EPOCH - 3 : training on 17460800 raw words (17426883 effective words) took 11.8s, 1474206 effective words/s
2021-08-05 00:04:26,816 EPOCH 4 - PROGRESS: at 6.64% examples, 1143992 words/s, in_qsize 54, out_qsize 1
2021-08-05 00:04:27,835 EPOCH 4 - PROGRESS: at 14.66% examples, 1258046 words/s, in_qsize 55, out_qsize 2
2021-08-05 00:04:28,844 EPOCH 4 - PROGRESS: at 22.91% examples, 1313184 words/s, in_qsize 54, out_qsize 1
2021-08-05 00:04:29,855 EPOCH 4 - PROGRESS: at 30.93% examples, 1330358 words/s, in_qsize 56, out_qsize 1
2021-08-05 00:04:30,864 EPOCH 4 - PROGRESS: at 39.06% examples, 1345239 words/s, in_qsize 54, out_qsize 1
2021-08-05 00:04:31,874 EPOCH 4 - PROGRESS: at 47.65% examples, 1368024 words/s, in_qsize 56, out_qsize 1
2021-08-05 00:04:32,887 EPOCH 4 - PROGRESS: at 56.76% examples, 1396323 words/s, in_qsize 56, out_qsize 5
2021-08-05 00:04:33,888 EPOCH 4 - PROGRESS: at 65.69% examples, 1416084 words/s, in_qsize 54, out_qsize 1
2021-08-05 00:04:34,892 EPOCH 4 - PROGRESS: at 74.85% examples, 1435328 words/s, in_qsize 55, out_qsize 1
2021-08-05 00:04:35,897 EPOCH 4 - PROGRESS: at 83.79% examples, 1446592 words/s, in_qsize 53, out_qsize 4
2021-08-05 00:04:36,905 EPOCH 4 - PROGRESS: at 93.12% examples, 1461860 words/s, in_qsize 55, out_qsize 0
2021-08-05 00:04:37,500 worker thread finished; awaiting finish of 27 more threads
2021-08-05 00:04:37,503 worker thread finished; awaiting finish of 26 more threads
2021-08-05 00:04:37,505 worker thread finished; awaiting finish of 25 more threads
2021-08-05 00:04:37,509 worker thread finished; awaiting finish of 24 more threads
2021-08-05 00:04:37,509 worker thread finished; awaiting finish of 23 more threads
2021-08-05 00:04:37,516 worker thread finished; awaiting finish of 22 more threads
2021-08-05 00:04:37,526 worker thread finished; awaiting finish of 21 more threads
2021-08-05 00:04:37,533 worker thread finished; awaiting finish of 20 more threads
2021-08-05 00:04:37,542 worker thread finished; awaiting finish of 19 more threads
2021-08-05 00:04:37,546 worker thread finished; awaiting finish of 18 more threads
2021-08-05 00:04:37,549 worker thread finished; awaiting finish of 17 more threads
2021-08-05 00:04:37,558 worker thread finished; awaiting finish of 16 more threads
2021-08-05 00:04:37,572 worker thread finished; awaiting finish of 15 more threads
2021-08-05 00:04:37,577 worker thread finished; awaiting finish of 14 more threads
2021-08-05 00:04:37,578 worker thread finished; awaiting finish of 13 more threads
2021-08-05 00:04:37,587 worker thread finished; awaiting finish of 12 more threads
2021-08-05 00:04:37,587 worker thread finished; awaiting finish of 11 more threads
2021-08-05 00:04:37,590 worker thread finished; awaiting finish of 10 more threads
2021-08-05 00:04:37,603 worker thread finished; awaiting finish of 9 more threads
2021-08-05 00:04:37,603 worker thread finished; awaiting finish of 8 more threads
2021-08-05 00:04:37,605 worker thread finished; awaiting finish of 7 more threads
2021-08-05 00:04:37,609 worker thread finished; awaiting finish of 6 more threads
2021-08-05 00:04:37,612 worker thread finished; awaiting finish of 5 more threads
2021-08-05 00:04:37,623 worker thread finished; awaiting finish of 4 more threads
2021-08-05 00:04:37,625 worker thread finished; awaiting finish of 3 more threads
2021-08-05 00:04:37,625 worker thread finished; awaiting finish of 2 more threads
2021-08-05 00:04:37,627 worker thread finished; awaiting finish of 1 more threads
2021-08-05 00:04:37,630 worker thread finished; awaiting finish of 0 more threads
2021-08-05 00:04:37,630 EPOCH - 4 : training on 17460800 raw words (17426784 effective words) took 11.8s, 1473508 effective words/s
2021-08-05 00:04:38,648 EPOCH 5 - PROGRESS: at 7.22% examples, 1246316 words/s, in_qsize 55, out_qsize 7
2021-08-05 00:04:39,676 EPOCH 5 - PROGRESS: at 16.84% examples, 1441049 words/s, in_qsize 56, out_qsize 7
2021-08-05 00:04:40,680 EPOCH 5 - PROGRESS: at 26.29% examples, 1506541 words/s, in_qsize 55, out_qsize 0
2021-08-05 00:04:41,682 EPOCH 5 - PROGRESS: at 35.57% examples, 1533345 words/s, in_qsize 55, out_qsize 2
2021-08-05 00:04:42,719 EPOCH 5 - PROGRESS: at 44.96% examples, 1542381 words/s, in_qsize 56, out_qsize 7
2021-08-05 00:04:43,725 EPOCH 5 - PROGRESS: at 54.64% examples, 1564596 words/s, in_qsize 55, out_qsize 1
2021-08-05 00:04:44,726 EPOCH 5 - PROGRESS: at 63.80% examples, 1568933 words/s, in_qsize 56, out_qsize 0
2021-08-05 00:04:45,729 EPOCH 5 - PROGRESS: at 72.51% examples, 1561934 words/s, in_qsize 54, out_qsize 5
2021-08-05 00:04:46,759 EPOCH 5 - PROGRESS: at 82.01% examples, 1567246 words/s, in_qsize 56, out_qsize 1
2021-08-05 00:04:47,763 EPOCH 5 - PROGRESS: at 91.18% examples, 1569486 words/s, in_qsize 55, out_qsize 0
2021-08-05 00:04:48,575 worker thread finished; awaiting finish of 27 more threads
2021-08-05 00:04:48,582 worker thread finished; awaiting finish of 26 more threads
2021-08-05 00:04:48,583 worker thread finished; awaiting finish of 25 more threads
2021-08-05 00:04:48,586 worker thread finished; awaiting finish of 24 more threads
2021-08-05 00:04:48,588 worker thread finished; awaiting finish of 23 more threads
2021-08-05 00:04:48,600 worker thread finished; awaiting finish of 22 more threads
2021-08-05 00:04:48,607 worker thread finished; awaiting finish of 21 more threads
2021-08-05 00:04:48,615 worker thread finished; awaiting finish of 20 more threads
2021-08-05 00:04:48,622 worker thread finished; awaiting finish of 19 more threads
2021-08-05 00:04:48,628 worker thread finished; awaiting finish of 18 more threads
2021-08-05 00:04:48,634 worker thread finished; awaiting finish of 17 more threads
2021-08-05 00:04:48,639 worker thread finished; awaiting finish of 16 more threads
2021-08-05 00:04:48,643 worker thread finished; awaiting finish of 15 more threads
2021-08-05 00:04:48,649 worker thread finished; awaiting finish of 14 more threads
2021-08-05 00:04:48,658 worker thread finished; awaiting finish of 13 more threads
2021-08-05 00:04:48,659 worker thread finished; awaiting finish of 12 more threads
2021-08-05 00:04:48,662 worker thread finished; awaiting finish of 11 more threads
2021-08-05 00:04:48,662 worker thread finished; awaiting finish of 10 more threads
2021-08-05 00:04:48,666 worker thread finished; awaiting finish of 9 more threads
2021-08-05 00:04:48,674 worker thread finished; awaiting finish of 8 more threads
2021-08-05 00:04:48,674 worker thread finished; awaiting finish of 7 more threads
2021-08-05 00:04:48,677 worker thread finished; awaiting finish of 6 more threads
2021-08-05 00:04:48,679 worker thread finished; awaiting finish of 5 more threads
2021-08-05 00:04:48,682 worker thread finished; awaiting finish of 4 more threads
2021-08-05 00:04:48,685 worker thread finished; awaiting finish of 3 more threads
2021-08-05 00:04:48,689 worker thread finished; awaiting finish of 2 more threads
2021-08-05 00:04:48,692 worker thread finished; awaiting finish of 1 more threads
2021-08-05 00:04:48,711 worker thread finished; awaiting finish of 0 more threads
2021-08-05 00:04:48,711 EPOCH - 5 : training on 17460800 raw words (17426824 effective words) took 11.1s, 1574050 effective words/s
2021-08-05 00:04:48,711 Word2Vec lifecycle event {'msg': 'training on 87304000 raw words (87134025 effective words) took 58.2s, 1497749 effective words/s', 'datetime': '2021-08-05T00:04:48.711442', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'train'}
2021-08-05 00:04:48,711 Word2Vec lifecycle event {'params': 'Word2Vec(vocab=10913, vector_size=128, alpha=0.025)', 'datetime': '2021-08-05T00:04:48.711586', 'gensim': '4.0.1', 'python': '3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) \n[GCC 9.3.0]', 'platform': 'Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10', 'event': 'created'}
2021-08-05 00:04:49,627 fairwalk: embed
2021-08-05 00:06:13,548 fairwalk: result
2021-08-05 00:06:13,595 embed_baselines
Epoch: 0001 train_loss= 35.23234 train_acc= 0.00028 time= 1.72035
Epoch: 0002 train_loss= 468.99051 train_acc= 0.00028 time= 1.67677
Epoch: 0003 train_loss= 29.26333 train_acc= 0.00028 time= 1.68294
Epoch: 0004 train_loss= 0.69315 train_acc= 0.00028 time= 1.64288
Epoch: 0005 train_loss= 0.69315 train_acc= 0.00028 time= 1.65579
Epoch: 0006 train_loss= 0.69315 train_acc= 0.00028 time= 1.66160
Epoch: 0007 train_loss= 0.69315 train_acc= 0.00028 time= 1.65019
Epoch: 0008 train_loss= 0.69315 train_acc= 0.00028 time= 1.65648
Epoch: 0009 train_loss= 0.69315 train_acc= 0.00028 time= 1.64950
Epoch: 0010 train_loss= 0.69315 train_acc= 0.00028 time= 1.66618
Epoch: 0011 train_loss= 0.69315 train_acc= 0.00028 time= 1.62625
Epoch: 0012 train_loss= 0.69315 train_acc= 0.00028 time= 1.66398
Epoch: 0013 train_loss= 0.69315 train_acc= 0.00028 time= 1.64825
Epoch: 0014 train_loss= 0.69315 train_acc= 0.00028 time= 1.64944
Epoch: 0015 train_loss= 0.69315 train_acc= 0.00028 time= 1.63643
Epoch: 0016 train_loss= 0.69315 train_acc= 0.00028 time= 1.65731
Epoch: 0017 train_loss= 0.69315 train_acc= 0.00028 time= 1.63595
Epoch: 0018 train_loss= 0.69315 train_acc= 0.00028 time= 1.65306
Epoch: 0019 train_loss= 0.69315 train_acc= 0.00028 time= 1.64290
Epoch: 0020 train_loss= 0.69315 train_acc= 0.00028 time= 1.63996
Epoch: 0021 train_loss= 0.69315 train_acc= 0.00028 time= 1.62266
Epoch: 0022 train_loss= 0.69315 train_acc= 0.00028 time= 1.66171
Epoch: 0023 train_loss= 0.69315 train_acc= 0.00028 time= 1.63753
Epoch: 0024 train_loss= 0.69315 train_acc= 0.00028 time= 1.63467
Epoch: 0025 train_loss= 0.69315 train_acc= 0.00028 time= 1.63936
Epoch: 0026 train_loss= 0.69315 train_acc= 0.00028 time= 1.61272
Epoch: 0027 train_loss= 0.69315 train_acc= 0.00028 time= 1.62600
Epoch: 0028 train_loss= 0.69315 train_acc= 0.00028 time= 1.62953
Epoch: 0029 train_loss= 0.69315 train_acc= 0.00028 time= 1.64208
Epoch: 0030 train_loss= 0.69315 train_acc= 0.00028 time= 1.63773
Epoch: 0031 train_loss= 0.69315 train_acc= 0.00028 time= 1.64083
Epoch: 0032 train_loss= 0.69315 train_acc= 0.00028 time= 1.62742
Epoch: 0033 train_loss= 0.69315 train_acc= 0.00028 time= 1.63143
Epoch: 0034 train_loss= 0.69315 train_acc= 0.00028 time= 1.62733
Epoch: 0035 train_loss= 0.69315 train_acc= 0.00028 time= 1.63877
Epoch: 0036 train_loss= 0.69315 train_acc= 0.00028 time= 1.64102
Epoch: 0037 train_loss= 0.69315 train_acc= 0.00028 time= 1.64279
Epoch: 0038 train_loss= 0.69315 train_acc= 0.00028 time= 1.63591
Epoch: 0039 train_loss= 0.69315 train_acc= 0.00028 time= 1.63211
Epoch: 0040 train_loss= 0.69315 train_acc= 0.00028 time= 1.64805
Epoch: 0041 train_loss= 0.69315 train_acc= 0.00028 time= 1.64169
Epoch: 0042 train_loss= 0.69315 train_acc= 0.00028 time= 1.63967
Epoch: 0043 train_loss= 0.69315 train_acc= 0.00028 time= 1.63803
Epoch: 0044 train_loss= 0.69315 train_acc= 0.00028 time= 1.66067
Epoch: 0045 train_loss= 0.69315 train_acc= 0.00028 time= 1.63068
Epoch: 0046 train_loss= 0.69315 train_acc= 0.00028 time= 1.64494
Epoch: 0047 train_loss= 0.69315 train_acc= 0.00028 time= 1.63815
Epoch: 0048 train_loss= 0.69315 train_acc= 0.00028 time= 1.65338
Epoch: 0049 train_loss= 0.69315 train_acc= 0.00028 time= 1.64168
Epoch: 0050 train_loss= 0.69315 train_acc= 0.00028 time= 1.64298
Epoch: 0051 train_loss= 0.69315 train_acc= 0.00028 time= 1.64886
Epoch: 0052 train_loss= 0.69315 train_acc= 0.00028 time= 1.62207
Epoch: 0053 train_loss= 0.69315 train_acc= 0.00028 time= 1.63747
Epoch: 0054 train_loss= 0.69315 train_acc= 0.00028 time= 1.62804
Epoch: 0055 train_loss= 0.69315 train_acc= 0.00028 time= 1.62408
Epoch: 0056 train_loss= 0.69315 train_acc= 0.00028 time= 1.64938
Epoch: 0057 train_loss= 0.69315 train_acc= 0.00028 time= 1.62834
Epoch: 0058 train_loss= 0.69315 train_acc= 0.00028 time= 1.63556
Epoch: 0059 train_loss= 0.69315 train_acc= 0.00028 time= 1.63550
Epoch: 0060 train_loss= 0.69315 train_acc= 0.00028 time= 1.65258
Epoch: 0061 train_loss= 0.69315 train_acc= 0.00028 time= 1.63338
Epoch: 0062 train_loss= 0.69315 train_acc= 0.00028 time= 1.63059
Epoch: 0063 train_loss= 0.69315 train_acc= 0.00028 time= 1.65018
Epoch: 0064 train_loss= 0.69315 train_acc= 0.00028 time= 1.64468
Epoch: 0065 train_loss= 0.69315 train_acc= 0.00028 time= 1.63299
Epoch: 0066 train_loss= 0.69315 train_acc= 0.00028 time= 1.61976
Epoch: 0067 train_loss= 0.69315 train_acc= 0.00028 time= 1.64805
Epoch: 0068 train_loss= 0.69315 train_acc= 0.00028 time= 1.62651
Epoch: 0069 train_loss= 0.69315 train_acc= 0.00028 time= 1.64695
Epoch: 0070 train_loss= 0.69315 train_acc= 0.00028 time= 1.63527
Epoch: 0071 train_loss= 0.69315 train_acc= 0.00028 time= 1.62141
Epoch: 0072 train_loss= 0.69315 train_acc= 0.00028 time= 1.64755
Epoch: 0073 train_loss= 0.69315 train_acc= 0.00028 time= 1.64382
Epoch: 0074 train_loss= 0.69315 train_acc= 0.00028 time= 1.63105
Epoch: 0075 train_loss= 0.69315 train_acc= 0.00028 time= 1.64379
Epoch: 0076 train_loss= 0.69315 train_acc= 0.00028 time= 1.63504
Epoch: 0077 train_loss= 0.69315 train_acc= 0.00028 time= 1.66351
Epoch: 0078 train_loss= 0.69315 train_acc= 0.00028 time= 1.64112
Epoch: 0079 train_loss= 0.69315 train_acc= 0.00028 time= 1.65025
Epoch: 0080 train_loss= 0.69315 train_acc= 0.00028 time= 1.63999
Epoch: 0081 train_loss= 0.69315 train_acc= 0.00028 time= 1.64986
Epoch: 0082 train_loss= 0.69315 train_acc= 0.00028 time= 1.63694
Epoch: 0083 train_loss= 0.69315 train_acc= 0.00028 time= 1.63863
Epoch: 0084 train_loss= 0.69315 train_acc= 0.00028 time= 1.64577
Epoch: 0085 train_loss= 0.69315 train_acc= 0.00028 time= 1.62756
Epoch: 0086 train_loss= 0.69315 train_acc= 0.00028 time= 1.63076
Epoch: 0087 train_loss= 0.69315 train_acc= 0.00028 time= 1.63307
Epoch: 0088 train_loss= 0.69315 train_acc= 0.00028 time= 1.64136
Epoch: 0089 train_loss= 0.69315 train_acc= 0.00028 time= 1.64429
Epoch: 0090 train_loss= 0.69315 train_acc= 0.00028 time= 1.62918
Epoch: 0091 train_loss= 0.69315 train_acc= 0.00028 time= 1.63281
Epoch: 0092 train_loss= 0.69315 train_acc= 0.00028 time= 1.62941
Epoch: 0093 train_loss= 0.69315 train_acc= 0.00028 time= 1.63683
Epoch: 0094 train_loss= 0.69315 train_acc= 0.00028 time= 1.62005
Epoch: 0095 train_loss= 0.69315 train_acc= 0.00028 time= 1.62814
Epoch: 0096 train_loss= 0.69315 train_acc= 0.00028 time= 1.64740
Epoch: 0097 train_loss= 0.69315 train_acc= 0.00028 time= 1.64426
Epoch: 0098 train_loss= 0.69315 train_acc= 0.00028 time= 1.64325
Epoch: 0099 train_loss= 0.69315 train_acc= 0.00028 time= 1.62385
Epoch: 0100 train_loss= 0.69315 train_acc= 0.00028 time= 1.63155
Epoch: 0101 train_loss= 0.69315 train_acc= 0.00028 time= 1.64832
Epoch: 0102 train_loss= 0.69315 train_acc= 0.00028 time= 1.62724
Epoch: 0103 train_loss= 0.69315 train_acc= 0.00028 time= 1.64363
Epoch: 0104 train_loss= 0.69315 train_acc= 0.00028 time= 1.64489
Epoch: 0105 train_loss= 0.69315 train_acc= 0.00028 time= 1.64656
Epoch: 0106 train_loss= 0.69315 train_acc= 0.00028 time= 1.63795
Epoch: 0107 train_loss= 0.69315 train_acc= 0.00028 time= 1.62938
Epoch: 0108 train_loss= 0.69315 train_acc= 0.00028 time= 1.65065
Epoch: 0109 train_loss= 0.69315 train_acc= 0.00028 time= 1.62641
Epoch: 0110 train_loss= 0.69315 train_acc= 0.00028 time= 1.62509
Epoch: 0111 train_loss= 0.69315 train_acc= 0.00028 time= 1.62523
Epoch: 0112 train_loss= 0.69315 train_acc= 0.00028 time= 1.65144
Epoch: 0113 train_loss= 0.69315 train_acc= 0.00028 time= 1.62665
Epoch: 0114 train_loss= 0.69315 train_acc= 0.00028 time= 1.66081
Epoch: 0115 train_loss= 0.69315 train_acc= 0.00028 time= 1.64576
Epoch: 0116 train_loss= 0.69315 train_acc= 0.00028 time= 1.63395
Epoch: 0117 train_loss= 0.69315 train_acc= 0.00028 time= 1.63985
Epoch: 0118 train_loss= 0.69315 train_acc= 0.00028 time= 1.65420
Epoch: 0119 train_loss= 0.69315 train_acc= 0.00028 time= 1.61929
Epoch: 0120 train_loss= 0.69315 train_acc= 0.00028 time= 1.63182
Epoch: 0121 train_loss= 0.69315 train_acc= 0.00028 time= 1.63138
Epoch: 0122 train_loss= 0.69315 train_acc= 0.00028 time= 1.63082
Epoch: 0123 train_loss= 0.69315 train_acc= 0.00028 time= 1.62530
Epoch: 0124 train_loss= 0.69315 train_acc= 0.00028 time= 1.64875
Epoch: 0125 train_loss= 0.69315 train_acc= 0.00028 time= 1.64598
Epoch: 0126 train_loss= 0.69315 train_acc= 0.00028 time= 1.64980
Epoch: 0127 train_loss= 0.69315 train_acc= 0.00028 time= 1.61918
Epoch: 0128 train_loss= 0.69315 train_acc= 0.00028 time= 1.62885
Epoch: 0129 train_loss= 0.69315 train_acc= 0.00028 time= 1.64457
Epoch: 0130 train_loss= 0.69315 train_acc= 0.00028 time= 1.64542
Epoch: 0131 train_loss= 0.69315 train_acc= 0.00028 time= 1.64445
Epoch: 0132 train_loss= 0.69315 train_acc= 0.00028 time= 1.64375
Epoch: 0133 train_loss= 0.69315 train_acc= 0.00028 time= 1.66925
Epoch: 0134 train_loss= 0.69315 train_acc= 0.00028 time= 1.66136
Epoch: 0135 train_loss= 0.69315 train_acc= 0.00028 time= 1.63609
Epoch: 0136 train_loss= 0.69315 train_acc= 0.00028 time= 1.63297
Epoch: 0137 train_loss= 0.69315 train_acc= 0.00028 time= 1.67219
Epoch: 0138 train_loss= 0.69315 train_acc= 0.00028 time= 1.62705
Epoch: 0139 train_loss= 0.69315 train_acc= 0.00028 time= 1.64130
Epoch: 0140 train_loss= 0.69315 train_acc= 0.00028 time= 1.67846
Epoch: 0141 train_loss= 0.69315 train_acc= 0.00028 time= 1.64328
Epoch: 0142 train_loss= 0.69315 train_acc= 0.00028 time= 1.63828
Epoch: 0143 train_loss= 0.69315 train_acc= 0.00028 time= 1.63171
Epoch: 0144 train_loss= 0.69315 train_acc= 0.00028 time= 1.64027
Epoch: 0145 train_loss= 0.69315 train_acc= 0.00028 time= 1.65001
Epoch: 0146 train_loss= 0.69315 train_acc= 0.00028 time= 1.63649
Epoch: 0147 train_loss= 0.69315 train_acc= 0.00028 time= 1.62712
Epoch: 0148 train_loss= 0.69315 train_acc= 0.00028 time= 1.64676
Epoch: 0149 train_loss= 0.69315 train_acc= 0.00028 time= 1.66020
Epoch: 0150 train_loss= 0.69315 train_acc= 0.00028 time= 1.65504
Epoch: 0151 train_loss= 0.69315 train_acc= 0.00028 time= 1.65046
Epoch: 0152 train_loss= 0.69315 train_acc= 0.00028 time= 1.62613
Epoch: 0153 train_loss= 0.69315 train_acc= 0.00028 time= 1.63147
Epoch: 0154 train_loss= 0.69315 train_acc= 0.00028 time= 1.63928
Epoch: 0155 train_loss= 0.69315 train_acc= 0.00028 time= 1.62642
Epoch: 0156 train_loss= 0.69315 train_acc= 0.00028 time= 1.66839
Epoch: 0157 train_loss= 0.69315 train_acc= 0.00028 time= 1.63351
Epoch: 0158 train_loss= 0.69315 train_acc= 0.00028 time= 1.65663
Epoch: 0159 train_loss= 0.69315 train_acc= 0.00028 time= 1.64371
Epoch: 0160 train_loss= 0.69315 train_acc= 0.00028 time= 1.64613
Epoch: 0161 train_loss= 0.69315 train_acc= 0.00028 time= 1.64086
Epoch: 0162 train_loss= 0.69315 train_acc= 0.00028 time= 1.64531
Epoch: 0163 train_loss= 0.69315 train_acc= 0.00028 time= 1.65523
Epoch: 0164 train_loss= 0.69315 train_acc= 0.00028 time= 1.63627
Epoch: 0165 train_loss= 0.69315 train_acc= 0.00028 time= 1.62266
Epoch: 0166 train_loss= 0.69315 train_acc= 0.00028 time= 1.63359
Epoch: 0167 train_loss= 0.69315 train_acc= 0.00028 time= 1.64595
Epoch: 0168 train_loss= 0.69315 train_acc= 0.00028 time= 1.64836
Epoch: 0169 train_loss= 0.69315 train_acc= 0.00028 time= 1.64268
Epoch: 0170 train_loss= 0.69315 train_acc= 0.00028 time= 1.65746
Epoch: 0171 train_loss= 0.69315 train_acc= 0.00028 time= 1.63298
Epoch: 0172 train_loss= 0.69315 train_acc= 0.00028 time= 1.64134
Epoch: 0173 train_loss= 0.69315 train_acc= 0.00028 time= 1.64086
Epoch: 0174 train_loss= 0.69315 train_acc= 0.00028 time= 1.64255
Epoch: 0175 train_loss= 0.69315 train_acc= 0.00028 time= 1.64205
Epoch: 0176 train_loss= 0.69315 train_acc= 0.00028 time= 1.64589
Epoch: 0177 train_loss= 0.69315 train_acc= 0.00028 time= 1.65407
Epoch: 0178 train_loss= 0.69315 train_acc= 0.00028 time= 1.62576
Epoch: 0179 train_loss= 0.69315 train_acc= 0.00028 time= 1.62177
Epoch: 0180 train_loss= 0.69315 train_acc= 0.00028 time= 1.65665
Epoch: 0181 train_loss= 0.69315 train_acc= 0.00028 time= 1.63862
Epoch: 0182 train_loss= 0.69315 train_acc= 0.00028 time= 1.65481
Epoch: 0183 train_loss= 0.69315 train_acc= 0.00028 time= 1.63916
Epoch: 0184 train_loss= 0.69315 train_acc= 0.00028 time= 1.64337
Epoch: 0185 train_loss= 0.69315 train_acc= 0.00028 time= 1.62929
Epoch: 0186 train_loss= 0.69315 train_acc= 0.00028 time= 1.62466
Epoch: 0187 train_loss= 0.69315 train_acc= 0.00028 time= 1.62960
Epoch: 0188 train_loss= 0.69315 train_acc= 0.00028 time= 1.63677
Epoch: 0189 train_loss= 0.69315 train_acc= 0.00028 time= 1.62835
Epoch: 0190 train_loss= 0.69315 train_acc= 0.00028 time= 1.66478
Epoch: 0191 train_loss= 0.69315 train_acc= 0.00028 time= 1.64559
Epoch: 0192 train_loss= 0.69315 train_acc= 0.00028 time= 1.65658
Epoch: 0193 train_loss= 0.69315 train_acc= 0.00028 time= 1.62369
Epoch: 0194 train_loss= 0.69315 train_acc= 0.00028 time= 1.65006
Epoch: 0195 train_loss= 0.69315 train_acc= 0.00028 time= 1.64257
Epoch: 0196 train_loss= 0.69315 train_acc= 0.00028 time= 1.63976
Epoch: 0197 train_loss= 0.69315 train_acc= 0.00028 time= 1.64499
Epoch: 0198 train_loss= 0.69315 train_acc= 0.00028 time= 1.65776
Epoch: 0199 train_loss= 0.69315 train_acc= 0.00028 time= 1.63430
Epoch: 0200 train_loss= 0.69315 train_acc= 0.00028 time= 1.65359
Epoch: 0201 train_loss= 0.69315 train_acc= 0.00028 time= 1.66947
Epoch: 0202 train_loss= 0.69315 train_acc= 0.00028 time= 1.64628
Epoch: 0203 train_loss= 0.69315 train_acc= 0.00028 time= 1.63706
Epoch: 0204 train_loss= 0.69315 train_acc= 0.00028 time= 1.65306
Epoch: 0205 train_loss= 0.69315 train_acc= 0.00028 time= 1.65446
Epoch: 0206 train_loss= 0.69315 train_acc= 0.00028 time= 1.62827
Epoch: 0207 train_loss= 0.69315 train_acc= 0.00028 time= 1.64311
Epoch: 0208 train_loss= 0.69315 train_acc= 0.00028 time= 1.63647
Epoch: 0209 train_loss= 0.69315 train_acc= 0.00028 time= 1.63720
Epoch: 0210 train_loss= 0.69315 train_acc= 0.00028 time= 1.64631
Epoch: 0211 train_loss= 0.69315 train_acc= 0.00028 time= 1.62930
Epoch: 0212 train_loss= 0.69315 train_acc= 0.00028 time= 1.62972
Epoch: 0213 train_loss= 0.69315 train_acc= 0.00028 time= 1.65297
Epoch: 0214 train_loss= 0.69315 train_acc= 0.00028 time= 1.62240
Epoch: 0215 train_loss= 0.69315 train_acc= 0.00028 time= 1.64464
Epoch: 0216 train_loss= 0.69315 train_acc= 0.00028 time= 1.64409
Epoch: 0217 train_loss= 0.69315 train_acc= 0.00028 time= 1.65031
Epoch: 0218 train_loss= 0.69315 train_acc= 0.00028 time= 1.62709
Epoch: 0219 train_loss= 0.69315 train_acc= 0.00028 time= 1.64397
Epoch: 0220 train_loss= 0.69315 train_acc= 0.00028 time= 1.63834
Epoch: 0221 train_loss= 0.69315 train_acc= 0.00028 time= 1.62354
Epoch: 0222 train_loss= 0.69315 train_acc= 0.00028 time= 1.63669
Epoch: 0223 train_loss= 0.69315 train_acc= 0.00028 time= 1.64276
Epoch: 0224 train_loss= 0.69315 train_acc= 0.00028 time= 1.65114
Epoch: 0225 train_loss= 0.69315 train_acc= 0.00028 time= 1.63006
Epoch: 0226 train_loss= 0.69315 train_acc= 0.00028 time= 1.64796
Epoch: 0227 train_loss= 0.69315 train_acc= 0.00028 time= 1.64528
Epoch: 0228 train_loss= 0.69315 train_acc= 0.00028 time= 1.62987
Epoch: 0229 train_loss= 0.69315 train_acc= 0.00028 time= 1.63542
Epoch: 0230 train_loss= 0.69315 train_acc= 0.00028 time= 1.64426
Epoch: 0231 train_loss= 0.69315 train_acc= 0.00028 time= 1.65515
Epoch: 0232 train_loss= 0.69315 train_acc= 0.00028 time= 1.65370
Epoch: 0233 train_loss= 0.69315 train_acc= 0.00028 time= 1.62661
Epoch: 0234 train_loss= 0.69315 train_acc= 0.00028 time= 1.65890
Epoch: 0235 train_loss= 0.69315 train_acc= 0.00028 time= 1.65488
Epoch: 0236 train_loss= 0.69315 train_acc= 0.00028 time= 1.63322
Epoch: 0237 train_loss= 0.69315 train_acc= 0.00028 time= 1.64382
Epoch: 0238 train_loss= 0.69315 train_acc= 0.00028 time= 1.63060
Epoch: 0239 train_loss= 0.69315 train_acc= 0.00028 time= 1.64064
Epoch: 0240 train_loss= 0.69315 train_acc= 0.00028 time= 1.66913
Epoch: 0241 train_loss= 0.69315 train_acc= 0.00028 time= 1.63177
Epoch: 0242 train_loss= 0.69315 train_acc= 0.00028 time= 1.64054
Epoch: 0243 train_loss= 0.69315 train_acc= 0.00028 time= 1.63015
Epoch: 0244 train_loss= 0.69315 train_acc= 0.00028 time= 1.62365
Epoch: 0245 train_loss= 0.69315 train_acc= 0.00028 time= 1.62706
Epoch: 0246 train_loss= 0.69315 train_acc= 0.00028 time= 1.64428
Epoch: 0247 train_loss= 0.69315 train_acc= 0.00028 time= 1.65063
Epoch: 0248 train_loss= 0.69315 train_acc= 0.00028 time= 1.62756
Epoch: 0249 train_loss= 0.69315 train_acc= 0.00028 time= 1.62957
Epoch: 0250 train_loss= 0.69315 train_acc= 0.00028 time= 1.62373
Epoch: 0251 train_loss= 0.69315 train_acc= 0.00028 time= 1.64537
Epoch: 0252 train_loss= 0.69315 train_acc= 0.00028 time= 1.62771
Epoch: 0253 train_loss= 0.69315 train_acc= 0.00028 time= 1.62932
Epoch: 0254 train_loss= 0.69315 train_acc= 0.00028 time= 1.63246
Epoch: 0255 train_loss= 0.69315 train_acc= 0.00028 time= 1.64243
Epoch: 0256 train_loss= 0.69315 train_acc= 0.00028 time= 1.62280
Epoch: 0257 train_loss= 0.69315 train_acc= 0.00028 time= 1.62617
Epoch: 0258 train_loss= 0.69315 train_acc= 0.00028 time= 1.63494
Epoch: 0259 train_loss= 0.69315 train_acc= 0.00028 time= 1.64147
Epoch: 0260 train_loss= 0.69315 train_acc= 0.00028 time= 1.63440
Epoch: 0261 train_loss= 0.69315 train_acc= 0.00028 time= 1.63745
Epoch: 0262 train_loss= 0.69315 train_acc= 0.00028 time= 1.65510
Epoch: 0263 train_loss= 0.69315 train_acc= 0.00028 time= 1.65774
Epoch: 0264 train_loss= 0.69315 train_acc= 0.00028 time= 1.63771
Epoch: 0265 train_loss= 0.69315 train_acc= 0.00028 time= 1.65247
Epoch: 0266 train_loss= 0.69315 train_acc= 0.00028 time= 1.64309
Epoch: 0267 train_loss= 0.69315 train_acc= 0.00028 time= 1.63880
Epoch: 0268 train_loss= 0.69315 train_acc= 0.00028 time= 1.64198
Epoch: 0269 train_loss= 0.69315 train_acc= 0.00028 time= 1.64820
Epoch: 0270 train_loss= 0.69315 train_acc= 0.00028 time= 1.65971
Epoch: 0271 train_loss= 0.69315 train_acc= 0.00028 time= 1.63958
Epoch: 0272 train_loss= 0.69315 train_acc= 0.00028 time= 1.62666
Epoch: 0273 train_loss= 0.69315 train_acc= 0.00028 time= 1.62705
Epoch: 0274 train_loss= 0.69315 train_acc= 0.00028 time= 1.63633
Epoch: 0275 train_loss= 0.69315 train_acc= 0.00028 time= 1.63606
Epoch: 0276 train_loss= 0.69315 train_acc= 0.00028 time= 1.63867
Epoch: 0277 train_loss= 0.69315 train_acc= 0.00028 time= 1.62740
Epoch: 0278 train_loss= 0.69315 train_acc= 0.00028 time= 1.63322
Epoch: 0279 train_loss= 0.69315 train_acc= 0.00028 time= 1.63378
Epoch: 0280 train_loss= 0.69315 train_acc= 0.00028 time= 1.64136
Epoch: 0281 train_loss= 0.69315 train_acc= 0.00028 time= 1.64547
Epoch: 0282 train_loss= 0.69315 train_acc= 0.00028 time= 1.64651
Epoch: 0283 train_loss= 0.69315 train_acc= 0.00028 time= 1.62512
Epoch: 0284 train_loss= 0.69315 train_acc= 0.00028 time= 1.67069
Epoch: 0285 train_loss= 0.69315 train_acc= 0.00028 time= 1.62996
Epoch: 0286 train_loss= 0.69315 train_acc= 0.00028 time= 1.63395
Epoch: 0287 train_loss= 0.69315 train_acc= 0.00028 time= 1.64619
Epoch: 0288 train_loss= 0.69315 train_acc= 0.00028 time= 1.64040
Epoch: 0289 train_loss= 0.69315 train_acc= 0.00028 time= 1.63946
Epoch: 0290 train_loss= 0.69315 train_acc= 0.00028 time= 1.63351
Epoch: 0291 train_loss= 0.69315 train_acc= 0.00028 time= 1.64946
Epoch: 0292 train_loss= 0.69315 train_acc= 0.00028 time= 1.63171
Epoch: 0293 train_loss= 0.69315 train_acc= 0.00028 time= 1.62106
Epoch: 0294 train_loss= 0.69315 train_acc= 0.00028 time= 1.65224
Epoch: 0295 train_loss= 0.69315 train_acc= 0.00028 time= 1.61788
Epoch: 0296 train_loss= 0.69315 train_acc= 0.00028 time= 1.64402
Epoch: 0297 train_loss= 0.69315 train_acc= 0.00028 time= 1.62641
Epoch: 0298 train_loss= 0.69315 train_acc= 0.00028 time= 1.64033
Epoch: 0299 train_loss= 0.69315 train_acc= 0.00028 time= 1.63882
Epoch: 0300 train_loss= 0.69315 train_acc= 0.00028 time= 1.62663
Optimization Finished!
Model: [1.4477420070054103,2.0050627824730065e-13]
Epoch: 0001 train_loss= 50.86500 train_acc= 0.00028 time= 1.72474
Epoch: 0002 train_loss= 276.97424 train_acc= 0.00028 time= 1.65880
Epoch: 0003 train_loss= 22.47624 train_acc= 0.00028 time= 1.65657
Epoch: 0004 train_loss= 0.69315 train_acc= 0.00028 time= 1.64198
Epoch: 0005 train_loss= 0.69315 train_acc= 0.00028 time= 1.65419
Epoch: 0006 train_loss= 0.69315 train_acc= 0.00028 time= 1.65998
Epoch: 0007 train_loss= 0.69315 train_acc= 0.00028 time= 1.64570
Epoch: 0008 train_loss= 0.69315 train_acc= 0.00028 time= 1.67883
Epoch: 0009 train_loss= 0.69315 train_acc= 0.00028 time= 1.67061
Epoch: 0010 train_loss= 0.69315 train_acc= 0.00028 time= 1.66837
Epoch: 0011 train_loss= 0.69315 train_acc= 0.00028 time= 1.64212
Epoch: 0012 train_loss= 0.69315 train_acc= 0.00028 time= 1.65385
Epoch: 0013 train_loss= 0.69315 train_acc= 0.00028 time= 1.67580
Epoch: 0014 train_loss= 0.69315 train_acc= 0.00028 time= 1.66983
Epoch: 0015 train_loss= 0.69315 train_acc= 0.00028 time= 1.65112
Epoch: 0016 train_loss= 0.69315 train_acc= 0.00028 time= 1.65936
Epoch: 0017 train_loss= 0.69315 train_acc= 0.00028 time= 1.63593
Epoch: 0018 train_loss= 0.69315 train_acc= 0.00028 time= 1.66381
Epoch: 0019 train_loss= 0.69315 train_acc= 0.00028 time= 1.64795
Epoch: 0020 train_loss= 0.69315 train_acc= 0.00028 time= 1.66175
Epoch: 0021 train_loss= 0.69315 train_acc= 0.00028 time= 1.66913
Epoch: 0022 train_loss= 0.69315 train_acc= 0.00028 time= 1.66114
Epoch: 0023 train_loss= 0.69315 train_acc= 0.00028 time= 1.64983
Epoch: 0024 train_loss= 0.69315 train_acc= 0.00028 time= 1.70505
Epoch: 0025 train_loss= 0.69315 train_acc= 0.00028 time= 1.64266
Epoch: 0026 train_loss= 0.69315 train_acc= 0.00028 time= 1.64335
Epoch: 0027 train_loss= 0.69315 train_acc= 0.00028 time= 1.64148
Epoch: 0028 train_loss= 0.69315 train_acc= 0.00028 time= 1.63689
Epoch: 0029 train_loss= 0.69315 train_acc= 0.00028 time= 1.69207
Epoch: 0030 train_loss= 0.69315 train_acc= 0.00028 time= 1.64322
Epoch: 0031 train_loss= 0.69315 train_acc= 0.00028 time= 1.65602
Epoch: 0032 train_loss= 0.69315 train_acc= 0.00028 time= 1.66613
Epoch: 0033 train_loss= 0.69315 train_acc= 0.00028 time= 1.65268
Epoch: 0034 train_loss= 0.69315 train_acc= 0.00028 time= 1.65326
Epoch: 0035 train_loss= 0.69315 train_acc= 0.00028 time= 1.67110
Epoch: 0036 train_loss= 0.69315 train_acc= 0.00028 time= 1.65628
Epoch: 0037 train_loss= 0.69315 train_acc= 0.00028 time= 1.64074
Epoch: 0038 train_loss= 0.69315 train_acc= 0.00028 time= 1.64472
Epoch: 0039 train_loss= 0.69315 train_acc= 0.00028 time= 1.64308
Epoch: 0040 train_loss= 0.69315 train_acc= 0.00028 time= 1.65449
Epoch: 0041 train_loss= 0.69315 train_acc= 0.00028 time= 1.64275
Epoch: 0042 train_loss= 0.69315 train_acc= 0.00028 time= 1.63782
Epoch: 0043 train_loss= 0.69315 train_acc= 0.00028 time= 1.65052
Epoch: 0044 train_loss= 0.69315 train_acc= 0.00028 time= 1.67941
Epoch: 0045 train_loss= 0.69315 train_acc= 0.00028 time= 1.64489
Epoch: 0046 train_loss= 0.69315 train_acc= 0.00028 time= 1.64639
Epoch: 0047 train_loss= 0.69315 train_acc= 0.00028 time= 1.67591
Epoch: 0048 train_loss= 0.69315 train_acc= 0.00028 time= 1.63747
Epoch: 0049 train_loss= 0.69315 train_acc= 0.00028 time= 1.65614
Epoch: 0050 train_loss= 0.69315 train_acc= 0.00028 time= 1.64931
Epoch: 0051 train_loss= 0.69315 train_acc= 0.00028 time= 1.66390
Epoch: 0052 train_loss= 0.69315 train_acc= 0.00028 time= 1.65131
Epoch: 0053 train_loss= 0.69315 train_acc= 0.00028 time= 1.63676
Epoch: 0054 train_loss= 0.69315 train_acc= 0.00028 time= 1.65766
Epoch: 0055 train_loss= 0.69315 train_acc= 0.00028 time= 1.64965
Epoch: 0056 train_loss= 0.69315 train_acc= 0.00028 time= 1.64491
Epoch: 0057 train_loss= 0.69315 train_acc= 0.00028 time= 1.64308
Epoch: 0058 train_loss= 0.69315 train_acc= 0.00028 time= 1.64783
Epoch: 0059 train_loss= 0.69315 train_acc= 0.00028 time= 1.63880
Epoch: 0060 train_loss= 0.69315 train_acc= 0.00028 time= 1.64445
Epoch: 0061 train_loss= 0.69315 train_acc= 0.00028 time= 1.64752
Epoch: 0062 train_loss= 0.69315 train_acc= 0.00028 time= 1.65399
Epoch: 0063 train_loss= 0.69315 train_acc= 0.00028 time= 1.64990
Epoch: 0064 train_loss= 0.69315 train_acc= 0.00028 time= 1.64119
Epoch: 0065 train_loss= 0.69315 train_acc= 0.00028 time= 1.64956
Epoch: 0066 train_loss= 0.69315 train_acc= 0.00028 time= 1.64479
Epoch: 0067 train_loss= 0.69315 train_acc= 0.00028 time= 1.64033
Epoch: 0068 train_loss= 0.69315 train_acc= 0.00028 time= 1.64617
Epoch: 0069 train_loss= 0.69315 train_acc= 0.00028 time= 1.63345
Epoch: 0070 train_loss= 0.69315 train_acc= 0.00028 time= 1.65377
Epoch: 0071 train_loss= 0.69315 train_acc= 0.00028 time= 1.66199
Epoch: 0072 train_loss= 0.69315 train_acc= 0.00028 time= 1.65643
Epoch: 0073 train_loss= 0.69315 train_acc= 0.00028 time= 1.65184
Epoch: 0074 train_loss= 0.69315 train_acc= 0.00028 time= 1.64216
Epoch: 0075 train_loss= 0.69315 train_acc= 0.00028 time= 1.64442
Epoch: 0076 train_loss= 0.69315 train_acc= 0.00028 time= 1.66405
Epoch: 0077 train_loss= 0.69315 train_acc= 0.00028 time= 1.63840
Epoch: 0078 train_loss= 0.69315 train_acc= 0.00028 time= 1.67979
Epoch: 0079 train_loss= 0.69315 train_acc= 0.00028 time= 1.66022
Epoch: 0080 train_loss= 0.69315 train_acc= 0.00028 time= 1.64339
Epoch: 0081 train_loss= 0.69315 train_acc= 0.00028 time= 1.65511
Epoch: 0082 train_loss= 0.69315 train_acc= 0.00028 time= 1.64190
Epoch: 0083 train_loss= 0.69315 train_acc= 0.00028 time= 1.63899
Epoch: 0084 train_loss= 0.69315 train_acc= 0.00028 time= 1.64472
Epoch: 0085 train_loss= 0.69315 train_acc= 0.00028 time= 1.65087
Epoch: 0086 train_loss= 0.69315 train_acc= 0.00028 time= 1.64994
Epoch: 0087 train_loss= 0.69315 train_acc= 0.00028 time= 1.64853
Epoch: 0088 train_loss= 0.69315 train_acc= 0.00028 time= 1.64843
Epoch: 0089 train_loss= 0.69315 train_acc= 0.00028 time= 1.64960
Epoch: 0090 train_loss= 0.69315 train_acc= 0.00028 time= 1.64044
Epoch: 0091 train_loss= 0.69315 train_acc= 0.00028 time= 1.63889
Epoch: 0092 train_loss= 0.69315 train_acc= 0.00028 time= 1.64693
Epoch: 0093 train_loss= 0.69315 train_acc= 0.00028 time= 1.64958
Epoch: 0094 train_loss= 0.69315 train_acc= 0.00028 time= 1.64567
Epoch: 0095 train_loss= 0.69315 train_acc= 0.00028 time= 1.64148
Epoch: 0096 train_loss= 0.69315 train_acc= 0.00028 time= 1.65479
Epoch: 0097 train_loss= 0.69315 train_acc= 0.00028 time= 1.65560
Epoch: 0098 train_loss= 0.69315 train_acc= 0.00028 time= 1.66500
Epoch: 0099 train_loss= 0.69315 train_acc= 0.00028 time= 1.66169
Epoch: 0100 train_loss= 0.69315 train_acc= 0.00028 time= 1.64917
Epoch: 0101 train_loss= 0.69315 train_acc= 0.00028 time= 1.63710
Epoch: 0102 train_loss= 0.69315 train_acc= 0.00028 time= 1.63929
Epoch: 0103 train_loss= 0.69315 train_acc= 0.00028 time= 1.63801
Epoch: 0104 train_loss= 0.69315 train_acc= 0.00028 time= 1.64200
Epoch: 0105 train_loss= 0.69315 train_acc= 0.00028 time= 1.63128
Epoch: 0106 train_loss= 0.69315 train_acc= 0.00028 time= 1.64868
Epoch: 0107 train_loss= 0.69315 train_acc= 0.00028 time= 1.63977
Epoch: 0108 train_loss= 0.69315 train_acc= 0.00028 time= 1.68154
Epoch: 0109 train_loss= 0.69315 train_acc= 0.00028 time= 1.64566
Epoch: 0110 train_loss= 0.69315 train_acc= 0.00028 time= 1.64261
Epoch: 0111 train_loss= 0.69315 train_acc= 0.00028 time= 1.64641
Epoch: 0112 train_loss= 0.69315 train_acc= 0.00028 time= 1.70325
Epoch: 0113 train_loss= 0.69315 train_acc= 0.00028 time= 1.63854
Epoch: 0114 train_loss= 0.69315 train_acc= 0.00028 time= 1.65386
Epoch: 0115 train_loss= 0.69315 train_acc= 0.00028 time= 1.63990
Epoch: 0116 train_loss= 0.69315 train_acc= 0.00028 time= 1.64860
Epoch: 0117 train_loss= 0.69315 train_acc= 0.00028 time= 1.64510
Epoch: 0118 train_loss= 0.69315 train_acc= 0.00028 time= 1.65047
Epoch: 0119 train_loss= 0.69315 train_acc= 0.00028 time= 1.65996
Epoch: 0120 train_loss= 0.69315 train_acc= 0.00028 time= 1.64452
Epoch: 0121 train_loss= 0.69315 train_acc= 0.00028 time= 1.62660
Epoch: 0122 train_loss= 0.69315 train_acc= 0.00028 time= 1.65832
Epoch: 0123 train_loss= 0.69315 train_acc= 0.00028 time= 1.65347
Epoch: 0124 train_loss= 0.69315 train_acc= 0.00028 time= 1.65742
Epoch: 0125 train_loss= 0.69315 train_acc= 0.00028 time= 1.66121
Epoch: 0126 train_loss= 0.69315 train_acc= 0.00028 time= 1.65880
Epoch: 0127 train_loss= 0.69315 train_acc= 0.00028 time= 1.66465
Epoch: 0128 train_loss= 0.69315 train_acc= 0.00028 time= 1.67051
Epoch: 0129 train_loss= 0.69315 train_acc= 0.00028 time= 1.64243
Epoch: 0130 train_loss= 0.69315 train_acc= 0.00028 time= 1.65298
Epoch: 0131 train_loss= 0.69315 train_acc= 0.00028 time= 1.65878
Epoch: 0132 train_loss= 0.69315 train_acc= 0.00028 time= 1.68469
Epoch: 0133 train_loss= 0.69315 train_acc= 0.00028 time= 1.65504
Epoch: 0134 train_loss= 0.69315 train_acc= 0.00028 time= 1.66022
Epoch: 0135 train_loss= 0.69315 train_acc= 0.00028 time= 1.63292
Epoch: 0136 train_loss= 0.69315 train_acc= 0.00028 time= 1.63659
Epoch: 0137 train_loss= 0.69315 train_acc= 0.00028 time= 1.64101
Epoch: 0138 train_loss= 0.69315 train_acc= 0.00028 time= 1.64943
Epoch: 0139 train_loss= 0.69315 train_acc= 0.00028 time= 1.62936
Epoch: 0140 train_loss= 0.69315 train_acc= 0.00028 time= 1.66923
Epoch: 0141 train_loss= 0.69315 train_acc= 0.00028 time= 1.64042
Epoch: 0142 train_loss= 0.69315 train_acc= 0.00028 time= 1.63855
Epoch: 0143 train_loss= 0.69315 train_acc= 0.00028 time= 1.65804
Epoch: 0144 train_loss= 0.69315 train_acc= 0.00028 time= 1.64102
Epoch: 0145 train_loss= 0.69315 train_acc= 0.00028 time= 1.65215
Epoch: 0146 train_loss= 0.69315 train_acc= 0.00028 time= 1.64536
Epoch: 0147 train_loss= 0.69315 train_acc= 0.00028 time= 1.64384
Epoch: 0148 train_loss= 0.69315 train_acc= 0.00028 time= 1.63086
Epoch: 0149 train_loss= 0.69315 train_acc= 0.00028 time= 1.64812
Epoch: 0150 train_loss= 0.69315 train_acc= 0.00028 time= 1.63679
Epoch: 0151 train_loss= 0.69315 train_acc= 0.00028 time= 1.64125
Epoch: 0152 train_loss= 0.69315 train_acc= 0.00028 time= 1.64778
Epoch: 0153 train_loss= 0.69315 train_acc= 0.00028 time= 1.63555
Epoch: 0154 train_loss= 0.69315 train_acc= 0.00028 time= 1.67265
Epoch: 0155 train_loss= 0.69315 train_acc= 0.00028 time= 1.63953
Epoch: 0156 train_loss= 0.69315 train_acc= 0.00028 time= 1.64879
Epoch: 0157 train_loss= 0.69315 train_acc= 0.00028 time= 1.63179
Epoch: 0158 train_loss= 0.69315 train_acc= 0.00028 time= 1.63843
Epoch: 0159 train_loss= 0.69315 train_acc= 0.00028 time= 1.63613
Epoch: 0160 train_loss= 0.69315 train_acc= 0.00028 time= 1.63974
Epoch: 0161 train_loss= 0.69315 train_acc= 0.00028 time= 1.63344
Epoch: 0162 train_loss= 0.69315 train_acc= 0.00028 time= 1.64603
Epoch: 0163 train_loss= 0.69315 train_acc= 0.00028 time= 1.64264
Epoch: 0164 train_loss= 0.69315 train_acc= 0.00028 time= 1.64746
Epoch: 0165 train_loss= 0.69315 train_acc= 0.00028 time= 1.65011
Epoch: 0166 train_loss= 0.69315 train_acc= 0.00028 time= 1.64502
Epoch: 0167 train_loss= 0.69315 train_acc= 0.00028 time= 1.65804
Epoch: 0168 train_loss= 0.69315 train_acc= 0.00028 time= 1.63441
Epoch: 0169 train_loss= 0.69315 train_acc= 0.00028 time= 1.66219
Epoch: 0170 train_loss= 0.69315 train_acc= 0.00028 time= 1.64090
Epoch: 0171 train_loss= 0.69315 train_acc= 0.00028 time= 1.63966
Epoch: 0172 train_loss= 0.69315 train_acc= 0.00028 time= 1.64065
Epoch: 0173 train_loss= 0.69315 train_acc= 0.00028 time= 1.65305
Epoch: 0174 train_loss= 0.69315 train_acc= 0.00028 time= 1.66646
Epoch: 0175 train_loss= 0.69315 train_acc= 0.00028 time= 1.65104
Epoch: 0176 train_loss= 0.69315 train_acc= 0.00028 time= 1.64537
Epoch: 0177 train_loss= 0.69315 train_acc= 0.00028 time= 1.66883
Epoch: 0178 train_loss= 0.69315 train_acc= 0.00028 time= 1.64449
Epoch: 0179 train_loss= 0.69315 train_acc= 0.00028 time= 1.65602
Epoch: 0180 train_loss= 0.69315 train_acc= 0.00028 time= 1.63838
Epoch: 0181 train_loss= 0.69315 train_acc= 0.00028 time= 1.64501
Epoch: 0182 train_loss= 0.69315 train_acc= 0.00028 time= 1.63729
Epoch: 0183 train_loss= 0.69315 train_acc= 0.00028 time= 1.64484
Epoch: 0184 train_loss= 0.69315 train_acc= 0.00028 time= 1.64917
Epoch: 0185 train_loss= 0.69315 train_acc= 0.00028 time= 1.67509
Epoch: 0186 train_loss= 0.69315 train_acc= 0.00028 time= 1.63690
Epoch: 0187 train_loss= 0.69315 train_acc= 0.00028 time= 1.63629
Epoch: 0188 train_loss= 0.69315 train_acc= 0.00028 time= 1.65734
Epoch: 0189 train_loss= 0.69315 train_acc= 0.00028 time= 1.66610
Epoch: 0190 train_loss= 0.69315 train_acc= 0.00028 time= 1.64189
Epoch: 0191 train_loss= 0.69315 train_acc= 0.00028 time= 1.64706
Epoch: 0192 train_loss= 0.69315 train_acc= 0.00028 time= 1.64847
Epoch: 0193 train_loss= 0.69315 train_acc= 0.00028 time= 1.65411
Epoch: 0194 train_loss= 0.69315 train_acc= 0.00028 time= 1.65506
Epoch: 0195 train_loss= 0.69315 train_acc= 0.00028 time= 1.63355
Epoch: 0196 train_loss= 0.69315 train_acc= 0.00028 time= 1.63797
Epoch: 0197 train_loss= 0.69315 train_acc= 0.00028 time= 1.64564
Epoch: 0198 train_loss= 0.69315 train_acc= 0.00028 time= 1.63893
Epoch: 0199 train_loss= 0.69315 train_acc= 0.00028 time= 1.66698
Epoch: 0200 train_loss= 0.69315 train_acc= 0.00028 time= 1.64396
Epoch: 0201 train_loss= 0.69315 train_acc= 0.00028 time= 1.69175
Epoch: 0202 train_loss= 0.69315 train_acc= 0.00028 time= 1.65783
Epoch: 0203 train_loss= 0.69315 train_acc= 0.00028 time= 1.64620
Epoch: 0204 train_loss= 0.69315 train_acc= 0.00028 time= 1.64563
Epoch: 0205 train_loss= 0.69315 train_acc= 0.00028 time= 1.66101
Epoch: 0206 train_loss= 0.69315 train_acc= 0.00028 time= 1.65947
Epoch: 0207 train_loss= 0.69315 train_acc= 0.00028 time= 1.64924
Epoch: 0208 train_loss= 0.69315 train_acc= 0.00028 time= 1.64561
Epoch: 0209 train_loss= 0.69315 train_acc= 0.00028 time= 1.65620
Epoch: 0210 train_loss= 0.69315 train_acc= 0.00028 time= 1.66026
Epoch: 0211 train_loss= 0.69315 train_acc= 0.00028 time= 1.64982
Epoch: 0212 train_loss= 0.69315 train_acc= 0.00028 time= 1.64099
Epoch: 0213 train_loss= 0.69315 train_acc= 0.00028 time= 1.63653
Epoch: 0214 train_loss= 0.69315 train_acc= 0.00028 time= 1.64031
Epoch: 0215 train_loss= 0.69315 train_acc= 0.00028 time= 1.63769
Epoch: 0216 train_loss= 0.69315 train_acc= 0.00028 time= 1.63336
Epoch: 0217 train_loss= 0.69315 train_acc= 0.00028 time= 1.65130
Epoch: 0218 train_loss= 0.69315 train_acc= 0.00028 time= 1.64115
Epoch: 0219 train_loss= 0.69315 train_acc= 0.00028 time= 1.65662
Epoch: 0220 train_loss= 0.69315 train_acc= 0.00028 time= 1.63031
Epoch: 0221 train_loss= 0.69315 train_acc= 0.00028 time= 1.64755
Epoch: 0222 train_loss= 0.69315 train_acc= 0.00028 time= 1.64479
Epoch: 0223 train_loss= 0.69315 train_acc= 0.00028 time= 1.65427
Epoch: 0224 train_loss= 0.69315 train_acc= 0.00028 time= 1.63560
Epoch: 0225 train_loss= 0.69315 train_acc= 0.00028 time= 1.64454
Epoch: 0226 train_loss= 0.69315 train_acc= 0.00028 time= 1.64217
Epoch: 0227 train_loss= 0.69315 train_acc= 0.00028 time= 1.64484
Epoch: 0228 train_loss= 0.69315 train_acc= 0.00028 time= 1.65372
Epoch: 0229 train_loss= 0.69315 train_acc= 0.00028 time= 1.64208
Epoch: 0230 train_loss= 0.69315 train_acc= 0.00028 time= 1.63366
Epoch: 0231 train_loss= 0.69315 train_acc= 0.00028 time= 1.64111
Epoch: 0232 train_loss= 0.69315 train_acc= 0.00028 time= 1.64545
Epoch: 0233 train_loss= 0.69315 train_acc= 0.00028 time= 1.65598
Epoch: 0234 train_loss= 0.69315 train_acc= 0.00028 time= 1.64513
Epoch: 0235 train_loss= 0.69315 train_acc= 0.00028 time= 1.63522
Epoch: 0236 train_loss= 0.69315 train_acc= 0.00028 time= 1.64368
Epoch: 0237 train_loss= 0.69315 train_acc= 0.00028 time= 1.64544
Epoch: 0238 train_loss= 0.69315 train_acc= 0.00028 time= 1.62933
Epoch: 0239 train_loss= 0.69315 train_acc= 0.00028 time= 1.63178
Epoch: 0240 train_loss= 0.69315 train_acc= 0.00028 time= 1.65117
Epoch: 0241 train_loss= 0.69315 train_acc= 0.00028 time= 1.65182
Epoch: 0242 train_loss= 0.69315 train_acc= 0.00028 time= 1.65228
Epoch: 0243 train_loss= 0.69315 train_acc= 0.00028 time= 1.65024
Epoch: 0244 train_loss= 0.69315 train_acc= 0.00028 time= 1.64633
Epoch: 0245 train_loss= 0.69315 train_acc= 0.00028 time= 1.64590
Epoch: 0246 train_loss= 0.69315 train_acc= 0.00028 time= 1.67456
Epoch: 0247 train_loss= 0.69315 train_acc= 0.00028 time= 1.65807
Epoch: 0248 train_loss= 0.69315 train_acc= 0.00028 time= 1.63657
Epoch: 0249 train_loss= 0.69315 train_acc= 0.00028 time= 1.64887
Epoch: 0250 train_loss= 0.69315 train_acc= 0.00028 time= 1.64210
Epoch: 0251 train_loss= 0.69315 train_acc= 0.00028 time= 1.64745
Epoch: 0252 train_loss= 0.69315 train_acc= 0.00028 time= 1.66507
Epoch: 0253 train_loss= 0.69315 train_acc= 0.00028 time= 1.65517
Epoch: 0254 train_loss= 0.69315 train_acc= 0.00028 time= 1.65647
Epoch: 0255 train_loss= 0.69315 train_acc= 0.00028 time= 1.64562
Epoch: 0256 train_loss= 0.69315 train_acc= 0.00028 time= 1.64185
Epoch: 0257 train_loss= 0.69315 train_acc= 0.00028 time= 1.63965
Epoch: 0258 train_loss= 0.69315 train_acc= 0.00028 time= 1.63988
Epoch: 0259 train_loss= 0.69315 train_acc= 0.00028 time= 1.64564
Epoch: 0260 train_loss= 0.69315 train_acc= 0.00028 time= 1.64332
Epoch: 0261 train_loss= 0.69315 train_acc= 0.00028 time= 1.64207
Epoch: 0262 train_loss= 0.69315 train_acc= 0.00028 time= 1.65736
Epoch: 0263 train_loss= 0.69315 train_acc= 0.00028 time= 1.66122
Epoch: 0264 train_loss= 0.69315 train_acc= 0.00028 time= 1.64130
Epoch: 0265 train_loss= 0.69315 train_acc= 0.00028 time= 1.64086
Epoch: 0266 train_loss= 0.69315 train_acc= 0.00028 time= 1.66233
Epoch: 0267 train_loss= 0.69315 train_acc= 0.00028 time= 1.63491
Epoch: 0268 train_loss= 0.69315 train_acc= 0.00028 time= 1.64449
Epoch: 0269 train_loss= 0.69315 train_acc= 0.00028 time= 1.65856
Epoch: 0270 train_loss= 0.69315 train_acc= 0.00028 time= 1.66691
Epoch: 0271 train_loss= 0.69315 train_acc= 0.00028 time= 1.65356
Epoch: 0272 train_loss= 0.69315 train_acc= 0.00028 time= 1.65464
Epoch: 0273 train_loss= 0.69315 train_acc= 0.00028 time= 1.65631
Epoch: 0274 train_loss= 0.69315 train_acc= 0.00028 time= 1.64100
Epoch: 0275 train_loss= 0.69315 train_acc= 0.00028 time= 1.63515
Epoch: 0276 train_loss= 0.69315 train_acc= 0.00028 time= 1.63241
Epoch: 0277 train_loss= 0.69315 train_acc= 0.00028 time= 1.63883
Epoch: 0278 train_loss= 0.69315 train_acc= 0.00028 time= 1.66387
Epoch: 0279 train_loss= 0.69315 train_acc= 0.00028 time= 1.63857
Epoch: 0280 train_loss= 0.69315 train_acc= 0.00028 time= 1.64028
Epoch: 0281 train_loss= 0.69315 train_acc= 0.00028 time= 1.65044
Epoch: 0282 train_loss= 0.69315 train_acc= 0.00028 time= 1.64223
Epoch: 0283 train_loss= 0.69315 train_acc= 0.00028 time= 1.69490
Epoch: 0284 train_loss= 0.69315 train_acc= 0.00028 time= 1.64390
Epoch: 0285 train_loss= 0.69315 train_acc= 0.00028 time= 1.65260
Epoch: 0286 train_loss= 0.69315 train_acc= 0.00028 time= 1.65432
Epoch: 0287 train_loss= 0.69315 train_acc= 0.00028 time= 1.64206
Epoch: 0288 train_loss= 0.69315 train_acc= 0.00028 time= 1.65295
Epoch: 0289 train_loss= 0.69315 train_acc= 0.00028 time= 1.64417
Epoch: 0290 train_loss= 0.69315 train_acc= 0.00028 time= 1.63600
Epoch: 0291 train_loss= 0.69315 train_acc= 0.00028 time= 1.64437
Epoch: 0292 train_loss= 0.69315 train_acc= 0.00028 time= 1.64457
Epoch: 0293 train_loss= 0.69315 train_acc= 0.00028 time= 1.64456
Epoch: 0294 train_loss= 0.69315 train_acc= 0.00028 time= 1.64066
Epoch: 0295 train_loss= 0.69315 train_acc= 0.00028 time= 1.65074
Epoch: 0296 train_loss= 0.69315 train_acc= 0.00028 time= 1.64317
Epoch: 0297 train_loss= 0.69315 train_acc= 0.00028 time= 1.66108
Epoch: 0298 train_loss= 0.69315 train_acc= 0.00028 time= 1.64088
Epoch: 0299 train_loss= 0.69315 train_acc= 0.00028 time= 1.64083
Epoch: 0300 train_loss= 0.69315 train_acc= 0.00028 time= 1.64062
Optimization Finished!
Model: [1.4477459470881067,5.86567831343688e-14]
Epoch: 0001 train_loss= 43.41343 train_acc= 0.00028 time= 1.70834
Epoch: 0002 train_loss= 293.80994 train_acc= 0.00028 time= 1.62707
Epoch: 0003 train_loss= 22.82385 train_acc= 0.00028 time= 1.63946
Epoch: 0004 train_loss= 0.69314 train_acc= 0.00028 time= 1.63346
Epoch: 0005 train_loss= 0.69315 train_acc= 0.00028 time= 1.63256
Epoch: 0006 train_loss= 0.69315 train_acc= 0.00028 time= 1.63364
Epoch: 0007 train_loss= 0.69315 train_acc= 0.00028 time= 1.64522
Epoch: 0008 train_loss= 0.69315 train_acc= 0.00028 time= 1.65828
Epoch: 0009 train_loss= 0.69315 train_acc= 0.00028 time= 1.66148
Epoch: 0010 train_loss= 0.69315 train_acc= 0.00028 time= 1.64840
Epoch: 0011 train_loss= 0.69315 train_acc= 0.00028 time= 1.64760
Epoch: 0012 train_loss= 0.69315 train_acc= 0.00028 time= 1.64032
Epoch: 0013 train_loss= 0.69315 train_acc= 0.00028 time= 1.64318
Epoch: 0014 train_loss= 0.69315 train_acc= 0.00028 time= 1.63052
Epoch: 0015 train_loss= 0.69315 train_acc= 0.00028 time= 1.63436
Epoch: 0016 train_loss= 0.69315 train_acc= 0.00028 time= 1.64895
Epoch: 0017 train_loss= 0.69315 train_acc= 0.00028 time= 1.64236
Epoch: 0018 train_loss= 0.69315 train_acc= 0.00028 time= 1.62690
Epoch: 0019 train_loss= 0.69315 train_acc= 0.00028 time= 1.64327
Epoch: 0020 train_loss= 0.69315 train_acc= 0.00028 time= 1.63796
Epoch: 0021 train_loss= 0.69315 train_acc= 0.00028 time= 1.63484
Epoch: 0022 train_loss= 0.69315 train_acc= 0.00028 time= 1.64033
Epoch: 0023 train_loss= 0.69315 train_acc= 0.00028 time= 1.63104
Epoch: 0024 train_loss= 0.69315 train_acc= 0.00028 time= 1.64665
Epoch: 0025 train_loss= 0.69315 train_acc= 0.00028 time= 1.63981
Epoch: 0026 train_loss= 0.69315 train_acc= 0.00028 time= 1.63445
Epoch: 0027 train_loss= 0.69315 train_acc= 0.00028 time= 1.64258
Epoch: 0028 train_loss= 0.69315 train_acc= 0.00028 time= 1.63596
Epoch: 0029 train_loss= 0.69315 train_acc= 0.00028 time= 1.63782
Epoch: 0030 train_loss= 0.69315 train_acc= 0.00028 time= 1.63477
Epoch: 0031 train_loss= 0.69315 train_acc= 0.00028 time= 1.61801
Epoch: 0032 train_loss= 0.69315 train_acc= 0.00028 time= 1.62518
Epoch: 0033 train_loss= 0.69315 train_acc= 0.00028 time= 1.66677
Epoch: 0034 train_loss= 0.69315 train_acc= 0.00028 time= 1.62976
Epoch: 0035 train_loss= 0.69315 train_acc= 0.00028 time= 1.63166
Epoch: 0036 train_loss= 0.69315 train_acc= 0.00028 time= 1.63931
Epoch: 0037 train_loss= 0.69315 train_acc= 0.00028 time= 1.63642
Epoch: 0038 train_loss= 0.69315 train_acc= 0.00028 time= 1.63275
Epoch: 0039 train_loss= 0.69315 train_acc= 0.00028 time= 1.63387
Epoch: 0040 train_loss= 0.69315 train_acc= 0.00028 time= 1.63056
Epoch: 0041 train_loss= 0.69315 train_acc= 0.00028 time= 1.65540
Epoch: 0042 train_loss= 0.69315 train_acc= 0.00028 time= 1.63399
Epoch: 0043 train_loss= 0.69315 train_acc= 0.00028 time= 1.63513
Epoch: 0044 train_loss= 0.69315 train_acc= 0.00028 time= 1.64461
Epoch: 0045 train_loss= 0.69315 train_acc= 0.00028 time= 1.62769
Epoch: 0046 train_loss= 0.69315 train_acc= 0.00028 time= 1.61820
Epoch: 0047 train_loss= 0.69315 train_acc= 0.00028 time= 1.63654
Epoch: 0048 train_loss= 0.69315 train_acc= 0.00028 time= 1.63568
Epoch: 0049 train_loss= 0.69315 train_acc= 0.00028 time= 1.64405
Epoch: 0050 train_loss= 0.69315 train_acc= 0.00028 time= 1.62327
Epoch: 0051 train_loss= 0.69315 train_acc= 0.00028 time= 1.63764
Epoch: 0052 train_loss= 0.69315 train_acc= 0.00028 time= 1.62040
Epoch: 0053 train_loss= 0.69315 train_acc= 0.00028 time= 1.63841
Epoch: 0054 train_loss= 0.69315 train_acc= 0.00028 time= 1.63207
Epoch: 0055 train_loss= 0.69315 train_acc= 0.00028 time= 1.62577
Epoch: 0056 train_loss= 0.69315 train_acc= 0.00028 time= 1.65260
Epoch: 0057 train_loss= 0.69315 train_acc= 0.00028 time= 1.63843
Epoch: 0058 train_loss= 0.69315 train_acc= 0.00028 time= 1.62989
Epoch: 0059 train_loss= 0.69315 train_acc= 0.00028 time= 1.63882
Epoch: 0060 train_loss= 0.69315 train_acc= 0.00028 time= 1.62297
Epoch: 0061 train_loss= 0.69315 train_acc= 0.00028 time= 1.64372
Epoch: 0062 train_loss= 0.69315 train_acc= 0.00028 time= 1.63051
Epoch: 0063 train_loss= 0.69315 train_acc= 0.00028 time= 1.65072
Epoch: 0064 train_loss= 0.69315 train_acc= 0.00028 time= 1.64623
Epoch: 0065 train_loss= 0.69315 train_acc= 0.00028 time= 1.64564
Epoch: 0066 train_loss= 0.69315 train_acc= 0.00028 time= 1.63610
Epoch: 0067 train_loss= 0.69315 train_acc= 0.00028 time= 1.65117
Epoch: 0068 train_loss= 0.69315 train_acc= 0.00028 time= 1.61944
Epoch: 0069 train_loss= 0.69315 train_acc= 0.00028 time= 1.64914
Epoch: 0070 train_loss= 0.69315 train_acc= 0.00028 time= 1.63764
Epoch: 0071 train_loss= 0.69315 train_acc= 0.00028 time= 1.64069
Epoch: 0072 train_loss= 0.69315 train_acc= 0.00028 time= 1.64239
Epoch: 0073 train_loss= 0.69315 train_acc= 0.00028 time= 1.63454
Epoch: 0074 train_loss= 0.69315 train_acc= 0.00028 time= 1.65643
Epoch: 0075 train_loss= 0.69315 train_acc= 0.00028 time= 1.62949
Epoch: 0076 train_loss= 0.69315 train_acc= 0.00028 time= 1.63730
Epoch: 0077 train_loss= 0.69315 train_acc= 0.00028 time= 1.62838
Epoch: 0078 train_loss= 0.69315 train_acc= 0.00028 time= 1.64245
Epoch: 0079 train_loss= 0.69315 train_acc= 0.00028 time= 1.63454
Epoch: 0080 train_loss= 0.69315 train_acc= 0.00028 time= 1.63354
Epoch: 0081 train_loss= 0.69315 train_acc= 0.00028 time= 1.65319
Epoch: 0082 train_loss= 0.69315 train_acc= 0.00028 time= 1.62387
Epoch: 0083 train_loss= 0.69315 train_acc= 0.00028 time= 1.62232
Epoch: 0084 train_loss= 0.69315 train_acc= 0.00028 time= 1.61928
Epoch: 0085 train_loss= 0.69315 train_acc= 0.00028 time= 1.63273
Epoch: 0086 train_loss= 0.69315 train_acc= 0.00028 time= 1.61819
Epoch: 0087 train_loss= 0.69315 train_acc= 0.00028 time= 1.63879
Epoch: 0088 train_loss= 0.69315 train_acc= 0.00028 time= 1.62236
Epoch: 0089 train_loss= 0.69315 train_acc= 0.00028 time= 1.66041
Epoch: 0090 train_loss= 0.69315 train_acc= 0.00028 time= 1.63438
Epoch: 0091 train_loss= 0.69315 train_acc= 0.00028 time= 1.63385
Epoch: 0092 train_loss= 0.69315 train_acc= 0.00028 time= 1.64341
Epoch: 0093 train_loss= 0.69315 train_acc= 0.00028 time= 1.62891
Epoch: 0094 train_loss= 0.69315 train_acc= 0.00028 time= 1.65711
Epoch: 0095 train_loss= 0.69315 train_acc= 0.00028 time= 1.63539
Epoch: 0096 train_loss= 0.69315 train_acc= 0.00028 time= 1.62578
Epoch: 0097 train_loss= 0.69315 train_acc= 0.00028 time= 1.63612
Epoch: 0098 train_loss= 0.69315 train_acc= 0.00028 time= 1.64035
Epoch: 0099 train_loss= 0.69315 train_acc= 0.00028 time= 1.64941
Epoch: 0100 train_loss= 0.69315 train_acc= 0.00028 time= 1.63056
Epoch: 0101 train_loss= 0.69315 train_acc= 0.00028 time= 1.63626
Epoch: 0102 train_loss= 0.69315 train_acc= 0.00028 time= 1.63694
Epoch: 0103 train_loss= 0.69315 train_acc= 0.00028 time= 1.65557
Epoch: 0104 train_loss= 0.69315 train_acc= 0.00028 time= 1.62806
Epoch: 0105 train_loss= 0.69315 train_acc= 0.00028 time= 1.63681
Epoch: 0106 train_loss= 0.69315 train_acc= 0.00028 time= 1.63833
Epoch: 0107 train_loss= 0.69315 train_acc= 0.00028 time= 1.63543
Epoch: 0108 train_loss= 0.69315 train_acc= 0.00028 time= 1.64078
Epoch: 0109 train_loss= 0.69315 train_acc= 0.00028 time= 1.62351
Epoch: 0110 train_loss= 0.69315 train_acc= 0.00028 time= 1.63165
Epoch: 0111 train_loss= 0.69315 train_acc= 0.00028 time= 1.63077
Epoch: 0112 train_loss= 0.69315 train_acc= 0.00028 time= 1.63236
Epoch: 0113 train_loss= 0.69315 train_acc= 0.00028 time= 1.63479
Epoch: 0114 train_loss= 0.69315 train_acc= 0.00028 time= 1.64606
Epoch: 0115 train_loss= 0.69315 train_acc= 0.00028 time= 1.62843
Epoch: 0116 train_loss= 0.69315 train_acc= 0.00028 time= 1.63914
Epoch: 0117 train_loss= 0.69315 train_acc= 0.00028 time= 1.62013
Epoch: 0118 train_loss= 0.69315 train_acc= 0.00028 time= 1.63499
Epoch: 0119 train_loss= 0.69315 train_acc= 0.00028 time= 1.63201
Epoch: 0120 train_loss= 0.69315 train_acc= 0.00028 time= 1.66793
Epoch: 0121 train_loss= 0.69315 train_acc= 0.00028 time= 1.67032
Epoch: 0122 train_loss= 0.69315 train_acc= 0.00028 time= 1.65379
Epoch: 0123 train_loss= 0.69315 train_acc= 0.00028 time= 1.63460
Epoch: 0124 train_loss= 0.69315 train_acc= 0.00028 time= 1.62974
Epoch: 0125 train_loss= 0.69315 train_acc= 0.00028 time= 1.63496
Epoch: 0126 train_loss= 0.69315 train_acc= 0.00028 time= 1.64757
Epoch: 0127 train_loss= 0.69315 train_acc= 0.00028 time= 1.67824
Epoch: 0128 train_loss= 0.69315 train_acc= 0.00028 time= 1.62889
Epoch: 0129 train_loss= 0.69315 train_acc= 0.00028 time= 1.62753
Epoch: 0130 train_loss= 0.69315 train_acc= 0.00028 time= 1.63483
Epoch: 0131 train_loss= 0.69315 train_acc= 0.00028 time= 1.63037
Epoch: 0132 train_loss= 0.69315 train_acc= 0.00028 time= 1.63988
Epoch: 0133 train_loss= 0.69315 train_acc= 0.00028 time= 1.64847
Epoch: 0134 train_loss= 0.69315 train_acc= 0.00028 time= 1.64943
Epoch: 0135 train_loss= 0.69315 train_acc= 0.00028 time= 1.63730
Epoch: 0136 train_loss= 0.69315 train_acc= 0.00028 time= 1.64474
Epoch: 0137 train_loss= 0.69315 train_acc= 0.00028 time= 1.63073
Epoch: 0138 train_loss= 0.69315 train_acc= 0.00028 time= 1.62871
Epoch: 0139 train_loss= 0.69315 train_acc= 0.00028 time= 1.63564
Epoch: 0140 train_loss= 0.69315 train_acc= 0.00028 time= 1.64064
Epoch: 0141 train_loss= 0.69315 train_acc= 0.00028 time= 1.64860
Epoch: 0142 train_loss= 0.69315 train_acc= 0.00028 time= 1.64112
Epoch: 0143 train_loss= 0.69315 train_acc= 0.00028 time= 1.64701
Epoch: 0144 train_loss= 0.69315 train_acc= 0.00028 time= 1.62295
Epoch: 0145 train_loss= 0.69315 train_acc= 0.00028 time= 1.62673
Epoch: 0146 train_loss= 0.69315 train_acc= 0.00028 time= 1.62920
Epoch: 0147 train_loss= 0.69315 train_acc= 0.00028 time= 1.63901
Epoch: 0148 train_loss= 0.69315 train_acc= 0.00028 time= 1.65234
Epoch: 0149 train_loss= 0.69315 train_acc= 0.00028 time= 1.65061
Epoch: 0150 train_loss= 0.69315 train_acc= 0.00028 time= 1.64558
Epoch: 0151 train_loss= 0.69315 train_acc= 0.00028 time= 1.63602
Epoch: 0152 train_loss= 0.69315 train_acc= 0.00028 time= 1.63279
Epoch: 0153 train_loss= 0.69315 train_acc= 0.00028 time= 1.63260
Epoch: 0154 train_loss= 0.69315 train_acc= 0.00028 time= 1.64127
Epoch: 0155 train_loss= 0.69315 train_acc= 0.00028 time= 1.64131
Epoch: 0156 train_loss= 0.69315 train_acc= 0.00028 time= 1.63438
Epoch: 0157 train_loss= 0.69315 train_acc= 0.00028 time= 1.63594
Epoch: 0158 train_loss= 0.69315 train_acc= 0.00028 time= 1.62737
Epoch: 0159 train_loss= 0.69315 train_acc= 0.00028 time= 1.65894
Epoch: 0160 train_loss= 0.69315 train_acc= 0.00028 time= 1.64047
Epoch: 0161 train_loss= 0.69315 train_acc= 0.00028 time= 1.63471
Epoch: 0162 train_loss= 0.69315 train_acc= 0.00028 time= 1.61737
Epoch: 0163 train_loss= 0.69315 train_acc= 0.00028 time= 1.64739
Epoch: 0164 train_loss= 0.69315 train_acc= 0.00028 time= 1.62774
Epoch: 0165 train_loss= 0.69315 train_acc= 0.00028 time= 1.63819
Epoch: 0166 train_loss= 0.69315 train_acc= 0.00028 time= 1.62488
Epoch: 0167 train_loss= 0.69315 train_acc= 0.00028 time= 1.63882
Epoch: 0168 train_loss= 0.69315 train_acc= 0.00028 time= 1.64300
Epoch: 0169 train_loss= 0.69315 train_acc= 0.00028 time= 1.64765
Epoch: 0170 train_loss= 0.69315 train_acc= 0.00028 time= 1.65065
Epoch: 0171 train_loss= 0.69315 train_acc= 0.00028 time= 1.63580
Epoch: 0172 train_loss= 0.69315 train_acc= 0.00028 time= 1.64448
Epoch: 0173 train_loss= 0.69315 train_acc= 0.00028 time= 1.63088
Epoch: 0174 train_loss= 0.69315 train_acc= 0.00028 time= 1.63551
Epoch: 0175 train_loss= 0.69315 train_acc= 0.00028 time= 1.66070
Epoch: 0176 train_loss= 0.69315 train_acc= 0.00028 time= 1.64482
Epoch: 0177 train_loss= 0.69315 train_acc= 0.00028 time= 1.64211
Epoch: 0178 train_loss= 0.69315 train_acc= 0.00028 time= 1.63139
Epoch: 0179 train_loss= 0.69315 train_acc= 0.00028 time= 1.65344
Epoch: 0180 train_loss= 0.69315 train_acc= 0.00028 time= 1.62661
Epoch: 0181 train_loss= 0.69315 train_acc= 0.00028 time= 1.63340
Epoch: 0182 train_loss= 0.69315 train_acc= 0.00028 time= 1.63723
Epoch: 0183 train_loss= 0.69315 train_acc= 0.00028 time= 1.64476
Epoch: 0184 train_loss= 0.69315 train_acc= 0.00028 time= 1.63430
Epoch: 0185 train_loss= 0.69315 train_acc= 0.00028 time= 1.65684
Epoch: 0186 train_loss= 0.69315 train_acc= 0.00028 time= 1.62382
Epoch: 0187 train_loss= 0.69315 train_acc= 0.00028 time= 1.64048
Epoch: 0188 train_loss= 0.69315 train_acc= 0.00028 time= 1.62942
Epoch: 0189 train_loss= 0.69315 train_acc= 0.00028 time= 1.62338
Epoch: 0190 train_loss= 0.69315 train_acc= 0.00028 time= 1.65147
Epoch: 0191 train_loss= 0.69315 train_acc= 0.00028 time= 1.63544
Epoch: 0192 train_loss= 0.69315 train_acc= 0.00028 time= 1.63724
Epoch: 0193 train_loss= 0.69315 train_acc= 0.00028 time= 1.64303
Epoch: 0194 train_loss= 0.69315 train_acc= 0.00028 time= 1.65696
Epoch: 0195 train_loss= 0.69315 train_acc= 0.00028 time= 1.63477
Epoch: 0196 train_loss= 0.69315 train_acc= 0.00028 time= 1.63748
Epoch: 0197 train_loss= 0.69315 train_acc= 0.00028 time= 1.65165
Epoch: 0198 train_loss= 0.69315 train_acc= 0.00028 time= 1.62395
Epoch: 0199 train_loss= 0.69315 train_acc= 0.00028 time= 1.63970
Epoch: 0200 train_loss= 0.69315 train_acc= 0.00028 time= 1.66506
Epoch: 0201 train_loss= 0.69315 train_acc= 0.00028 time= 1.63707
Epoch: 0202 train_loss= 0.69315 train_acc= 0.00028 time= 1.70287
Epoch: 0203 train_loss= 0.69315 train_acc= 0.00028 time= 1.62185
Epoch: 0204 train_loss= 0.69315 train_acc= 0.00028 time= 1.63383
Epoch: 0205 train_loss= 0.69315 train_acc= 0.00028 time= 1.64176
Epoch: 0206 train_loss= 0.69315 train_acc= 0.00028 time= 1.63084
Epoch: 0207 train_loss= 0.69315 train_acc= 0.00028 time= 1.64995
Epoch: 0208 train_loss= 0.69315 train_acc= 0.00028 time= 1.64770
Epoch: 0209 train_loss= 0.69315 train_acc= 0.00028 time= 1.63862
Epoch: 0210 train_loss= 0.69315 train_acc= 0.00028 time= 1.64124
Epoch: 0211 train_loss= 0.69315 train_acc= 0.00028 time= 1.64028
Epoch: 0212 train_loss= 0.69315 train_acc= 0.00028 time= 1.64155
Epoch: 0213 train_loss= 0.69315 train_acc= 0.00028 time= 1.64587
Epoch: 0214 train_loss= 0.69315 train_acc= 0.00028 time= 1.64170
Epoch: 0215 train_loss= 0.69315 train_acc= 0.00028 time= 1.64484
Epoch: 0216 train_loss= 0.69315 train_acc= 0.00028 time= 1.64097
Epoch: 0217 train_loss= 0.69315 train_acc= 0.00028 time= 1.66447
Epoch: 0218 train_loss= 0.69315 train_acc= 0.00028 time= 1.64110
Epoch: 0219 train_loss= 0.69315 train_acc= 0.00028 time= 1.62725
Epoch: 0220 train_loss= 0.69315 train_acc= 0.00028 time= 1.64682
Epoch: 0221 train_loss= 0.69315 train_acc= 0.00028 time= 1.63110
Epoch: 0222 train_loss= 0.69315 train_acc= 0.00028 time= 1.65287
Epoch: 0223 train_loss= 0.69315 train_acc= 0.00028 time= 1.64079
Epoch: 0224 train_loss= 0.69315 train_acc= 0.00028 time= 1.63314
Epoch: 0225 train_loss= 0.69315 train_acc= 0.00028 time= 1.64166
Epoch: 0226 train_loss= 0.69315 train_acc= 0.00028 time= 1.62942
Epoch: 0227 train_loss= 0.69315 train_acc= 0.00028 time= 1.62741
Epoch: 0228 train_loss= 0.69315 train_acc= 0.00028 time= 1.62677
Epoch: 0229 train_loss= 0.69315 train_acc= 0.00028 time= 1.64698
Epoch: 0230 train_loss= 0.69315 train_acc= 0.00028 time= 1.64724
Epoch: 0231 train_loss= 0.69315 train_acc= 0.00028 time= 1.63864
Epoch: 0232 train_loss= 0.69315 train_acc= 0.00028 time= 1.63249
Epoch: 0233 train_loss= 0.69315 train_acc= 0.00028 time= 1.64330
Epoch: 0234 train_loss= 0.69315 train_acc= 0.00028 time= 1.64360
Epoch: 0235 train_loss= 0.69315 train_acc= 0.00028 time= 1.61257
Epoch: 0236 train_loss= 0.69315 train_acc= 0.00028 time= 1.63560
Epoch: 0237 train_loss= 0.69315 train_acc= 0.00028 time= 1.65026
Epoch: 0238 train_loss= 0.69315 train_acc= 0.00028 time= 1.65470
Epoch: 0239 train_loss= 0.69315 train_acc= 0.00028 time= 1.62400
Epoch: 0240 train_loss= 0.69315 train_acc= 0.00028 time= 1.61645
Epoch: 0241 train_loss= 0.69315 train_acc= 0.00028 time= 1.65185
Epoch: 0242 train_loss= 0.69315 train_acc= 0.00028 time= 1.64492
Epoch: 0243 train_loss= 0.69315 train_acc= 0.00028 time= 1.63597
Epoch: 0244 train_loss= 0.69315 train_acc= 0.00028 time= 1.64937
Epoch: 0245 train_loss= 0.69315 train_acc= 0.00028 time= 1.65640
Epoch: 0246 train_loss= 0.69315 train_acc= 0.00028 time= 1.62492
Epoch: 0247 train_loss= 0.69315 train_acc= 0.00028 time= 1.62922
Epoch: 0248 train_loss= 0.69315 train_acc= 0.00028 time= 1.62143
Epoch: 0249 train_loss= 0.69315 train_acc= 0.00028 time= 1.64444
Epoch: 0250 train_loss= 0.69315 train_acc= 0.00028 time= 1.63469
Epoch: 0251 train_loss= 0.69315 train_acc= 0.00028 time= 1.63049
Epoch: 0252 train_loss= 0.69315 train_acc= 0.00028 time= 1.64958
Epoch: 0253 train_loss= 0.69315 train_acc= 0.00028 time= 1.65951
Epoch: 0254 train_loss= 0.69315 train_acc= 0.00028 time= 1.63946
Epoch: 0255 train_loss= 0.69315 train_acc= 0.00028 time= 1.63595
Epoch: 0256 train_loss= 0.69315 train_acc= 0.00028 time= 1.63369
Epoch: 0257 train_loss= 0.69315 train_acc= 0.00028 time= 1.68375
Epoch: 0258 train_loss= 0.69315 train_acc= 0.00028 time= 1.64111
Epoch: 0259 train_loss= 0.69315 train_acc= 0.00028 time= 1.62478
Epoch: 0260 train_loss= 0.69315 train_acc= 0.00028 time= 1.66949
Epoch: 0261 train_loss= 0.69315 train_acc= 0.00028 time= 1.65591
Epoch: 0262 train_loss= 0.69315 train_acc= 0.00028 time= 1.65209
Epoch: 0263 train_loss= 0.69315 train_acc= 0.00028 time= 1.64141
Epoch: 0264 train_loss= 0.69315 train_acc= 0.00028 time= 1.64623
Epoch: 0265 train_loss= 0.69315 train_acc= 0.00028 time= 1.64423
Epoch: 0266 train_loss= 0.69315 train_acc= 0.00028 time= 1.63171
Epoch: 0267 train_loss= 0.69315 train_acc= 0.00028 time= 1.62457
Epoch: 0268 train_loss= 0.69315 train_acc= 0.00028 time= 1.64570
Epoch: 0269 train_loss= 0.69315 train_acc= 0.00028 time= 1.64203
Epoch: 0270 train_loss= 0.69315 train_acc= 0.00028 time= 1.64060
Epoch: 0271 train_loss= 0.69315 train_acc= 0.00028 time= 1.64796
Epoch: 0272 train_loss= 0.69315 train_acc= 0.00028 time= 1.64327
Epoch: 0273 train_loss= 0.69315 train_acc= 0.00028 time= 1.62960
Epoch: 0274 train_loss= 0.69315 train_acc= 0.00028 time= 1.63682
Epoch: 0275 train_loss= 0.69315 train_acc= 0.00028 time= 1.64072
Epoch: 0276 train_loss= 0.69315 train_acc= 0.00028 time= 1.63205
Epoch: 0277 train_loss= 0.69315 train_acc= 0.00028 time= 1.61969
Epoch: 0278 train_loss= 0.69315 train_acc= 0.00028 time= 1.63631
Epoch: 0279 train_loss= 0.69315 train_acc= 0.00028 time= 1.63787
Epoch: 0280 train_loss= 0.69315 train_acc= 0.00028 time= 1.63260
Epoch: 0281 train_loss= 0.69315 train_acc= 0.00028 time= 1.61917
Epoch: 0282 train_loss= 0.69315 train_acc= 0.00028 time= 1.62749
Epoch: 0283 train_loss= 0.69315 train_acc= 0.00028 time= 1.64384
Epoch: 0284 train_loss= 0.69315 train_acc= 0.00028 time= 1.63935
Epoch: 0285 train_loss= 0.69315 train_acc= 0.00028 time= 1.63105
Epoch: 0286 train_loss= 0.69315 train_acc= 0.00028 time= 1.62961
Epoch: 0287 train_loss= 0.69315 train_acc= 0.00028 time= 1.62785
Epoch: 0288 train_loss= 0.69315 train_acc= 0.00028 time= 1.63991
Epoch: 0289 train_loss= 0.69315 train_acc= 0.00028 time= 1.63989
Epoch: 0290 train_loss= 0.69315 train_acc= 0.00028 time= 1.66181
Epoch: 0291 train_loss= 0.69315 train_acc= 0.00028 time= 1.63525
Epoch: 0292 train_loss= 0.69315 train_acc= 0.00028 time= 1.64250
Epoch: 0293 train_loss= 0.69315 train_acc= 0.00028 time= 1.63464
Epoch: 0294 train_loss= 0.69315 train_acc= 0.00028 time= 1.62176
Epoch: 0295 train_loss= 0.69315 train_acc= 0.00028 time= 1.64799
Epoch: 0296 train_loss= 0.69315 train_acc= 0.00028 time= 1.63906
Epoch: 0297 train_loss= 0.69315 train_acc= 0.00028 time= 1.63203
Epoch: 0298 train_loss= 0.69315 train_acc= 0.00028 time= 1.62510
Epoch: 0299 train_loss= 0.69315 train_acc= 0.00028 time= 1.63293
Epoch: 0300 train_loss= 0.69315 train_acc= 0.00028 time= 1.64483
Optimization Finished!
Model: [1.4477414172684122,-7.135033304926538e-14]
Epoch: 0001 train_loss= 26.02703 train_acc= 0.00028 time= 1.68785
Epoch: 0002 train_loss= 290.43005 train_acc= 0.00028 time= 1.63111
Epoch: 0003 train_loss= 21.65833 train_acc= 0.00028 time= 1.63264
Epoch: 0004 train_loss= 0.69315 train_acc= 0.00028 time= 1.63979
Epoch: 0005 train_loss= 0.69315 train_acc= 0.00028 time= 1.63117
Epoch: 0006 train_loss= 0.69315 train_acc= 0.00028 time= 1.63437
Epoch: 0007 train_loss= 0.69315 train_acc= 0.00028 time= 1.66438
Epoch: 0008 train_loss= 0.69315 train_acc= 0.00028 time= 1.65830
Epoch: 0009 train_loss= 0.69315 train_acc= 0.00028 time= 1.67420
Epoch: 0010 train_loss= 0.69315 train_acc= 0.00028 time= 1.65810
Epoch: 0011 train_loss= 0.69315 train_acc= 0.00028 time= 1.65097
Epoch: 0012 train_loss= 0.69315 train_acc= 0.00028 time= 1.65353
Epoch: 0013 train_loss= 0.69315 train_acc= 0.00028 time= 1.63130
Epoch: 0014 train_loss= 0.69315 train_acc= 0.00028 time= 1.63235
Epoch: 0015 train_loss= 0.69315 train_acc= 0.00028 time= 1.64969
Epoch: 0016 train_loss= 0.69315 train_acc= 0.00028 time= 1.64017
Epoch: 0017 train_loss= 0.69315 train_acc= 0.00028 time= 1.65262
Epoch: 0018 train_loss= 0.69315 train_acc= 0.00028 time= 1.63237
Epoch: 0019 train_loss= 0.69315 train_acc= 0.00028 time= 1.64428
Epoch: 0020 train_loss= 0.69315 train_acc= 0.00028 time= 1.63296
Epoch: 0021 train_loss= 0.69315 train_acc= 0.00028 time= 1.61656
Epoch: 0022 train_loss= 0.69315 train_acc= 0.00028 time= 1.62791
Epoch: 0023 train_loss= 0.69315 train_acc= 0.00028 time= 1.63828
Epoch: 0024 train_loss= 0.69315 train_acc= 0.00028 time= 1.63645
Epoch: 0025 train_loss= 0.69315 train_acc= 0.00028 time= 1.63992
Epoch: 0026 train_loss= 0.69315 train_acc= 0.00028 time= 1.64391
Epoch: 0027 train_loss= 0.69315 train_acc= 0.00028 time= 1.64203
Epoch: 0028 train_loss= 0.69315 train_acc= 0.00028 time= 1.68010
Epoch: 0029 train_loss= 0.69315 train_acc= 0.00028 time= 1.62373
Epoch: 0030 train_loss= 0.69315 train_acc= 0.00028 time= 1.64439
Epoch: 0031 train_loss= 0.69315 train_acc= 0.00028 time= 1.64407
Epoch: 0032 train_loss= 0.69315 train_acc= 0.00028 time= 1.63063
Epoch: 0033 train_loss= 0.69315 train_acc= 0.00028 time= 1.63332
Epoch: 0034 train_loss= 0.69315 train_acc= 0.00028 time= 1.62606
Epoch: 0035 train_loss= 0.69315 train_acc= 0.00028 time= 1.65812
Epoch: 0036 train_loss= 0.69315 train_acc= 0.00028 time= 1.64063
Epoch: 0037 train_loss= 0.69315 train_acc= 0.00028 time= 1.64335
Epoch: 0038 train_loss= 0.69315 train_acc= 0.00028 time= 1.63202
Epoch: 0039 train_loss= 0.69315 train_acc= 0.00028 time= 1.64391
Epoch: 0040 train_loss= 0.69315 train_acc= 0.00028 time= 1.63372
Epoch: 0041 train_loss= 0.69315 train_acc= 0.00028 time= 1.63151
Epoch: 0042 train_loss= 0.69315 train_acc= 0.00028 time= 1.62056
Epoch: 0043 train_loss= 0.69315 train_acc= 0.00028 time= 1.63810
Epoch: 0044 train_loss= 0.69315 train_acc= 0.00028 time= 1.63902
Epoch: 0045 train_loss= 0.69315 train_acc= 0.00028 time= 1.61879
Epoch: 0046 train_loss= 0.69315 train_acc= 0.00028 time= 1.63860
Epoch: 0047 train_loss= 0.69315 train_acc= 0.00028 time= 1.63216
Epoch: 0048 train_loss= 0.69315 train_acc= 0.00028 time= 1.63468
Epoch: 0049 train_loss= 0.69315 train_acc= 0.00028 time= 1.64047
Epoch: 0050 train_loss= 0.69315 train_acc= 0.00028 time= 1.63031
Epoch: 0051 train_loss= 0.69315 train_acc= 0.00028 time= 1.63582
Epoch: 0052 train_loss= 0.69315 train_acc= 0.00028 time= 1.63661
Epoch: 0053 train_loss= 0.69315 train_acc= 0.00028 time= 1.65287
Epoch: 0054 train_loss= 0.69315 train_acc= 0.00028 time= 1.63249
Epoch: 0055 train_loss= 0.69315 train_acc= 0.00028 time= 1.62603
Epoch: 0056 train_loss= 0.69315 train_acc= 0.00028 time= 1.63632
Epoch: 0057 train_loss= 0.69315 train_acc= 0.00028 time= 1.63444
Epoch: 0058 train_loss= 0.69315 train_acc= 0.00028 time= 1.64450
Epoch: 0059 train_loss= 0.69315 train_acc= 0.00028 time= 1.62827
Epoch: 0060 train_loss= 0.69315 train_acc= 0.00028 time= 1.63997
Epoch: 0061 train_loss= 0.69315 train_acc= 0.00028 time= 1.62904
Epoch: 0062 train_loss= 0.69315 train_acc= 0.00028 time= 1.62291
Epoch: 0063 train_loss= 0.69315 train_acc= 0.00028 time= 1.63101
Epoch: 0064 train_loss= 0.69315 train_acc= 0.00028 time= 1.63012
Epoch: 0065 train_loss= 0.69315 train_acc= 0.00028 time= 1.62637
Epoch: 0066 train_loss= 0.69315 train_acc= 0.00028 time= 1.63835
Epoch: 0067 train_loss= 0.69315 train_acc= 0.00028 time= 1.63953
Epoch: 0068 train_loss= 0.69315 train_acc= 0.00028 time= 1.63427
Epoch: 0069 train_loss= 0.69315 train_acc= 0.00028 time= 1.62342
Epoch: 0070 train_loss= 0.69315 train_acc= 0.00028 time= 1.63588
Epoch: 0071 train_loss= 0.69315 train_acc= 0.00028 time= 1.63245
Epoch: 0072 train_loss= 0.69315 train_acc= 0.00028 time= 1.65375
Epoch: 0073 train_loss= 0.69315 train_acc= 0.00028 time= 1.63117
Epoch: 0074 train_loss= 0.69315 train_acc= 0.00028 time= 1.67622
Epoch: 0075 train_loss= 0.69315 train_acc= 0.00028 time= 1.63650
Epoch: 0076 train_loss= 0.69315 train_acc= 0.00028 time= 1.65972
Epoch: 0077 train_loss= 0.69315 train_acc= 0.00028 time= 1.65524
Epoch: 0078 train_loss= 0.69315 train_acc= 0.00028 time= 1.62476
Epoch: 0079 train_loss= 0.69315 train_acc= 0.00028 time= 1.62537
Epoch: 0080 train_loss= 0.69315 train_acc= 0.00028 time= 1.62830
Epoch: 0081 train_loss= 0.69315 train_acc= 0.00028 time= 1.63739
Epoch: 0082 train_loss= 0.69315 train_acc= 0.00028 time= 1.63958
Epoch: 0083 train_loss= 0.69315 train_acc= 0.00028 time= 1.61611
Epoch: 0084 train_loss= 0.69315 train_acc= 0.00028 time= 1.62835
Epoch: 0085 train_loss= 0.69315 train_acc= 0.00028 time= 1.62592
Epoch: 0086 train_loss= 0.69315 train_acc= 0.00028 time= 1.63080
Epoch: 0087 train_loss= 0.69315 train_acc= 0.00028 time= 1.64540
Epoch: 0088 train_loss= 0.69315 train_acc= 0.00028 time= 1.62005
Epoch: 0089 train_loss= 0.69315 train_acc= 0.00028 time= 1.61627
Epoch: 0090 train_loss= 0.69315 train_acc= 0.00028 time= 1.62884
Epoch: 0091 train_loss= 0.69315 train_acc= 0.00028 time= 1.64012
Epoch: 0092 train_loss= 0.69315 train_acc= 0.00028 time= 1.64109
Epoch: 0093 train_loss= 0.69315 train_acc= 0.00028 time= 1.66257
Epoch: 0094 train_loss= 0.69315 train_acc= 0.00028 time= 1.62456
Epoch: 0095 train_loss= 0.69315 train_acc= 0.00028 time= 1.63476
Epoch: 0096 train_loss= 0.69315 train_acc= 0.00028 time= 1.63362
Epoch: 0097 train_loss= 0.69315 train_acc= 0.00028 time= 1.62872
Epoch: 0098 train_loss= 0.69315 train_acc= 0.00028 time= 1.63529
Epoch: 0099 train_loss= 0.69315 train_acc= 0.00028 time= 1.62114
Epoch: 0100 train_loss= 0.69315 train_acc= 0.00028 time= 1.62079
Epoch: 0101 train_loss= 0.69315 train_acc= 0.00028 time= 1.63646
Epoch: 0102 train_loss= 0.69315 train_acc= 0.00028 time= 1.62829
Epoch: 0103 train_loss= 0.69315 train_acc= 0.00028 time= 1.63539
Epoch: 0104 train_loss= 0.69315 train_acc= 0.00028 time= 1.65039
Epoch: 0105 train_loss= 0.69315 train_acc= 0.00028 time= 1.63491
Epoch: 0106 train_loss= 0.69315 train_acc= 0.00028 time= 1.62840
Epoch: 0107 train_loss= 0.69315 train_acc= 0.00028 time= 1.62172
Epoch: 0108 train_loss= 0.69315 train_acc= 0.00028 time= 1.64327
Epoch: 0109 train_loss= 0.69315 train_acc= 0.00028 time= 1.64361
Epoch: 0110 train_loss= 0.69315 train_acc= 0.00028 time= 1.64351
Epoch: 0111 train_loss= 0.69315 train_acc= 0.00028 time= 1.64650
Epoch: 0112 train_loss= 0.69315 train_acc= 0.00028 time= 1.63342
Epoch: 0113 train_loss= 0.69315 train_acc= 0.00028 time= 1.64153
Epoch: 0114 train_loss= 0.69315 train_acc= 0.00028 time= 1.62817
Epoch: 0115 train_loss= 0.69315 train_acc= 0.00028 time= 1.62312
Epoch: 0116 train_loss= 0.69315 train_acc= 0.00028 time= 1.63354
Epoch: 0117 train_loss= 0.69315 train_acc= 0.00028 time= 1.62957
Epoch: 0118 train_loss= 0.69315 train_acc= 0.00028 time= 1.63014
Epoch: 0119 train_loss= 0.69315 train_acc= 0.00028 time= 1.62908
Epoch: 0120 train_loss= 0.69315 train_acc= 0.00028 time= 1.63926
Epoch: 0121 train_loss= 0.69315 train_acc= 0.00028 time= 1.63210
Epoch: 0122 train_loss= 0.69315 train_acc= 0.00028 time= 1.64873
Epoch: 0123 train_loss= 0.69315 train_acc= 0.00028 time= 1.62128
Epoch: 0124 train_loss= 0.69315 train_acc= 0.00028 time= 1.64147
Epoch: 0125 train_loss= 0.69315 train_acc= 0.00028 time= 1.62373
Epoch: 0126 train_loss= 0.69315 train_acc= 0.00028 time= 1.63450
Epoch: 0127 train_loss= 0.69315 train_acc= 0.00028 time= 1.63102
Epoch: 0128 train_loss= 0.69315 train_acc= 0.00028 time= 1.64212
Epoch: 0129 train_loss= 0.69315 train_acc= 0.00028 time= 1.63618
Epoch: 0130 train_loss= 0.69315 train_acc= 0.00028 time= 1.62277
Epoch: 0131 train_loss= 0.69315 train_acc= 0.00028 time= 1.64214
Epoch: 0132 train_loss= 0.69315 train_acc= 0.00028 time= 1.64668
Epoch: 0133 train_loss= 0.69315 train_acc= 0.00028 time= 1.63743
Epoch: 0134 train_loss= 0.69315 train_acc= 0.00028 time= 1.66462
Epoch: 0135 train_loss= 0.69315 train_acc= 0.00028 time= 1.63955
Epoch: 0136 train_loss= 0.69315 train_acc= 0.00028 time= 1.63717
Epoch: 0137 train_loss= 0.69315 train_acc= 0.00028 time= 1.63768
Epoch: 0138 train_loss= 0.69315 train_acc= 0.00028 time= 1.62941
Epoch: 0139 train_loss= 0.69315 train_acc= 0.00028 time= 1.64615
Epoch: 0140 train_loss= 0.69315 train_acc= 0.00028 time= 1.64752
Epoch: 0141 train_loss= 0.69315 train_acc= 0.00028 time= 1.62639
Epoch: 0142 train_loss= 0.69315 train_acc= 0.00028 time= 1.64613
Epoch: 0143 train_loss= 0.69315 train_acc= 0.00028 time= 1.62119
Epoch: 0144 train_loss= 0.69315 train_acc= 0.00028 time= 1.62027
Epoch: 0145 train_loss= 0.69315 train_acc= 0.00028 time= 1.61863
Epoch: 0146 train_loss= 0.69315 train_acc= 0.00028 time= 1.63390
Epoch: 0147 train_loss= 0.69315 train_acc= 0.00028 time= 1.62373
Epoch: 0148 train_loss= 0.69315 train_acc= 0.00028 time= 1.63817
Epoch: 0149 train_loss= 0.69315 train_acc= 0.00028 time= 1.63974
Epoch: 0150 train_loss= 0.69315 train_acc= 0.00028 time= 1.62310
Epoch: 0151 train_loss= 0.69315 train_acc= 0.00028 time= 1.63084
Epoch: 0152 train_loss= 0.69315 train_acc= 0.00028 time= 1.63315
Epoch: 0153 train_loss= 0.69315 train_acc= 0.00028 time= 1.63423
Epoch: 0154 train_loss= 0.69315 train_acc= 0.00028 time= 1.63520
Epoch: 0155 train_loss= 0.69315 train_acc= 0.00028 time= 1.62632
Epoch: 0156 train_loss= 0.69315 train_acc= 0.00028 time= 1.65445
Epoch: 0157 train_loss= 0.69315 train_acc= 0.00028 time= 1.66133
Epoch: 0158 train_loss= 0.69315 train_acc= 0.00028 time= 1.63364
Epoch: 0159 train_loss= 0.69315 train_acc= 0.00028 time= 1.65144
Epoch: 0160 train_loss= 0.69315 train_acc= 0.00028 time= 1.64636
Epoch: 0161 train_loss= 0.69315 train_acc= 0.00028 time= 1.63426
Epoch: 0162 train_loss= 0.69315 train_acc= 0.00028 time= 1.62500
Epoch: 0163 train_loss= 0.69315 train_acc= 0.00028 time= 1.62695
Epoch: 0164 train_loss= 0.69315 train_acc= 0.00028 time= 1.62940
Epoch: 0165 train_loss= 0.69315 train_acc= 0.00028 time= 1.62777
Epoch: 0166 train_loss= 0.69315 train_acc= 0.00028 time= 1.63525
Epoch: 0167 train_loss= 0.69315 train_acc= 0.00028 time= 1.63978
Epoch: 0168 train_loss= 0.69315 train_acc= 0.00028 time= 1.63977
Epoch: 0169 train_loss= 0.69315 train_acc= 0.00028 time= 1.63803
Epoch: 0170 train_loss= 0.69315 train_acc= 0.00028 time= 1.62678
Epoch: 0171 train_loss= 0.69315 train_acc= 0.00028 time= 1.63115
Epoch: 0172 train_loss= 0.69315 train_acc= 0.00028 time= 1.63687
Epoch: 0173 train_loss= 0.69315 train_acc= 0.00028 time= 1.62571
Epoch: 0174 train_loss= 0.69315 train_acc= 0.00028 time= 1.63034
Epoch: 0175 train_loss= 0.69315 train_acc= 0.00028 time= 1.63466
Epoch: 0176 train_loss= 0.69315 train_acc= 0.00028 time= 1.64236
Epoch: 0177 train_loss= 0.69315 train_acc= 0.00028 time= 1.64572
Epoch: 0178 train_loss= 0.69315 train_acc= 0.00028 time= 1.62853
Epoch: 0179 train_loss= 0.69315 train_acc= 0.00028 time= 1.63208
Epoch: 0180 train_loss= 0.69315 train_acc= 0.00028 time= 1.65655
Epoch: 0181 train_loss= 0.69315 train_acc= 0.00028 time= 1.64501
Epoch: 0182 train_loss= 0.69315 train_acc= 0.00028 time= 1.64116
Epoch: 0183 train_loss= 0.69315 train_acc= 0.00028 time= 1.62239
Epoch: 0184 train_loss= 0.69315 train_acc= 0.00028 time= 1.64873
Epoch: 0185 train_loss= 0.69315 train_acc= 0.00028 time= 1.63804
Epoch: 0186 train_loss= 0.69315 train_acc= 0.00028 time= 1.62748
Epoch: 0187 train_loss= 0.69315 train_acc= 0.00028 time= 1.64900
Epoch: 0188 train_loss= 0.69315 train_acc= 0.00028 time= 1.64570
Epoch: 0189 train_loss= 0.69315 train_acc= 0.00028 time= 1.63921
Epoch: 0190 train_loss= 0.69315 train_acc= 0.00028 time= 1.62308
Epoch: 0191 train_loss= 0.69315 train_acc= 0.00028 time= 1.64584
Epoch: 0192 train_loss= 0.69315 train_acc= 0.00028 time= 1.64386
Epoch: 0193 train_loss= 0.69315 train_acc= 0.00028 time= 1.64773
Epoch: 0194 train_loss= 0.69315 train_acc= 0.00028 time= 1.63050
Epoch: 0195 train_loss= 0.69315 train_acc= 0.00028 time= 1.63801
Epoch: 0196 train_loss= 0.69315 train_acc= 0.00028 time= 1.64985
Epoch: 0197 train_loss= 0.69315 train_acc= 0.00028 time= 1.63559
Epoch: 0198 train_loss= 0.69315 train_acc= 0.00028 time= 1.62185
Epoch: 0199 train_loss= 0.69315 train_acc= 0.00028 time= 1.63960
Epoch: 0200 train_loss= 0.69315 train_acc= 0.00028 time= 1.63637
Epoch: 0201 train_loss= 0.69315 train_acc= 0.00028 time= 1.63469
Epoch: 0202 train_loss= 0.69315 train_acc= 0.00028 time= 1.62653
Epoch: 0203 train_loss= 0.69315 train_acc= 0.00028 time= 1.63976
Epoch: 0204 train_loss= 0.69315 train_acc= 0.00028 time= 1.64262
Epoch: 0205 train_loss= 0.69315 train_acc= 0.00028 time= 1.63681
Epoch: 0206 train_loss= 0.69315 train_acc= 0.00028 time= 1.63007
Epoch: 0207 train_loss= 0.69315 train_acc= 0.00028 time= 1.64068
Epoch: 0208 train_loss= 0.69315 train_acc= 0.00028 time= 1.63733
Epoch: 0209 train_loss= 0.69315 train_acc= 0.00028 time= 1.64167
Epoch: 0210 train_loss= 0.69315 train_acc= 0.00028 time= 1.63105
Epoch: 0211 train_loss= 0.69315 train_acc= 0.00028 time= 1.62206
Epoch: 0212 train_loss= 0.69315 train_acc= 0.00028 time= 1.63234
Epoch: 0213 train_loss= 0.69315 train_acc= 0.00028 time= 1.63505
Epoch: 0214 train_loss= 0.69315 train_acc= 0.00028 time= 1.63075
Epoch: 0215 train_loss= 0.69315 train_acc= 0.00028 time= 1.63127
Epoch: 0216 train_loss= 0.69315 train_acc= 0.00028 time= 1.64157
Epoch: 0217 train_loss= 0.69315 train_acc= 0.00028 time= 1.65590
Epoch: 0218 train_loss= 0.69315 train_acc= 0.00028 time= 1.64836
Epoch: 0219 train_loss= 0.69315 train_acc= 0.00028 time= 1.63030
Epoch: 0220 train_loss= 0.69315 train_acc= 0.00028 time= 1.63263
Epoch: 0221 train_loss= 0.69315 train_acc= 0.00028 time= 1.63228
Epoch: 0222 train_loss= 0.69315 train_acc= 0.00028 time= 1.64514
Epoch: 0223 train_loss= 0.69315 train_acc= 0.00028 time= 1.62725
Epoch: 0224 train_loss= 0.69315 train_acc= 0.00028 time= 1.62562
Epoch: 0225 train_loss= 0.69315 train_acc= 0.00028 time= 1.67780
Epoch: 0226 train_loss= 0.69315 train_acc= 0.00028 time= 1.66233
Epoch: 0227 train_loss= 0.69315 train_acc= 0.00028 time= 1.63377
Epoch: 0228 train_loss= 0.69315 train_acc= 0.00028 time= 1.64310
Epoch: 0229 train_loss= 0.69315 train_acc= 0.00028 time= 1.64859
Epoch: 0230 train_loss= 0.69315 train_acc= 0.00028 time= 1.64553
Epoch: 0231 train_loss= 0.69315 train_acc= 0.00028 time= 1.65117
Epoch: 0232 train_loss= 0.69315 train_acc= 0.00028 time= 1.66342
Epoch: 0233 train_loss= 0.69315 train_acc= 0.00028 time= 1.64129
Epoch: 0234 train_loss= 0.69315 train_acc= 0.00028 time= 1.63700
Epoch: 0235 train_loss= 0.69315 train_acc= 0.00028 time= 1.65213
Epoch: 0236 train_loss= 0.69315 train_acc= 0.00028 time= 1.64094
Epoch: 0237 train_loss= 0.69315 train_acc= 0.00028 time= 1.62900
Epoch: 0238 train_loss= 0.69315 train_acc= 0.00028 time= 1.62666
Epoch: 0239 train_loss= 0.69315 train_acc= 0.00028 time= 1.66300
Epoch: 0240 train_loss= 0.69315 train_acc= 0.00028 time= 1.63602
Epoch: 0241 train_loss= 0.69315 train_acc= 0.00028 time= 1.64440
Epoch: 0242 train_loss= 0.69315 train_acc= 0.00028 time= 1.64903
Epoch: 0243 train_loss= 0.69315 train_acc= 0.00028 time= 1.64877
Epoch: 0244 train_loss= 0.69315 train_acc= 0.00028 time= 1.63493
Epoch: 0245 train_loss= 0.69315 train_acc= 0.00028 time= 1.65200
Epoch: 0246 train_loss= 0.69315 train_acc= 0.00028 time= 1.65034
Epoch: 0247 train_loss= 0.69315 train_acc= 0.00028 time= 1.62945
Epoch: 0248 train_loss= 0.69315 train_acc= 0.00028 time= 1.64259
Epoch: 0249 train_loss= 0.69315 train_acc= 0.00028 time= 1.63927
Epoch: 0250 train_loss= 0.69315 train_acc= 0.00028 time= 1.65353
Epoch: 0251 train_loss= 0.69315 train_acc= 0.00028 time= 1.64825
Epoch: 0252 train_loss= 0.69315 train_acc= 0.00028 time= 1.63369
Epoch: 0253 train_loss= 0.69315 train_acc= 0.00028 time= 1.64245
Epoch: 0254 train_loss= 0.69315 train_acc= 0.00028 time= 1.68188
Epoch: 0255 train_loss= 0.69315 train_acc= 0.00028 time= 1.63509
Epoch: 0256 train_loss= 0.69315 train_acc= 0.00028 time= 1.62900
Epoch: 0257 train_loss= 0.69315 train_acc= 0.00028 time= 1.63791
Epoch: 0258 train_loss= 0.69315 train_acc= 0.00028 time= 1.63775
Epoch: 0259 train_loss= 0.69315 train_acc= 0.00028 time= 1.65550
Epoch: 0260 train_loss= 0.69315 train_acc= 0.00028 time= 1.65855
Epoch: 0261 train_loss= 0.69315 train_acc= 0.00028 time= 1.63208
Epoch: 0262 train_loss= 0.69315 train_acc= 0.00028 time= 1.64285
Epoch: 0263 train_loss= 0.69315 train_acc= 0.00028 time= 1.63183
Epoch: 0264 train_loss= 0.69315 train_acc= 0.00028 time= 1.63000
Epoch: 0265 train_loss= 0.69315 train_acc= 0.00028 time= 1.63903
Epoch: 0266 train_loss= 0.69315 train_acc= 0.00028 time= 1.65434
Epoch: 0267 train_loss= 0.69315 train_acc= 0.00028 time= 1.63755
Epoch: 0268 train_loss= 0.69315 train_acc= 0.00028 time= 1.63105
Epoch: 0269 train_loss= 0.69315 train_acc= 0.00028 time= 1.65951
Epoch: 0270 train_loss= 0.69315 train_acc= 0.00028 time= 1.65951
Epoch: 0271 train_loss= 0.69315 train_acc= 0.00028 time= 1.63815
Epoch: 0272 train_loss= 0.69315 train_acc= 0.00028 time= 1.62986
Epoch: 0273 train_loss= 0.69315 train_acc= 0.00028 time= 1.63506
Epoch: 0274 train_loss= 0.69315 train_acc= 0.00028 time= 1.62677
Epoch: 0275 train_loss= 0.69315 train_acc= 0.00028 time= 1.62325
Epoch: 0276 train_loss= 0.69315 train_acc= 0.00028 time= 1.64900
Epoch: 0277 train_loss= 0.69315 train_acc= 0.00028 time= 1.63206
Epoch: 0278 train_loss= 0.69315 train_acc= 0.00028 time= 1.61933
Epoch: 0279 train_loss= 0.69315 train_acc= 0.00028 time= 1.62771
Epoch: 0280 train_loss= 0.69315 train_acc= 0.00028 time= 1.63284
Epoch: 0281 train_loss= 0.69315 train_acc= 0.00028 time= 1.62629
Epoch: 0282 train_loss= 0.69315 train_acc= 0.00028 time= 1.63193
Epoch: 0283 train_loss= 0.69315 train_acc= 0.00028 time= 1.62854
Epoch: 0284 train_loss= 0.69315 train_acc= 0.00028 time= 1.63193
Epoch: 0285 train_loss= 0.69315 train_acc= 0.00028 time= 1.63497
Epoch: 0286 train_loss= 0.69315 train_acc= 0.00028 time= 1.63716
Epoch: 0287 train_loss= 0.69315 train_acc= 0.00028 time= 1.63647
Epoch: 0288 train_loss= 0.69315 train_acc= 0.00028 time= 1.63910
Epoch: 0289 train_loss= 0.69315 train_acc= 0.00028 time= 1.62411
Epoch: 0290 train_loss= 0.69315 train_acc= 0.00028 time= 1.62983
Epoch: 0291 train_loss= 0.69315 train_acc= 0.00028 time= 1.66178
Epoch: 0292 train_loss= 0.69315 train_acc= 0.00028 time= 1.64461
Epoch: 0293 train_loss= 0.69315 train_acc= 0.00028 time= 1.65142
Epoch: 0294 train_loss= 0.69315 train_acc= 0.00028 time= 1.65547
Epoch: 0295 train_loss= 0.69315 train_acc= 0.00028 time= 1.63644
Epoch: 0296 train_loss= 0.69315 train_acc= 0.00028 time= 1.65053
Epoch: 0297 train_loss= 0.69315 train_acc= 0.00028 time= 1.62658
Epoch: 0298 train_loss= 0.69315 train_acc= 0.00028 time= 1.63730
Epoch: 0299 train_loss= 0.69315 train_acc= 0.00028 time= 1.62745
Epoch: 0300 train_loss= 0.69315 train_acc= 0.00028 time= 1.64248
Optimization Finished!
Model: [1.4477413585241923,-8.200847408562162e-14]
Epoch: 0001 train_loss= 36.92236 train_acc= 0.00028 time= 1.70522
Epoch: 0002 train_loss= 263.43005 train_acc= 0.00028 time= 1.64421
Epoch: 0003 train_loss= 18.33514 train_acc= 0.00028 time= 1.65441
Epoch: 0004 train_loss= 0.69315 train_acc= 0.00028 time= 1.63124
Epoch: 0005 train_loss= 0.69315 train_acc= 0.00028 time= 1.64635
Epoch: 0006 train_loss= 0.69315 train_acc= 0.00028 time= 1.63636
Epoch: 0007 train_loss= 0.69315 train_acc= 0.00028 time= 1.65218
Epoch: 0008 train_loss= 0.69315 train_acc= 0.00028 time= 1.65253
Epoch: 0009 train_loss= 0.69315 train_acc= 0.00028 time= 1.64777
Epoch: 0010 train_loss= 0.69315 train_acc= 0.00028 time= 1.66128
Epoch: 0011 train_loss= 0.69315 train_acc= 0.00028 time= 1.66875
Epoch: 0012 train_loss= 0.69315 train_acc= 0.00028 time= 1.65162
Epoch: 0013 train_loss= 0.69315 train_acc= 0.00028 time= 1.65691
Epoch: 0014 train_loss= 0.69315 train_acc= 0.00028 time= 1.63949
Epoch: 0015 train_loss= 0.69315 train_acc= 0.00028 time= 1.63893
Epoch: 0016 train_loss= 0.69315 train_acc= 0.00028 time= 1.64957
Epoch: 0017 train_loss= 0.69315 train_acc= 0.00028 time= 1.64882
Epoch: 0018 train_loss= 0.69315 train_acc= 0.00028 time= 1.62768
Epoch: 0019 train_loss= 0.69315 train_acc= 0.00028 time= 1.63919
Epoch: 0020 train_loss= 0.69315 train_acc= 0.00028 time= 1.64781
Epoch: 0021 train_loss= 0.69315 train_acc= 0.00028 time= 1.64731
Epoch: 0022 train_loss= 0.69315 train_acc= 0.00028 time= 1.66468
Epoch: 0023 train_loss= 0.69315 train_acc= 0.00028 time= 1.65833
Epoch: 0024 train_loss= 0.69315 train_acc= 0.00028 time= 1.64470
Epoch: 0025 train_loss= 0.69315 train_acc= 0.00028 time= 1.63446
Epoch: 0026 train_loss= 0.69315 train_acc= 0.00028 time= 1.64202
Epoch: 0027 train_loss= 0.69315 train_acc= 0.00028 time= 1.65136
Epoch: 0028 train_loss= 0.69315 train_acc= 0.00028 time= 1.66315
Epoch: 0029 train_loss= 0.69315 train_acc= 0.00028 time= 1.65062
Epoch: 0030 train_loss= 0.69315 train_acc= 0.00028 time= 1.63781
Epoch: 0031 train_loss= 0.69315 train_acc= 0.00028 time= 1.63932
Epoch: 0032 train_loss= 0.69315 train_acc= 0.00028 time= 1.62806
Epoch: 0033 train_loss= 0.69315 train_acc= 0.00028 time= 1.63748
Epoch: 0034 train_loss= 0.69315 train_acc= 0.00028 time= 1.66171
Epoch: 0035 train_loss= 0.69315 train_acc= 0.00028 time= 1.64929
Epoch: 0036 train_loss= 0.69315 train_acc= 0.00028 time= 1.64483
Epoch: 0037 train_loss= 0.69315 train_acc= 0.00028 time= 1.64566
Epoch: 0038 train_loss= 0.69315 train_acc= 0.00028 time= 1.64560
Epoch: 0039 train_loss= 0.69315 train_acc= 0.00028 time= 1.64837
Epoch: 0040 train_loss= 0.69315 train_acc= 0.00028 time= 1.63600
Epoch: 0041 train_loss= 0.69315 train_acc= 0.00028 time= 1.66167
Epoch: 0042 train_loss= 0.69315 train_acc= 0.00028 time= 1.66146
Epoch: 0043 train_loss= 0.69315 train_acc= 0.00028 time= 1.64645
Epoch: 0044 train_loss= 0.69315 train_acc= 0.00028 time= 1.67632
Epoch: 0045 train_loss= 0.69315 train_acc= 0.00028 time= 1.66837
Epoch: 0046 train_loss= 0.69315 train_acc= 0.00028 time= 1.64320
Epoch: 0047 train_loss= 0.69315 train_acc= 0.00028 time= 1.63536
Epoch: 0048 train_loss= 0.69315 train_acc= 0.00028 time= 1.64643
Epoch: 0049 train_loss= 0.69315 train_acc= 0.00028 time= 1.63286
Epoch: 0050 train_loss= 0.69315 train_acc= 0.00028 time= 1.64636
Epoch: 0051 train_loss= 0.69315 train_acc= 0.00028 time= 1.64113
Epoch: 0052 train_loss= 0.69315 train_acc= 0.00028 time= 1.66631
Epoch: 0053 train_loss= 0.69315 train_acc= 0.00028 time= 1.63584
Epoch: 0054 train_loss= 0.69315 train_acc= 0.00028 time= 1.64906
Epoch: 0055 train_loss= 0.69315 train_acc= 0.00028 time= 1.63243
Epoch: 0056 train_loss= 0.69315 train_acc= 0.00028 time= 1.64461
Epoch: 0057 train_loss= 0.69315 train_acc= 0.00028 time= 1.63678
Epoch: 0058 train_loss= 0.69315 train_acc= 0.00028 time= 1.65231
Epoch: 0059 train_loss= 0.69315 train_acc= 0.00028 time= 1.66434
Epoch: 0060 train_loss= 0.69315 train_acc= 0.00028 time= 1.63826
Epoch: 0061 train_loss= 0.69315 train_acc= 0.00028 time= 1.64977
Epoch: 0062 train_loss= 0.69315 train_acc= 0.00028 time= 1.64847
Epoch: 0063 train_loss= 0.69315 train_acc= 0.00028 time= 1.63955
Epoch: 0064 train_loss= 0.69315 train_acc= 0.00028 time= 1.69154
Epoch: 0065 train_loss= 0.69315 train_acc= 0.00028 time= 1.65902
Epoch: 0066 train_loss= 0.69315 train_acc= 0.00028 time= 1.64920
Epoch: 0067 train_loss= 0.69315 train_acc= 0.00028 time= 1.66080
Epoch: 0068 train_loss= 0.69315 train_acc= 0.00028 time= 1.62900
Epoch: 0069 train_loss= 0.69315 train_acc= 0.00028 time= 1.64630
Epoch: 0070 train_loss= 0.69315 train_acc= 0.00028 time= 1.64923
Epoch: 0071 train_loss= 0.69315 train_acc= 0.00028 time= 1.64600
Epoch: 0072 train_loss= 0.69315 train_acc= 0.00028 time= 1.63739
Epoch: 0073 train_loss= 0.69315 train_acc= 0.00028 time= 1.65768
Epoch: 0074 train_loss= 0.69315 train_acc= 0.00028 time= 1.63408
Epoch: 0075 train_loss= 0.69315 train_acc= 0.00028 time= 1.64250
Epoch: 0076 train_loss= 0.69315 train_acc= 0.00028 time= 1.65544
Epoch: 0077 train_loss= 0.69315 train_acc= 0.00028 time= 1.64992
Epoch: 0078 train_loss= 0.69315 train_acc= 0.00028 time= 1.65099
Epoch: 0079 train_loss= 0.69315 train_acc= 0.00028 time= 1.65691
Epoch: 0080 train_loss= 0.69315 train_acc= 0.00028 time= 1.65643
Epoch: 0081 train_loss= 0.69315 train_acc= 0.00028 time= 1.67341
Epoch: 0082 train_loss= 0.69315 train_acc= 0.00028 time= 1.65604
Epoch: 0083 train_loss= 0.69315 train_acc= 0.00028 time= 1.64035
Epoch: 0084 train_loss= 0.69315 train_acc= 0.00028 time= 1.63677
Epoch: 0085 train_loss= 0.69315 train_acc= 0.00028 time= 1.65106
Epoch: 0086 train_loss= 0.69315 train_acc= 0.00028 time= 1.63942
Epoch: 0087 train_loss= 0.69315 train_acc= 0.00028 time= 1.64102
Epoch: 0088 train_loss= 0.69315 train_acc= 0.00028 time= 1.64414
Epoch: 0089 train_loss= 0.69315 train_acc= 0.00028 time= 1.65725
Epoch: 0090 train_loss= 0.69315 train_acc= 0.00028 time= 1.63626
Epoch: 0091 train_loss= 0.69315 train_acc= 0.00028 time= 1.65503
Epoch: 0092 train_loss= 0.69315 train_acc= 0.00028 time= 1.63247
Epoch: 0093 train_loss= 0.69315 train_acc= 0.00028 time= 1.63925
Epoch: 0094 train_loss= 0.69315 train_acc= 0.00028 time= 1.63696
Epoch: 0095 train_loss= 0.69315 train_acc= 0.00028 time= 1.64124
Epoch: 0096 train_loss= 0.69315 train_acc= 0.00028 time= 1.63183
Epoch: 0097 train_loss= 0.69315 train_acc= 0.00028 time= 1.63122
Epoch: 0098 train_loss= 0.69315 train_acc= 0.00028 time= 1.64547
Epoch: 0099 train_loss= 0.69315 train_acc= 0.00028 time= 1.63898
Epoch: 0100 train_loss= 0.69315 train_acc= 0.00028 time= 1.65908
Epoch: 0101 train_loss= 0.69315 train_acc= 0.00028 time= 1.65053
Epoch: 0102 train_loss= 0.69315 train_acc= 0.00028 time= 1.65914
Epoch: 0103 train_loss= 0.69315 train_acc= 0.00028 time= 1.63292
Epoch: 0104 train_loss= 0.69315 train_acc= 0.00028 time= 1.65771
Epoch: 0105 train_loss= 0.69315 train_acc= 0.00028 time= 1.64856
Epoch: 0106 train_loss= 0.69315 train_acc= 0.00028 time= 1.66579
Epoch: 0107 train_loss= 0.69315 train_acc= 0.00028 time= 1.66445
Epoch: 0108 train_loss= 0.69315 train_acc= 0.00028 time= 1.68498
Epoch: 0109 train_loss= 0.69315 train_acc= 0.00028 time= 1.64943
Epoch: 0110 train_loss= 0.69315 train_acc= 0.00028 time= 1.64424
Epoch: 0111 train_loss= 0.69315 train_acc= 0.00028 time= 1.66941
Epoch: 0112 train_loss= 0.69315 train_acc= 0.00028 time= 1.67513
Epoch: 0113 train_loss= 0.69315 train_acc= 0.00028 time= 1.64255
Epoch: 0114 train_loss= 0.69315 train_acc= 0.00028 time= 1.65120
Epoch: 0115 train_loss= 0.69315 train_acc= 0.00028 time= 1.64884
Epoch: 0116 train_loss= 0.69315 train_acc= 0.00028 time= 1.63209
Epoch: 0117 train_loss= 0.69315 train_acc= 0.00028 time= 1.63511
Epoch: 0118 train_loss= 0.69315 train_acc= 0.00028 time= 1.65514
Epoch: 0119 train_loss= 0.69315 train_acc= 0.00028 time= 1.65229
Epoch: 0120 train_loss= 0.69315 train_acc= 0.00028 time= 1.64534
Epoch: 0121 train_loss= 0.69315 train_acc= 0.00028 time= 1.63484
Epoch: 0122 train_loss= 0.69315 train_acc= 0.00028 time= 1.62521
Epoch: 0123 train_loss= 0.69315 train_acc= 0.00028 time= 1.63421
Epoch: 0124 train_loss= 0.69315 train_acc= 0.00028 time= 1.63528
Epoch: 0125 train_loss= 0.69315 train_acc= 0.00028 time= 1.64411
Epoch: 0126 train_loss= 0.69315 train_acc= 0.00028 time= 1.63757
Epoch: 0127 train_loss= 0.69315 train_acc= 0.00028 time= 1.64846
Epoch: 0128 train_loss= 0.69315 train_acc= 0.00028 time= 1.64791
Epoch: 0129 train_loss= 0.69315 train_acc= 0.00028 time= 1.64819
Epoch: 0130 train_loss= 0.69315 train_acc= 0.00028 time= 1.63349
Epoch: 0131 train_loss= 0.69315 train_acc= 0.00028 time= 1.63244
Epoch: 0132 train_loss= 0.69315 train_acc= 0.00028 time= 1.64592
Epoch: 0133 train_loss= 0.69315 train_acc= 0.00028 time= 1.63399
Epoch: 0134 train_loss= 0.69315 train_acc= 0.00028 time= 1.65370
Epoch: 0135 train_loss= 0.69315 train_acc= 0.00028 time= 1.67861
Epoch: 0136 train_loss= 0.69315 train_acc= 0.00028 time= 1.63513
Epoch: 0137 train_loss= 0.69315 train_acc= 0.00028 time= 1.64565
Epoch: 0138 train_loss= 0.69315 train_acc= 0.00028 time= 1.64784
Epoch: 0139 train_loss= 0.69315 train_acc= 0.00028 time= 1.63912
Epoch: 0140 train_loss= 0.69315 train_acc= 0.00028 time= 1.67063
Epoch: 0141 train_loss= 0.69315 train_acc= 0.00028 time= 1.64315
Epoch: 0142 train_loss= 0.69315 train_acc= 0.00028 time= 1.65996
Epoch: 0143 train_loss= 0.69315 train_acc= 0.00028 time= 1.65376
Epoch: 0144 train_loss= 0.69315 train_acc= 0.00028 time= 1.64818
Epoch: 0145 train_loss= 0.69315 train_acc= 0.00028 time= 1.65492
Epoch: 0146 train_loss= 0.69315 train_acc= 0.00028 time= 1.66016
Epoch: 0147 train_loss= 0.69315 train_acc= 0.00028 time= 1.64691
Epoch: 0148 train_loss= 0.69315 train_acc= 0.00028 time= 1.63745
Epoch: 0149 train_loss= 0.69315 train_acc= 0.00028 time= 1.64580
Epoch: 0150 train_loss= 0.69315 train_acc= 0.00028 time= 1.64323
Epoch: 0151 train_loss= 0.69315 train_acc= 0.00028 time= 1.64023
Epoch: 0152 train_loss= 0.69315 train_acc= 0.00028 time= 1.66332
Epoch: 0153 train_loss= 0.69315 train_acc= 0.00028 time= 1.69329
Epoch: 0154 train_loss= 0.69315 train_acc= 0.00028 time= 1.66282
Epoch: 0155 train_loss= 0.69315 train_acc= 0.00028 time= 1.64340
Epoch: 0156 train_loss= 0.69315 train_acc= 0.00028 time= 1.63088
Epoch: 0157 train_loss= 0.69315 train_acc= 0.00028 time= 1.62856
Epoch: 0158 train_loss= 0.69315 train_acc= 0.00028 time= 1.64398
Epoch: 0159 train_loss= 0.69315 train_acc= 0.00028 time= 1.65909
Epoch: 0160 train_loss= 0.69315 train_acc= 0.00028 time= 1.64664
Epoch: 0161 train_loss= 0.69315 train_acc= 0.00028 time= 1.64155
Epoch: 0162 train_loss= 0.69315 train_acc= 0.00028 time= 1.66156
Epoch: 0163 train_loss= 0.69315 train_acc= 0.00028 time= 1.64929
Epoch: 0164 train_loss= 0.69315 train_acc= 0.00028 time= 1.65194
Epoch: 0165 train_loss= 0.69315 train_acc= 0.00028 time= 1.64242
Epoch: 0166 train_loss= 0.69315 train_acc= 0.00028 time= 1.64067
Epoch: 0167 train_loss= 0.69315 train_acc= 0.00028 time= 1.62787
Epoch: 0168 train_loss= 0.69315 train_acc= 0.00028 time= 1.64762
Epoch: 0169 train_loss= 0.69315 train_acc= 0.00028 time= 1.64267
Epoch: 0170 train_loss= 0.69315 train_acc= 0.00028 time= 1.64146
Epoch: 0171 train_loss= 0.69315 train_acc= 0.00028 time= 1.64576
Epoch: 0172 train_loss= 0.69315 train_acc= 0.00028 time= 1.64180
Epoch: 0173 train_loss= 0.69315 train_acc= 0.00028 time= 1.65097
Epoch: 0174 train_loss= 0.69315 train_acc= 0.00028 time= 1.65243
Epoch: 0175 train_loss= 0.69315 train_acc= 0.00028 time= 1.62114
Epoch: 0176 train_loss= 0.69315 train_acc= 0.00028 time= 1.65921
Epoch: 0177 train_loss= 0.69315 train_acc= 0.00028 time= 1.64446
Epoch: 0178 train_loss= 0.69315 train_acc= 0.00028 time= 1.64986
Epoch: 0179 train_loss= 0.69315 train_acc= 0.00028 time= 1.63337
Epoch: 0180 train_loss= 0.69315 train_acc= 0.00028 time= 1.62754
Epoch: 0181 train_loss= 0.69315 train_acc= 0.00028 time= 1.64139
Epoch: 0182 train_loss= 0.69315 train_acc= 0.00028 time= 1.63023
Epoch: 0183 train_loss= 0.69315 train_acc= 0.00028 time= 1.66517
Epoch: 0184 train_loss= 0.69315 train_acc= 0.00028 time= 1.64141
Epoch: 0185 train_loss= 0.69315 train_acc= 0.00028 time= 1.65636
Epoch: 0186 train_loss= 0.69315 train_acc= 0.00028 time= 1.64795
Epoch: 0187 train_loss= 0.69315 train_acc= 0.00028 time= 1.63980
Epoch: 0188 train_loss= 0.69315 train_acc= 0.00028 time= 1.63464
Epoch: 0189 train_loss= 0.69315 train_acc= 0.00028 time= 1.63448
Epoch: 0190 train_loss= 0.69315 train_acc= 0.00028 time= 1.62959
Epoch: 0191 train_loss= 0.69315 train_acc= 0.00028 time= 1.63853
Epoch: 0192 train_loss= 0.69315 train_acc= 0.00028 time= 1.65057
Epoch: 0193 train_loss= 0.69315 train_acc= 0.00028 time= 1.67178
Epoch: 0194 train_loss= 0.69315 train_acc= 0.00028 time= 1.63878
Epoch: 0195 train_loss= 0.69315 train_acc= 0.00028 time= 1.64773
Epoch: 0196 train_loss= 0.69315 train_acc= 0.00028 time= 1.65933
Epoch: 0197 train_loss= 0.69315 train_acc= 0.00028 time= 1.63301
Epoch: 0198 train_loss= 0.69315 train_acc= 0.00028 time= 1.64184
Epoch: 0199 train_loss= 0.69315 train_acc= 0.00028 time= 1.63687
Epoch: 0200 train_loss= 0.69315 train_acc= 0.00028 time= 1.65931
Epoch: 0201 train_loss= 0.69315 train_acc= 0.00028 time= 1.65348
Epoch: 0202 train_loss= 0.69315 train_acc= 0.00028 time= 1.63776
Epoch: 0203 train_loss= 0.69315 train_acc= 0.00028 time= 1.64012
Epoch: 0204 train_loss= 0.69315 train_acc= 0.00028 time= 1.67015
Epoch: 0205 train_loss= 0.69315 train_acc= 0.00028 time= 1.64370
Epoch: 0206 train_loss= 0.69315 train_acc= 0.00028 time= 1.64030
Epoch: 0207 train_loss= 0.69315 train_acc= 0.00028 time= 1.64531
Epoch: 0208 train_loss= 0.69315 train_acc= 0.00028 time= 1.64999
Epoch: 0209 train_loss= 0.69315 train_acc= 0.00028 time= 1.63717
Epoch: 0210 train_loss= 0.69315 train_acc= 0.00028 time= 1.64389
Epoch: 0211 train_loss= 0.69315 train_acc= 0.00028 time= 1.62222
Epoch: 0212 train_loss= 0.69315 train_acc= 0.00028 time= 1.65076
Epoch: 0213 train_loss= 0.69315 train_acc= 0.00028 time= 1.64683
Epoch: 0214 train_loss= 0.69315 train_acc= 0.00028 time= 1.63336
Epoch: 0215 train_loss= 0.69315 train_acc= 0.00028 time= 1.64269
Epoch: 0216 train_loss= 0.69315 train_acc= 0.00028 time= 1.64661
Epoch: 0217 train_loss= 0.69315 train_acc= 0.00028 time= 1.64190
Epoch: 0218 train_loss= 0.69315 train_acc= 0.00028 time= 1.64536
Epoch: 0219 train_loss= 0.69315 train_acc= 0.00028 time= 1.61907
Epoch: 0220 train_loss= 0.69315 train_acc= 0.00028 time= 1.62976
Epoch: 0221 train_loss= 0.69315 train_acc= 0.00028 time= 1.65453
Epoch: 0222 train_loss= 0.69315 train_acc= 0.00028 time= 1.63779
Epoch: 0223 train_loss= 0.69315 train_acc= 0.00028 time= 1.63413
Epoch: 0224 train_loss= 0.69315 train_acc= 0.00028 time= 1.63892
Epoch: 0225 train_loss= 0.69315 train_acc= 0.00028 time= 1.64697
Epoch: 0226 train_loss= 0.69315 train_acc= 0.00028 time= 1.64599
Epoch: 0227 train_loss= 0.69315 train_acc= 0.00028 time= 1.65262
Epoch: 0228 train_loss= 0.69315 train_acc= 0.00028 time= 1.64406
Epoch: 0229 train_loss= 0.69315 train_acc= 0.00028 time= 1.65070
Epoch: 0230 train_loss= 0.69315 train_acc= 0.00028 time= 1.64504
Epoch: 0231 train_loss= 0.69315 train_acc= 0.00028 time= 1.65434
Epoch: 0232 train_loss= 0.69315 train_acc= 0.00028 time= 1.64506
Epoch: 0233 train_loss= 0.69315 train_acc= 0.00028 time= 1.65313
Epoch: 0234 train_loss= 0.69315 train_acc= 0.00028 time= 1.64741
Epoch: 0235 train_loss= 0.69315 train_acc= 0.00028 time= 1.65858
Epoch: 0236 train_loss= 0.69315 train_acc= 0.00028 time= 1.64146
Epoch: 0237 train_loss= 0.69315 train_acc= 0.00028 time= 1.63754
Epoch: 0238 train_loss= 0.69315 train_acc= 0.00028 time= 1.62100
Epoch: 0239 train_loss= 0.69315 train_acc= 0.00028 time= 1.64536
Epoch: 0240 train_loss= 0.69315 train_acc= 0.00028 time= 1.65839
Epoch: 0241 train_loss= 0.69315 train_acc= 0.00028 time= 1.64751
Epoch: 0242 train_loss= 0.69315 train_acc= 0.00028 time= 1.66683
Epoch: 0243 train_loss= 0.69315 train_acc= 0.00028 time= 1.63110
Epoch: 0244 train_loss= 0.69315 train_acc= 0.00028 time= 1.65637
Epoch: 0245 train_loss= 0.69315 train_acc= 0.00028 time= 1.64587
Epoch: 0246 train_loss= 0.69315 train_acc= 0.00028 time= 1.64097
Epoch: 0247 train_loss= 0.69315 train_acc= 0.00028 time= 1.66433
Epoch: 0248 train_loss= 0.69315 train_acc= 0.00028 time= 1.66490
Epoch: 0249 train_loss= 0.69315 train_acc= 0.00028 time= 1.64471
Epoch: 0250 train_loss= 0.69315 train_acc= 0.00028 time= 1.63886
Epoch: 0251 train_loss= 0.69315 train_acc= 0.00028 time= 1.63213
Epoch: 0252 train_loss= 0.69315 train_acc= 0.00028 time= 1.63698
Epoch: 0253 train_loss= 0.69315 train_acc= 0.00028 time= 1.66485
Epoch: 0254 train_loss= 0.69315 train_acc= 0.00028 time= 1.65517
Epoch: 0255 train_loss= 0.69315 train_acc= 0.00028 time= 1.66321
Epoch: 0256 train_loss= 0.69315 train_acc= 0.00028 time= 1.63233
Epoch: 0257 train_loss= 0.69315 train_acc= 0.00028 time= 1.63700
Epoch: 0258 train_loss= 0.69315 train_acc= 0.00028 time= 1.64609
Epoch: 0259 train_loss= 0.69315 train_acc= 0.00028 time= 1.64571
Epoch: 0260 train_loss= 0.69315 train_acc= 0.00028 time= 1.63143
Epoch: 0261 train_loss= 0.69315 train_acc= 0.00028 time= 1.65222
Epoch: 0262 train_loss= 0.69315 train_acc= 0.00028 time= 1.66047
Epoch: 0263 train_loss= 0.69315 train_acc= 0.00028 time= 1.65208
Epoch: 0264 train_loss= 0.69315 train_acc= 0.00028 time= 1.64369
Epoch: 0265 train_loss= 0.69315 train_acc= 0.00028 time= 1.64687
Epoch: 0266 train_loss= 0.69315 train_acc= 0.00028 time= 1.64737
Epoch: 0267 train_loss= 0.69315 train_acc= 0.00028 time= 1.64230
Epoch: 0268 train_loss= 0.69315 train_acc= 0.00028 time= 1.64236
Epoch: 0269 train_loss= 0.69315 train_acc= 0.00028 time= 1.65405
Epoch: 0270 train_loss= 0.69315 train_acc= 0.00028 time= 1.64734
Epoch: 0271 train_loss= 0.69315 train_acc= 0.00028 time= 1.62032
Epoch: 0272 train_loss= 0.69315 train_acc= 0.00028 time= 1.64316
Epoch: 0273 train_loss= 0.69315 train_acc= 0.00028 time= 1.64961
Epoch: 0274 train_loss= 0.69315 train_acc= 0.00028 time= 1.65160
Epoch: 0275 train_loss= 0.69315 train_acc= 0.00028 time= 1.65315
Epoch: 0276 train_loss= 0.69315 train_acc= 0.00028 time= 1.64643
Epoch: 0277 train_loss= 0.69315 train_acc= 0.00028 time= 1.65016
Epoch: 0278 train_loss= 0.69315 train_acc= 0.00028 time= 1.64530
Epoch: 0279 train_loss= 0.69315 train_acc= 0.00028 time= 1.64005
Epoch: 0280 train_loss= 0.69315 train_acc= 0.00028 time= 1.66507
Epoch: 0281 train_loss= 0.69315 train_acc= 0.00028 time= 1.66110
Epoch: 0282 train_loss= 0.69315 train_acc= 0.00028 time= 1.63867
Epoch: 0283 train_loss= 0.69315 train_acc= 0.00028 time= 1.66206
Epoch: 0284 train_loss= 0.69315 train_acc= 0.00028 time= 1.66425
Epoch: 0285 train_loss= 0.69315 train_acc= 0.00028 time= 1.64759
Epoch: 0286 train_loss= 0.69315 train_acc= 0.00028 time= 1.64324
Epoch: 0287 train_loss= 0.69315 train_acc= 0.00028 time= 1.63778
Epoch: 0288 train_loss= 0.69315 train_acc= 0.00028 time= 1.63707
Epoch: 0289 train_loss= 0.69315 train_acc= 0.00028 time= 1.64571
Epoch: 0290 train_loss= 0.69315 train_acc= 0.00028 time= 1.67764
Epoch: 0291 train_loss= 0.69315 train_acc= 0.00028 time= 1.64241
Epoch: 0292 train_loss= 0.69315 train_acc= 0.00028 time= 1.64654
Epoch: 0293 train_loss= 0.69315 train_acc= 0.00028 time= 1.64602
Epoch: 0294 train_loss= 0.69315 train_acc= 0.00028 time= 1.65228
Epoch: 0295 train_loss= 0.69315 train_acc= 0.00028 time= 1.64763
Epoch: 0296 train_loss= 0.69315 train_acc= 0.00028 time= 1.65301
Epoch: 0297 train_loss= 0.69315 train_acc= 0.00028 time= 1.64069
Epoch: 0298 train_loss= 0.69315 train_acc= 0.00028 time= 1.65782
Epoch: 0299 train_loss= 0.69315 train_acc= 0.00028 time= 1.70427
Epoch: 0300 train_loss= 0.69315 train_acc= 0.00028 time= 1.63955
Optimization Finished!
Model: [1.447743137943939,-3.767356796894785e-14]
Epoch: 0001 train_loss= 116.81508 train_acc= 0.10630 time= 3.14024
Epoch: 0002 train_loss= 105694838917269815296.00000 train_acc= 0.49285 time= 1.77984
Epoch: 0003 train_loss= nan train_acc= 0.99972 time= 1.77977
Epoch: 0004 train_loss= nan train_acc= 0.99972 time= 1.76739
Epoch: 0005 train_loss= nan train_acc= 0.99972 time= 1.77247
Epoch: 0006 train_loss= nan train_acc= 0.99972 time= 1.76951
Epoch: 0007 train_loss= nan train_acc= 0.99972 time= 1.76083
Epoch: 0008 train_loss= nan train_acc= 0.99972 time= 1.78862
Epoch: 0009 train_loss= nan train_acc= 0.99972 time= 1.79317
Epoch: 0010 train_loss= nan train_acc= 0.99972 time= 1.73916
Epoch: 0011 train_loss= nan train_acc= 0.99972 time= 1.79986
Epoch: 0012 train_loss= nan train_acc= 0.99972 time= 1.77443
Epoch: 0013 train_loss= nan train_acc= 0.99972 time= 1.76634
Epoch: 0014 train_loss= nan train_acc= 0.99972 time= 1.74356
Epoch: 0015 train_loss= nan train_acc= 0.99972 time= 1.80041
Epoch: 0016 train_loss= nan train_acc= 0.99972 time= 1.79059
Epoch: 0017 train_loss= nan train_acc= 0.99972 time= 1.81137
Epoch: 0018 train_loss= nan train_acc= 0.99972 time= 1.77373
Epoch: 0019 train_loss= nan train_acc= 0.99972 time= 1.78633
Epoch: 0020 train_loss= nan train_acc= 0.99972 time= 1.74944
Epoch: 0021 train_loss= nan train_acc= 0.99972 time= 1.78349
Epoch: 0022 train_loss= nan train_acc= 0.99972 time= 1.76709
Epoch: 0023 train_loss= nan train_acc= 0.99972 time= 1.77458
Epoch: 0024 train_loss= nan train_acc= 0.99972 time= 1.78709
Epoch: 0025 train_loss= nan train_acc= 0.99972 time= 1.74866
Epoch: 0026 train_loss= nan train_acc= 0.99972 time= 1.73236
Epoch: 0027 train_loss= nan train_acc= 0.99972 time= 1.80828
Epoch: 0028 train_loss= nan train_acc= 0.99972 time= 1.79608
Epoch: 0029 train_loss= nan train_acc= 0.99972 time= 1.79169
Epoch: 0030 train_loss= nan train_acc= 0.99972 time= 1.82685
Epoch: 0031 train_loss= nan train_acc= 0.99972 time= 1.75113
Epoch: 0032 train_loss= nan train_acc= 0.99972 time= 1.74454
Epoch: 0033 train_loss= nan train_acc= 0.99972 time= 1.74520
Epoch: 0034 train_loss= nan train_acc= 0.99972 time= 1.76760
Epoch: 0035 train_loss= nan train_acc= 0.99972 time= 1.78670
Epoch: 0036 train_loss= nan train_acc= 0.99972 time= 1.74983
Epoch: 0037 train_loss= nan train_acc= 0.99972 time= 1.81088
Epoch: 0038 train_loss= nan train_acc= 0.99972 time= 1.76171
Epoch: 0039 train_loss= nan train_acc= 0.99972 time= 1.75187
Epoch: 0040 train_loss= nan train_acc= 0.99972 time= 1.78362
Epoch: 0041 train_loss= nan train_acc= 0.99972 time= 1.75707
Epoch: 0042 train_loss= nan train_acc= 0.99972 time= 1.78874
Epoch: 0043 train_loss= nan train_acc= 0.99972 time= 1.82139
Epoch: 0044 train_loss= nan train_acc= 0.99972 time= 1.77972
Epoch: 0045 train_loss= nan train_acc= 0.99972 time= 1.76460
Epoch: 0046 train_loss= nan train_acc= 0.99972 time= 1.71905
Epoch: 0047 train_loss= nan train_acc= 0.99972 time= 1.75990
Epoch: 0048 train_loss= nan train_acc= 0.99972 time= 1.77323
Epoch: 0049 train_loss= nan train_acc= 0.99972 time= 1.78747
Epoch: 0050 train_loss= nan train_acc= 0.99972 time= 1.75283
Epoch: 0051 train_loss= nan train_acc= 0.99972 time= 1.79913
Epoch: 0052 train_loss= nan train_acc= 0.99972 time= 1.78344
Epoch: 0053 train_loss= nan train_acc= 0.99972 time= 1.73410
Epoch: 0054 train_loss= nan train_acc= 0.99972 time= 1.80360
Epoch: 0055 train_loss= nan train_acc= 0.99972 time= 1.76212
Epoch: 0056 train_loss= nan train_acc= 0.99972 time= 1.75081
Epoch: 0057 train_loss= nan train_acc= 0.99972 time= 1.71487
Epoch: 0058 train_loss= nan train_acc= 0.99972 time= 1.77669
Epoch: 0059 train_loss= nan train_acc= 0.99972 time= 1.75129
Epoch: 0060 train_loss= nan train_acc= 0.99972 time= 1.79126
Epoch: 0061 train_loss= nan train_acc= 0.99972 time= 1.80787
Epoch: 0062 train_loss= nan train_acc= 0.99972 time= 1.72075
Epoch: 0063 train_loss= nan train_acc= 0.99972 time= 1.75591
Epoch: 0064 train_loss= nan train_acc= 0.99972 time= 1.78225
Epoch: 0065 train_loss= nan train_acc= 0.99972 time= 1.78451
Epoch: 0066 train_loss= nan train_acc= 0.99972 time= 1.83056
Epoch: 0067 train_loss= nan train_acc= 0.99972 time= 1.79099
Epoch: 0068 train_loss= nan train_acc= 0.99972 time= 1.78141
Epoch: 0069 train_loss= nan train_acc= 0.99972 time= 1.77851
Epoch: 0070 train_loss= nan train_acc= 0.99972 time= 1.75515
Epoch: 0071 train_loss= nan train_acc= 0.99972 time= 1.72071
Epoch: 0072 train_loss= nan train_acc= 0.99972 time= 1.77606
Epoch: 0073 train_loss= nan train_acc= 0.99972 time= 1.72913
Epoch: 0074 train_loss= nan train_acc= 0.99972 time= 1.78227
Epoch: 0075 train_loss= nan train_acc= 0.99972 time= 1.79459
Epoch: 0076 train_loss= nan train_acc= 0.99972 time= 1.78696
Epoch: 0077 train_loss= nan train_acc= 0.99972 time= 1.74284
Epoch: 0078 train_loss= nan train_acc= 0.99972 time= 1.79651
Epoch: 0079 train_loss= nan train_acc= 0.99972 time= 1.76987
Epoch: 0080 train_loss= nan train_acc= 0.99972 time= 1.81519
Epoch: 0081 train_loss= nan train_acc= 0.99972 time= 1.76099
Epoch: 0082 train_loss= nan train_acc= 0.99972 time= 1.73679
Epoch: 0083 train_loss= nan train_acc= 0.99972 time= 1.77989
Epoch: 0084 train_loss= nan train_acc= 0.99972 time= 1.77321
Epoch: 0085 train_loss= nan train_acc= 0.99972 time= 1.79016
Epoch: 0086 train_loss= nan train_acc= 0.99972 time= 1.75088
Epoch: 0087 train_loss= nan train_acc= 0.99972 time= 1.80626
Epoch: 0088 train_loss= nan train_acc= 0.99972 time= 1.74059
Epoch: 0089 train_loss= nan train_acc= 0.99972 time= 1.78378
Epoch: 0090 train_loss= nan train_acc= 0.99972 time= 1.74534
Epoch: 0091 train_loss= nan train_acc= 0.99972 time= 1.79519
Epoch: 0092 train_loss= nan train_acc= 0.99972 time= 1.79778
Epoch: 0093 train_loss= nan train_acc= 0.99972 time= 1.76950
Epoch: 0094 train_loss= nan train_acc= 0.99972 time= 1.75780
Epoch: 0095 train_loss= nan train_acc= 0.99972 time= 1.79953
Epoch: 0096 train_loss= nan train_acc= 0.99972 time= 1.79754
Epoch: 0097 train_loss= nan train_acc= 0.99972 time= 1.79365
Epoch: 0098 train_loss= nan train_acc= 0.99972 time= 1.76583
Epoch: 0099 train_loss= nan train_acc= 0.99972 time= 1.75096
Epoch: 0100 train_loss= nan train_acc= 0.99972 time= 1.78791
Epoch: 0101 train_loss= nan train_acc= 0.99972 time= 1.75710
Epoch: 0102 train_loss= nan train_acc= 0.99972 time= 1.79045
Epoch: 0103 train_loss= nan train_acc= 0.99972 time= 1.77005
Epoch: 0104 train_loss= nan train_acc= 0.99972 time= 1.79937
Epoch: 0105 train_loss= nan train_acc= 0.99972 time= 1.78042
Epoch: 0106 train_loss= nan train_acc= 0.99972 time= 1.78542
Epoch: 0107 train_loss= nan train_acc= 0.99972 time= 1.81355
Epoch: 0108 train_loss= nan train_acc= 0.99972 time= 1.76988
Epoch: 0109 train_loss= nan train_acc= 0.99972 time= 1.81596
Epoch: 0110 train_loss= nan train_acc= 0.99972 time= 1.76785
Epoch: 0111 train_loss= nan train_acc= 0.99972 time= 1.75565
Epoch: 0112 train_loss= nan train_acc= 0.99972 time= 1.74336
Epoch: 0113 train_loss= nan train_acc= 0.99972 time= 1.75786
Epoch: 0114 train_loss= nan train_acc= 0.99972 time= 1.80917
Epoch: 0115 train_loss= nan train_acc= 0.99972 time= 1.81028
Epoch: 0116 train_loss= nan train_acc= 0.99972 time= 1.77540
Epoch: 0117 train_loss= nan train_acc= 0.99972 time= 1.75857
Epoch: 0118 train_loss= nan train_acc= 0.99972 time= 1.79206
Epoch: 0119 train_loss= nan train_acc= 0.99972 time= 1.75029
Epoch: 0120 train_loss= nan train_acc= 0.99972 time= 1.73133
Epoch: 0121 train_loss= nan train_acc= 0.99972 time= 1.74538
Epoch: 0122 train_loss= nan train_acc= 0.99972 time= 1.80196
Epoch: 0123 train_loss= nan train_acc= 0.99972 time= 1.77291
Epoch: 0124 train_loss= nan train_acc= 0.99972 time= 1.80122
Epoch: 0125 train_loss= nan train_acc= 0.99972 time= 1.77679
Epoch: 0126 train_loss= nan train_acc= 0.99972 time= 1.73429
Epoch: 0127 train_loss= nan train_acc= 0.99972 time= 1.80917
Epoch: 0128 train_loss= nan train_acc= 0.99972 time= 1.76378
Epoch: 0129 train_loss= nan train_acc= 0.99972 time= 1.78718
Epoch: 0130 train_loss= nan train_acc= 0.99972 time= 1.76076
Epoch: 0131 train_loss= nan train_acc= 0.99972 time= 1.79432
Epoch: 0132 train_loss= nan train_acc= 0.99972 time= 1.76312
Epoch: 0133 train_loss= nan train_acc= 0.99972 time= 1.80478
Epoch: 0134 train_loss= nan train_acc= 0.99972 time= 1.76799
Epoch: 0135 train_loss= nan train_acc= 0.99972 time= 1.76118
Epoch: 0136 train_loss= nan train_acc= 0.99972 time= 1.76999
Epoch: 0137 train_loss= nan train_acc= 0.99972 time= 1.77732
Epoch: 0138 train_loss= nan train_acc= 0.99972 time= 1.75566
Epoch: 0139 train_loss= nan train_acc= 0.99972 time= 1.78431
Epoch: 0140 train_loss= nan train_acc= 0.99972 time= 1.76343
Epoch: 0141 train_loss= nan train_acc= 0.99972 time= 1.74884
Epoch: 0142 train_loss= nan train_acc= 0.99972 time= 1.79748
Epoch: 0143 train_loss= nan train_acc= 0.99972 time= 1.77172
Epoch: 0144 train_loss= nan train_acc= 0.99972 time= 1.76562
Epoch: 0145 train_loss= nan train_acc= 0.99972 time= 1.78685
Epoch: 0146 train_loss= nan train_acc= 0.99972 time= 1.72928
Epoch: 0147 train_loss= nan train_acc= 0.99972 time= 1.72148
Epoch: 0148 train_loss= nan train_acc= 0.99972 time= 1.73810
Epoch: 0149 train_loss= nan train_acc= 0.99972 time= 1.77565
Epoch: 0150 train_loss= nan train_acc= 0.99972 time= 1.75192
Epoch: 0151 train_loss= nan train_acc= 0.99972 time= 1.77226
Epoch: 0152 train_loss= nan train_acc= 0.99972 time= 1.77823
Epoch: 0153 train_loss= nan train_acc= 0.99972 time= 1.73517
Epoch: 0154 train_loss= nan train_acc= 0.99972 time= 1.78546
Epoch: 0155 train_loss= nan train_acc= 0.99972 time= 1.79162
Epoch: 0156 train_loss= nan train_acc= 0.99972 time= 1.78692
Epoch: 0157 train_loss= nan train_acc= 0.99972 time= 1.72808
Epoch: 0158 train_loss= nan train_acc= 0.99972 time= 1.75059
Epoch: 0159 train_loss= nan train_acc= 0.99972 time= 1.76840
Epoch: 0160 train_loss= nan train_acc= 0.99972 time= 1.80674
Epoch: 0161 train_loss= nan train_acc= 0.99972 time= 1.79884
Epoch: 0162 train_loss= nan train_acc= 0.99972 time= 1.76151
Epoch: 0163 train_loss= nan train_acc= 0.99972 time= 1.80385
Epoch: 0164 train_loss= nan train_acc= 0.99972 time= 1.77488
Epoch: 0165 train_loss= nan train_acc= 0.99972 time= 1.76437
Epoch: 0166 train_loss= nan train_acc= 0.99972 time= 1.79368
Epoch: 0167 train_loss= nan train_acc= 0.99972 time= 1.77617
Epoch: 0168 train_loss= nan train_acc= 0.99972 time= 1.76799
Epoch: 0169 train_loss= nan train_acc= 0.99972 time= 1.74562
Epoch: 0170 train_loss= nan train_acc= 0.99972 time= 1.79737
Epoch: 0171 train_loss= nan train_acc= 0.99972 time= 1.72585
Epoch: 0172 train_loss= nan train_acc= 0.99972 time= 1.79165
Epoch: 0173 train_loss= nan train_acc= 0.99972 time= 1.76450
Epoch: 0174 train_loss= nan train_acc= 0.99972 time= 1.78401
Epoch: 0175 train_loss= nan train_acc= 0.99972 time= 1.75272
Epoch: 0176 train_loss= nan train_acc= 0.99972 time= 1.79476
Epoch: 0177 train_loss= nan train_acc= 0.99972 time= 1.77376
Epoch: 0178 train_loss= nan train_acc= 0.99972 time= 1.73660
Epoch: 0179 train_loss= nan train_acc= 0.99972 time= 1.75078
Epoch: 0180 train_loss= nan train_acc= 0.99972 time= 1.78589
Epoch: 0181 train_loss= nan train_acc= 0.99972 time= 1.78970
Epoch: 0182 train_loss= nan train_acc= 0.99972 time= 1.78393
Epoch: 0183 train_loss= nan train_acc= 0.99972 time= 1.74035
Epoch: 0184 train_loss= nan train_acc= 0.99972 time= 1.81078
Epoch: 0185 train_loss= nan train_acc= 0.99972 time= 1.80039
Epoch: 0186 train_loss= nan train_acc= 0.99972 time= 1.75366
Epoch: 0187 train_loss= nan train_acc= 0.99972 time= 1.75181
Epoch: 0188 train_loss= nan train_acc= 0.99972 time= 1.79591
Epoch: 0189 train_loss= nan train_acc= 0.99972 time= 1.76017
Epoch: 0190 train_loss= nan train_acc= 0.99972 time= 1.78226
Epoch: 0191 train_loss= nan train_acc= 0.99972 time= 1.81267
Epoch: 0192 train_loss= nan train_acc= 0.99972 time= 1.76230
Epoch: 0193 train_loss= nan train_acc= 0.99972 time= 1.75863
Epoch: 0194 train_loss= nan train_acc= 0.99972 time= 1.77506
Epoch: 0195 train_loss= nan train_acc= 0.99972 time= 1.77816
Epoch: 0196 train_loss= nan train_acc= 0.99972 time= 1.74615
Epoch: 0197 train_loss= nan train_acc= 0.99972 time= 1.77678
Epoch: 0198 train_loss= nan train_acc= 0.99972 time= 1.74740
Epoch: 0199 train_loss= nan train_acc= 0.99972 time= 1.75789
Epoch: 0200 train_loss= nan train_acc= 0.99972 time= 1.77955
Epoch: 0201 train_loss= nan train_acc= 0.99972 time= 1.76840
Epoch: 0202 train_loss= nan train_acc= 0.99972 time= 1.78375
Epoch: 0203 train_loss= nan train_acc= 0.99972 time= 1.75386
Epoch: 0204 train_loss= nan train_acc= 0.99972 time= 1.78348
Epoch: 0205 train_loss= nan train_acc= 0.99972 time= 1.80098
Epoch: 0206 train_loss= nan train_acc= 0.99972 time= 1.80009
Epoch: 0207 train_loss= nan train_acc= 0.99972 time= 1.73661
Epoch: 0208 train_loss= nan train_acc= 0.99972 time= 1.80914
Epoch: 0209 train_loss= nan train_acc= 0.99972 time= 1.77647
Epoch: 0210 train_loss= nan train_acc= 0.99972 time= 1.74836
Epoch: 0211 train_loss= nan train_acc= 0.99972 time= 1.79051
Epoch: 0212 train_loss= nan train_acc= 0.99972 time= 1.74649
Epoch: 0213 train_loss= nan train_acc= 0.99972 time= 1.72275
Epoch: 0214 train_loss= nan train_acc= 0.99972 time= 1.74506
Epoch: 0215 train_loss= nan train_acc= 0.99972 time= 1.80950
Epoch: 0216 train_loss= nan train_acc= 0.99972 time= 1.79886
Epoch: 0217 train_loss= nan train_acc= 0.99972 time= 1.79756
Epoch: 0218 train_loss= nan train_acc= 0.99972 time= 1.80441
Epoch: 0219 train_loss= nan train_acc= 0.99972 time= 1.79618
Epoch: 0220 train_loss= nan train_acc= 0.99972 time= 1.77487
Epoch: 0221 train_loss= nan train_acc= 0.99972 time= 1.73912
Epoch: 0222 train_loss= nan train_acc= 0.99972 time= 1.80533
Epoch: 0223 train_loss= nan train_acc= 0.99972 time= 1.77666
Epoch: 0224 train_loss= nan train_acc= 0.99972 time= 1.80809
Epoch: 0225 train_loss= nan train_acc= 0.99972 time= 1.81499
Epoch: 0226 train_loss= nan train_acc= 0.99972 time= 1.77476
Epoch: 0227 train_loss= nan train_acc= 0.99972 time= 1.79177
Epoch: 0228 train_loss= nan train_acc= 0.99972 time= 1.76898
Epoch: 0229 train_loss= nan train_acc= 0.99972 time= 1.80982
Epoch: 0230 train_loss= nan train_acc= 0.99972 time= 1.77118
Epoch: 0231 train_loss= nan train_acc= 0.99972 time= 1.77040
Epoch: 0232 train_loss= nan train_acc= 0.99972 time= 1.73817
Epoch: 0233 train_loss= nan train_acc= 0.99972 time= 1.78255
Epoch: 0234 train_loss= nan train_acc= 0.99972 time= 1.77551
Epoch: 0235 train_loss= nan train_acc= 0.99972 time= 1.79588
Epoch: 0236 train_loss= nan train_acc= 0.99972 time= 1.83819
Epoch: 0237 train_loss= nan train_acc= 0.99972 time= 1.75767
Epoch: 0238 train_loss= nan train_acc= 0.99972 time= 1.73865
Epoch: 0239 train_loss= nan train_acc= 0.99972 time= 1.73543
Epoch: 0240 train_loss= nan train_acc= 0.99972 time= 1.74091
Epoch: 0241 train_loss= nan train_acc= 0.99972 time= 1.78137
Epoch: 0242 train_loss= nan train_acc= 0.99972 time= 1.74027
Epoch: 0243 train_loss= nan train_acc= 0.99972 time= 1.74535
Epoch: 0244 train_loss= nan train_acc= 0.99972 time= 1.75720
Epoch: 0245 train_loss= nan train_acc= 0.99972 time= 1.80511
Epoch: 0246 train_loss= nan train_acc= 0.99972 time= 1.73002
Epoch: 0247 train_loss= nan train_acc= 0.99972 time= 1.78936
Epoch: 0248 train_loss= nan train_acc= 0.99972 time= 1.73372
Epoch: 0249 train_loss= nan train_acc= 0.99972 time= 1.82769
Epoch: 0250 train_loss= nan train_acc= 0.99972 time= 1.78347
Epoch: 0251 train_loss= nan train_acc= 0.99972 time= 1.77281
Epoch: 0252 train_loss= nan train_acc= 0.99972 time= 1.80914
Epoch: 0253 train_loss= nan train_acc= 0.99972 time= 1.76198
Epoch: 0254 train_loss= nan train_acc= 0.99972 time= 1.80005
Epoch: 0255 train_loss= nan train_acc= 0.99972 time= 1.82169
Epoch: 0256 train_loss= nan train_acc= 0.99972 time= 1.79690
Epoch: 0257 train_loss= nan train_acc= 0.99972 time= 1.78637
Epoch: 0258 train_loss= nan train_acc= 0.99972 time= 1.73840
Epoch: 0259 train_loss= nan train_acc= 0.99972 time= 1.78468
Epoch: 0260 train_loss= nan train_acc= 0.99972 time= 1.75234
Epoch: 0261 train_loss= nan train_acc= 0.99972 time= 1.78882
Epoch: 0262 train_loss= nan train_acc= 0.99972 time= 1.81038
Epoch: 0263 train_loss= nan train_acc= 0.99972 time= 1.77870
Epoch: 0264 train_loss= nan train_acc= 0.99972 time= 1.73943
Epoch: 0265 train_loss= nan train_acc= 0.99972 time= 1.81707
Epoch: 0266 train_loss= nan train_acc= 0.99972 time= 1.72638
Epoch: 0267 train_loss= nan train_acc= 0.99972 time= 1.73379
Epoch: 0268 train_loss= nan train_acc= 0.99972 time= 1.75534
Epoch: 0269 train_loss= nan train_acc= 0.99972 time= 1.81165
Epoch: 0270 train_loss= nan train_acc= 0.99972 time= 1.76297
Epoch: 0271 train_loss= nan train_acc= 0.99972 time= 1.78070
Epoch: 0272 train_loss= nan train_acc= 0.99972 time= 1.75667
Epoch: 0273 train_loss= nan train_acc= 0.99972 time= 1.74363
Epoch: 0274 train_loss= nan train_acc= 0.99972 time= 1.77204
Epoch: 0275 train_loss= nan train_acc= 0.99972 time= 1.78651
Epoch: 0276 train_loss= nan train_acc= 0.99972 time= 1.73125
Epoch: 0277 train_loss= nan train_acc= 0.99972 time= 1.74414
Epoch: 0278 train_loss= nan train_acc= 0.99972 time= 1.75917
Epoch: 0279 train_loss= nan train_acc= 0.99972 time= 1.79999
Epoch: 0280 train_loss= nan train_acc= 0.99972 time= 1.77181
Epoch: 0281 train_loss= nan train_acc= 0.99972 time= 1.77393
Epoch: 0282 train_loss= nan train_acc= 0.99972 time= 1.78154
Epoch: 0283 train_loss= nan train_acc= 0.99972 time= 1.76621
Epoch: 0284 train_loss= nan train_acc= 0.99972 time= 1.74454
Epoch: 0285 train_loss= nan train_acc= 0.99972 time= 1.83486
Epoch: 0286 train_loss= nan train_acc= 0.99972 time= 1.74175
Epoch: 0287 train_loss= nan train_acc= 0.99972 time= 1.77011
Epoch: 0288 train_loss= nan train_acc= 0.99972 time= 1.73347
Epoch: 0289 train_loss= nan train_acc= 0.99972 time= 1.74785
Epoch: 0290 train_loss= nan train_acc= 0.99972 time= 1.79082
Epoch: 0291 train_loss= nan train_acc= 0.99972 time= 1.76631
Epoch: 0292 train_loss= nan train_acc= 0.99972 time= 1.77063
Epoch: 0293 train_loss= nan train_acc= 0.99972 time= 1.77026
Epoch: 0294 train_loss= nan train_acc= 0.99972 time= 1.80902
Epoch: 0295 train_loss= nan train_acc= 0.99972 time= 1.74992
Epoch: 0296 train_loss= nan train_acc= 0.99972 time= 1.77678
Epoch: 0297 train_loss= nan train_acc= 0.99972 time= 1.81784
Epoch: 0298 train_loss= nan train_acc= 0.99972 time= 1.80780
Epoch: 0299 train_loss= nan train_acc= 0.99972 time= 1.74252
Epoch: 0300 train_loss= nan train_acc= 0.99972 time= 1.75985
Optimization Finished!
Model: [nan,nan]
Epoch: 0001 train_loss= 153.99307 train_acc= 0.11285 time= 3.16975
Epoch: 0002 train_loss= 946566634405888.00000 train_acc= 0.47272 time= 1.73568
Epoch: 0003 train_loss= 32425234432.00000 train_acc= 0.34255 time= 1.76808
Epoch: 0004 train_loss= 12182120684322816.00000 train_acc= 0.44735 time= 1.78788
Epoch: 0005 train_loss= 41909362688.00000 train_acc= 0.27653 time= 1.80761
Epoch: 0006 train_loss= 108585402368.00000 train_acc= 0.28286 time= 1.74842
Epoch: 0007 train_loss= 109151904595968.00000 train_acc= 0.37043 time= 1.78535
Epoch: 0008 train_loss= 73115994238746624.00000 train_acc= 0.44813 time= 1.79205
Epoch: 0009 train_loss= 339976288.00000 train_acc= 0.06923 time= 1.77455
Epoch: 0010 train_loss= 10324.84277 train_acc= 0.00132 time= 1.79610
Epoch: 0011 train_loss= 14343.71387 train_acc= 0.00118 time= 1.79354
Epoch: 0012 train_loss= 7491.09131 train_acc= 0.00095 time= 1.75142
Epoch: 0013 train_loss= 7354.11572 train_acc= 0.00083 time= 1.81076
Epoch: 0014 train_loss= 12408.93848 train_acc= 0.00101 time= 1.82980
Epoch: 0015 train_loss= 51208.78125 train_acc= 0.00282 time= 1.78590
Epoch: 0016 train_loss= 8066.18701 train_acc= 0.00183 time= 1.84080
Epoch: 0017 train_loss= 1470987.62500 train_acc= 0.02330 time= 1.80112
Epoch: 0018 train_loss= 783827.75000 train_acc= 0.01827 time= 1.79237
Epoch: 0019 train_loss= 173897.81250 train_acc= 0.00663 time= 1.80101
Epoch: 0020 train_loss= 130076.16406 train_acc= 0.00737 time= 1.76585
Epoch: 0021 train_loss= 333291.71875 train_acc= 0.01898 time= 1.77619
Epoch: 0022 train_loss= 2631412.50000 train_acc= 0.04331 time= 1.78956
Epoch: 0023 train_loss= 24317296.00000 train_acc= 0.07033 time= 1.79341
Epoch: 0024 train_loss= 94510656.00000 train_acc= 0.10393 time= 1.79814
Epoch: 0025 train_loss= 1081438976.00000 train_acc= 0.14059 time= 1.80632
Epoch: 0026 train_loss= 27478679552.00000 train_acc= 0.16919 time= 1.74357
Epoch: 0027 train_loss= 42378821632.00000 train_acc= 0.19752 time= 1.76732
Epoch: 0028 train_loss= 158692507648.00000 train_acc= 0.21964 time= 1.80427
Epoch: 0029 train_loss= 460619907072.00000 train_acc= 0.23593 time= 1.79786
Epoch: 0030 train_loss= 3282474369024.00000 train_acc= 0.25388 time= 1.76530
Epoch: 0031 train_loss= 2917045108736.00000 train_acc= 0.26520 time= 1.75637
Epoch: 0032 train_loss= 6707007717376.00000 train_acc= 0.27666 time= 1.81769
Epoch: 0033 train_loss= 15077509955584.00000 train_acc= 0.27634 time= 1.76189
Epoch: 0034 train_loss= 51384212783104.00000 train_acc= 0.28003 time= 1.79053
Epoch: 0035 train_loss= 49073201610752.00000 train_acc= 0.27901 time= 1.79226
Epoch: 0036 train_loss= 114832829317120.00000 train_acc= 0.27294 time= 1.79738
Epoch: 0037 train_loss= 307906171895808.00000 train_acc= 0.26238 time= 1.75790
Epoch: 0038 train_loss= 29473856552960.00000 train_acc= 0.24109 time= 1.75364
Epoch: 0039 train_loss= 23541202288640.00000 train_acc= 0.22091 time= 1.74736
Epoch: 0040 train_loss= 17532821962752.00000 train_acc= 0.20431 time= 1.80637
Epoch: 0041 train_loss= 54115220586496.00000 train_acc= 0.18731 time= 1.78296
Epoch: 0042 train_loss= 13128414789632.00000 train_acc= 0.17114 time= 1.76514
Epoch: 0043 train_loss= 8232575172608.00000 train_acc= 0.15257 time= 1.76862
Epoch: 0044 train_loss= 4086104064000.00000 train_acc= 0.13891 time= 1.79145
Epoch: 0045 train_loss= 4898422784000.00000 train_acc= 0.12806 time= 1.77853
Epoch: 0046 train_loss= 1961194815488.00000 train_acc= 0.12291 time= 1.77206
Epoch: 0047 train_loss= 7684778098688.00000 train_acc= 0.11367 time= 1.80018
Epoch: 0048 train_loss= 1212066037760.00000 train_acc= 0.11424 time= 1.78482
Epoch: 0049 train_loss= 877682884608.00000 train_acc= 0.10793 time= 1.81490
Epoch: 0050 train_loss= 1400800935936.00000 train_acc= 0.10834 time= 1.80725
Epoch: 0051 train_loss= 380711403520.00000 train_acc= 0.10823 time= 1.81418
Epoch: 0052 train_loss= 239770124288.00000 train_acc= 0.11365 time= 1.79026
Epoch: 0053 train_loss= 257555431424.00000 train_acc= 0.11534 time= 1.82807
Epoch: 0054 train_loss= 466186403840.00000 train_acc= 0.12238 time= 1.76533
Epoch: 0055 train_loss= 142606450688.00000 train_acc= 0.13097 time= 1.76569
Epoch: 0056 train_loss= 122010828800.00000 train_acc= 0.13810 time= 1.76319
Epoch: 0057 train_loss= 117798027264.00000 train_acc= 0.14425 time= 1.77994
Epoch: 0058 train_loss= 77916168192.00000 train_acc= 0.14840 time= 1.78555
Epoch: 0059 train_loss= 112596975616.00000 train_acc= 0.15778 time= 1.78742
Epoch: 0060 train_loss= 93429366784.00000 train_acc= 0.16402 time= 1.80234
Epoch: 0061 train_loss= 81190854656.00000 train_acc= 0.16868 time= 1.76704
Epoch: 0062 train_loss= 113281613824.00000 train_acc= 0.17361 time= 1.76335
Epoch: 0063 train_loss= 45991256064.00000 train_acc= 0.17515 time= 1.78279
Epoch: 0064 train_loss= 43147591680.00000 train_acc= 0.17839 time= 1.78802
Epoch: 0065 train_loss= 206568292352.00000 train_acc= 0.17898 time= 1.76056
Epoch: 0066 train_loss= 110929149952.00000 train_acc= 0.17908 time= 1.78056
Epoch: 0067 train_loss= 128619413504.00000 train_acc= 0.17509 time= 1.79691
Epoch: 0068 train_loss= 144144973824.00000 train_acc= 0.17685 time= 1.75773
Epoch: 0069 train_loss= 28036120576.00000 train_acc= 0.17375 time= 1.79258
Epoch: 0070 train_loss= 62723899392.00000 train_acc= 0.17338 time= 1.79541
Epoch: 0071 train_loss= 38186229760.00000 train_acc= 0.17478 time= 1.79083
Epoch: 0072 train_loss= 33079029760.00000 train_acc= 0.17364 time= 1.74902
Epoch: 0073 train_loss= 48483598336.00000 train_acc= 0.17285 time= 1.78773
Epoch: 0074 train_loss= 37029257216.00000 train_acc= 0.16888 time= 1.76486
Epoch: 0075 train_loss= 32437346304.00000 train_acc= 0.17016 time= 1.83764
Epoch: 0076 train_loss= 21714569216.00000 train_acc= 0.16590 time= 1.76969
Epoch: 0077 train_loss= 43616862208.00000 train_acc= 0.16850 time= 1.79967
Epoch: 0078 train_loss= 41623425024.00000 train_acc= 0.16735 time= 1.75691
Epoch: 0079 train_loss= 66434482176.00000 train_acc= 0.16381 time= 1.75105
Epoch: 0080 train_loss= 24507146240.00000 train_acc= 0.16742 time= 1.79363
Epoch: 0081 train_loss= 23572744192.00000 train_acc= 0.16547 time= 1.78600
Epoch: 0082 train_loss= 27802767360.00000 train_acc= 0.16696 time= 1.75551
Epoch: 0083 train_loss= 20514269184.00000 train_acc= 0.16567 time= 1.80105
Epoch: 0084 train_loss= 21398325248.00000 train_acc= 0.16699 time= 1.77400
Epoch: 0085 train_loss= 21047779328.00000 train_acc= 0.16853 time= 1.73700
Epoch: 0086 train_loss= 68022853632.00000 train_acc= 0.17095 time= 1.80163
Epoch: 0087 train_loss= 26029234176.00000 train_acc= 0.16924 time= 1.76220
Epoch: 0088 train_loss= 113211154432.00000 train_acc= 0.16819 time= 1.79125
Epoch: 0089 train_loss= 20930656256.00000 train_acc= 0.16566 time= 1.76588
Epoch: 0090 train_loss= 51107463168.00000 train_acc= 0.16919 time= 1.80329
Epoch: 0091 train_loss= 17929353216.00000 train_acc= 0.17302 time= 1.77682
Epoch: 0092 train_loss= 100884512768.00000 train_acc= 0.17011 time= 1.74419
Epoch: 0093 train_loss= 33611524096.00000 train_acc= 0.17125 time= 1.76714
Epoch: 0094 train_loss= 66023559168.00000 train_acc= 0.16759 time= 1.80134
Epoch: 0095 train_loss= 19561213952.00000 train_acc= 0.16927 time= 1.83887
Epoch: 0096 train_loss= 40623693824.00000 train_acc= 0.17522 time= 1.79829
Epoch: 0097 train_loss= 17358694400.00000 train_acc= 0.17095 time= 1.79621
Epoch: 0098 train_loss= 29342881792.00000 train_acc= 0.16806 time= 1.79204
Epoch: 0099 train_loss= 83751329792.00000 train_acc= 0.16924 time= 1.75310
Epoch: 0100 train_loss= 38822961152.00000 train_acc= 0.16959 time= 1.78393
Epoch: 0101 train_loss= 34464874496.00000 train_acc= 0.17303 time= 1.75405
Epoch: 0102 train_loss= 24494086144.00000 train_acc= 0.17093 time= 1.76211
Epoch: 0103 train_loss= 38614482944.00000 train_acc= 0.17357 time= 1.75412
Epoch: 0104 train_loss= 29592649728.00000 train_acc= 0.16980 time= 1.81450
Epoch: 0105 train_loss= 136358199296.00000 train_acc= 0.17272 time= 1.81695
Epoch: 0106 train_loss= 122834624512.00000 train_acc= 0.17347 time= 1.77451
Epoch: 0107 train_loss= 19517976576.00000 train_acc= 0.17406 time= 1.73862
Epoch: 0108 train_loss= 19473907712.00000 train_acc= 0.17258 time= 1.76910
Epoch: 0109 train_loss= 172925485056.00000 train_acc= 0.16976 time= 1.79787
Epoch: 0110 train_loss= 54163898368.00000 train_acc= 0.18652 time= 1.80557
Epoch: 0111 train_loss= 18969825280.00000 train_acc= 0.17449 time= 1.79442
Epoch: 0112 train_loss= 18678546432.00000 train_acc= 0.17559 time= 1.82708
Epoch: 0113 train_loss= 33141248000.00000 train_acc= 0.17244 time= 1.79111
Epoch: 0114 train_loss= 83352502272.00000 train_acc= 0.17509 time= 1.79871
Epoch: 0115 train_loss= 33693433856.00000 train_acc= 0.16993 time= 1.75497
Epoch: 0116 train_loss= 19458428928.00000 train_acc= 0.17371 time= 1.79684
Epoch: 0117 train_loss= 104758812672.00000 train_acc= 0.17204 time= 1.72854
Epoch: 0118 train_loss= 24738985984.00000 train_acc= 0.17351 time= 1.77373
Epoch: 0119 train_loss= 26339504128.00000 train_acc= 0.17714 time= 1.76150
Epoch: 0120 train_loss= 160471760896.00000 train_acc= 0.17182 time= 1.74813
Epoch: 0121 train_loss= 29996855296.00000 train_acc= 0.16689 time= 1.78996
Epoch: 0122 train_loss= 49517658112.00000 train_acc= 0.17006 time= 1.78121
Epoch: 0123 train_loss= 48059654144.00000 train_acc= 0.16915 time= 1.80726
Epoch: 0124 train_loss= 31637932032.00000 train_acc= 0.17454 time= 1.78259
Epoch: 0125 train_loss= 18352443392.00000 train_acc= 0.16773 time= 1.78799
Epoch: 0126 train_loss= 31687467008.00000 train_acc= 0.17099 time= 1.79121
Epoch: 0127 train_loss= 42979049472.00000 train_acc= 0.17149 time= 1.77453
Epoch: 0128 train_loss= 60059058176.00000 train_acc= 0.16809 time= 1.82079
Epoch: 0129 train_loss= 51910705152.00000 train_acc= 0.16853 time= 1.77764
Epoch: 0130 train_loss= 76584927232.00000 train_acc= 0.16806 time= 1.77987
Epoch: 0131 train_loss= 33012895744.00000 train_acc= 0.16515 time= 1.73415
Epoch: 0132 train_loss= 66619326464.00000 train_acc= 0.16452 time= 1.79196
Epoch: 0133 train_loss= 32160249856.00000 train_acc= 0.16821 time= 1.81751
Epoch: 0134 train_loss= 26500317184.00000 train_acc= 0.16540 time= 1.75109
Epoch: 0135 train_loss= 15912537088.00000 train_acc= 0.16799 time= 1.76817
Epoch: 0136 train_loss= 47651741696.00000 train_acc= 0.16626 time= 1.81738
Epoch: 0137 train_loss= 57042903040.00000 train_acc= 0.16421 time= 1.78719
Epoch: 0138 train_loss= 28183740416.00000 train_acc= 0.16243 time= 1.76424
Epoch: 0139 train_loss= 23034474496.00000 train_acc= 0.16205 time= 1.74654
Epoch: 0140 train_loss= 52211978240.00000 train_acc= 0.16310 time= 1.77522
Epoch: 0141 train_loss= 19242317824.00000 train_acc= 0.16380 time= 1.79726
Epoch: 0142 train_loss= 109337583616.00000 train_acc= 0.16301 time= 1.75458
Epoch: 0143 train_loss= 38087974912.00000 train_acc= 0.16454 time= 1.81970
Epoch: 0144 train_loss= 19577675776.00000 train_acc= 0.16659 time= 1.81865
Epoch: 0145 train_loss= 21779085312.00000 train_acc= 0.16370 time= 1.77344
Epoch: 0146 train_loss= 109824835584.00000 train_acc= 0.16181 time= 1.74554
Epoch: 0147 train_loss= 33183385600.00000 train_acc= 0.16648 time= 1.79876
Epoch: 0148 train_loss= 21319741440.00000 train_acc= 0.16513 time= 1.79712
Epoch: 0149 train_loss= 111325839360.00000 train_acc= 0.16556 time= 1.79774
Epoch: 0150 train_loss= 59074703360.00000 train_acc= 0.16264 time= 1.81037
Epoch: 0151 train_loss= 78189682688.00000 train_acc= 0.16299 time= 1.76692
Epoch: 0152 train_loss= 23320821760.00000 train_acc= 0.16380 time= 1.79446
Epoch: 0153 train_loss= 78401060864.00000 train_acc= 0.16566 time= 1.77133
Epoch: 0154 train_loss= 16934133760.00000 train_acc= 0.16530 time= 1.76496
Epoch: 0155 train_loss= 41512472576.00000 train_acc= 0.16412 time= 1.73595
Epoch: 0156 train_loss= 24090722304.00000 train_acc= 0.16161 time= 1.80220
Epoch: 0157 train_loss= 141644251136.00000 train_acc= 0.16524 time= 1.75914
Epoch: 0158 train_loss= 45734797312.00000 train_acc= 0.16585 time= 1.80681
Epoch: 0159 train_loss= 86240845824.00000 train_acc= 0.16422 time= 1.79180
Epoch: 0160 train_loss= 65163288576.00000 train_acc= 0.16783 time= 1.83438
Epoch: 0161 train_loss= 22346262528.00000 train_acc= 0.16784 time= 1.75629
Epoch: 0162 train_loss= 16143624192.00000 train_acc= 0.16748 time= 1.81208
Epoch: 0163 train_loss= 24740048896.00000 train_acc= 0.18129 time= 1.82402
Epoch: 0164 train_loss= 19319521280.00000 train_acc= 0.16337 time= 1.76803
Epoch: 0165 train_loss= 16827598848.00000 train_acc= 0.16704 time= 1.81356
Epoch: 0166 train_loss= 34046085120.00000 train_acc= 0.16780 time= 1.77407
Epoch: 0167 train_loss= 15395519488.00000 train_acc= 0.16675 time= 1.76882
Epoch: 0168 train_loss= 22362931200.00000 train_acc= 0.16593 time= 1.80430
Epoch: 0169 train_loss= 22733631488.00000 train_acc= 0.16431 time= 1.76617
Epoch: 0170 train_loss= 30120673280.00000 train_acc= 0.16331 time= 1.78571
Epoch: 0171 train_loss= 48542146560.00000 train_acc= 0.16557 time= 1.77965
Epoch: 0172 train_loss= 29972752384.00000 train_acc= 0.16355 time= 1.77130
Epoch: 0173 train_loss= 64211677184.00000 train_acc= 0.16458 time= 1.75612
Epoch: 0174 train_loss= 53054377984.00000 train_acc= 0.16460 time= 1.81212
Epoch: 0175 train_loss= 29715374080.00000 train_acc= 0.16392 time= 1.74410
Epoch: 0176 train_loss= 21112211456.00000 train_acc= 0.16802 time= 1.81711
Epoch: 0177 train_loss= 48531447808.00000 train_acc= 0.16277 time= 1.75935
Epoch: 0178 train_loss= 26939285504.00000 train_acc= 0.16566 time= 1.75142
Epoch: 0179 train_loss= 15440617472.00000 train_acc= 0.16316 time= 1.79385
Epoch: 0180 train_loss= 17310148608.00000 train_acc= 0.16361 time= 1.77521
Epoch: 0181 train_loss= 21376204800.00000 train_acc= 0.16152 time= 1.77517
Epoch: 0182 train_loss= 14970035200.00000 train_acc= 0.16118 time= 1.75463
Epoch: 0183 train_loss= 21370703872.00000 train_acc= 0.16238 time= 1.75693
Epoch: 0184 train_loss= 105726681088.00000 train_acc= 0.16339 time= 1.75691
Epoch: 0185 train_loss= 86870335488.00000 train_acc= 0.16309 time= 1.79014
Epoch: 0186 train_loss= 57892659200.00000 train_acc= 0.15733 time= 1.75932
Epoch: 0187 train_loss= 36291072000.00000 train_acc= 0.16289 time= 1.79970
Epoch: 0188 train_loss= 30676092928.00000 train_acc= 0.16219 time= 1.79883
Epoch: 0189 train_loss= 15799714816.00000 train_acc= 0.16225 time= 1.81714
Epoch: 0190 train_loss= 17235283968.00000 train_acc= 0.15903 time= 1.80395
Epoch: 0191 train_loss= 118746136576.00000 train_acc= 0.16079 time= 1.83158
Epoch: 0192 train_loss= 46511845376.00000 train_acc= 0.16197 time= 1.80856
Epoch: 0193 train_loss= 39800643584.00000 train_acc= 0.16076 time= 1.78300
Epoch: 0194 train_loss= 15790364672.00000 train_acc= 0.16226 time= 1.82305
Epoch: 0195 train_loss= 133968625664.00000 train_acc= 0.16623 time= 1.78390
Epoch: 0196 train_loss= 29050607616.00000 train_acc= 0.16442 time= 1.74299
Epoch: 0197 train_loss= 17080542208.00000 train_acc= 0.16193 time= 1.78116
Epoch: 0198 train_loss= 15547298816.00000 train_acc= 0.16426 time= 1.75093
Epoch: 0199 train_loss= 31652517888.00000 train_acc= 0.16234 time= 1.83349
Epoch: 0200 train_loss= 23127412736.00000 train_acc= 0.15984 time= 1.79240
Epoch: 0201 train_loss= 18638125056.00000 train_acc= 0.16345 time= 1.75517
Epoch: 0202 train_loss= 79990906880.00000 train_acc= 0.16212 time= 1.79980
Epoch: 0203 train_loss= 25398185984.00000 train_acc= 0.20648 time= 1.81818
Epoch: 0204 train_loss= 42479403008.00000 train_acc= 0.15696 time= 1.73934
Epoch: 0205 train_loss= 65896513536.00000 train_acc= 0.16256 time= 1.82411
Epoch: 0206 train_loss= 59363573760.00000 train_acc= 0.15941 time= 1.76108
Epoch: 0207 train_loss= 23914577920.00000 train_acc= 0.15737 time= 1.79745
Epoch: 0208 train_loss= 23006031872.00000 train_acc= 0.15587 time= 1.74708
Epoch: 0209 train_loss= 18236211200.00000 train_acc= 0.15799 time= 1.77772
Epoch: 0210 train_loss= 24963948544.00000 train_acc= 0.15395 time= 1.78484
Epoch: 0211 train_loss= 23063894016.00000 train_acc= 0.15390 time= 1.78209
Epoch: 0212 train_loss= 39376130048.00000 train_acc= 0.15336 time= 1.82542
Epoch: 0213 train_loss= 20371914752.00000 train_acc= 0.15478 time= 1.77022
Epoch: 0214 train_loss= 14658207744.00000 train_acc= 0.15112 time= 1.74800
Epoch: 0215 train_loss= 52694462464.00000 train_acc= 0.15296 time= 1.76477
Epoch: 0216 train_loss= 14842951680.00000 train_acc= 0.15049 time= 1.79579
Epoch: 0217 train_loss= 33586155520.00000 train_acc= 0.15192 time= 1.73971
Epoch: 0218 train_loss= 18867712000.00000 train_acc= 0.14929 time= 1.82915
Epoch: 0219 train_loss= 16716494848.00000 train_acc= 0.14647 time= 1.73018
Epoch: 0220 train_loss= 16961640448.00000 train_acc= 0.15198 time= 1.78016
Epoch: 0221 train_loss= 38290755584.00000 train_acc= 0.14828 time= 1.74309
Epoch: 0222 train_loss= 14805474304.00000 train_acc= 0.14903 time= 1.76850
Epoch: 0223 train_loss= 17140241408.00000 train_acc= 0.14682 time= 1.77300
Epoch: 0224 train_loss= 21320599552.00000 train_acc= 0.14806 time= 1.80350
Epoch: 0225 train_loss= 3299077783552.00000 train_acc= 0.27088 time= 1.76501
Epoch: 0226 train_loss= 41916727296.00000 train_acc= 0.14607 time= 1.76860
Epoch: 0227 train_loss= 56566513664.00000 train_acc= 0.14849 time= 1.81361
Epoch: 0228 train_loss= 65953046528.00000 train_acc= 0.14543 time= 1.78287
Epoch: 0229 train_loss= 20224188416.00000 train_acc= 0.14593 time= 1.75940
Epoch: 0230 train_loss= 14598029312.00000 train_acc= 0.14570 time= 1.78561
Epoch: 0231 train_loss= 21306427392.00000 train_acc= 0.14965 time= 1.77684
Epoch: 0232 train_loss= 19372224512.00000 train_acc= 0.14373 time= 1.80271
Epoch: 0233 train_loss= 24693080064.00000 train_acc= 0.14337 time= 1.76895
Epoch: 0234 train_loss= 23556489216.00000 train_acc= 0.14290 time= 1.79866
Epoch: 0235 train_loss= 16003467264.00000 train_acc= 0.13973 time= 1.78972
Epoch: 0236 train_loss= 29213261824.00000 train_acc= 0.14093 time= 1.80485
Epoch: 0237 train_loss= 17290061824.00000 train_acc= 0.14206 time= 1.76761
Epoch: 0238 train_loss= 33390923776.00000 train_acc= 0.13688 time= 1.78105
Epoch: 0239 train_loss= 43112448000.00000 train_acc= 0.13799 time= 1.79691
Epoch: 0240 train_loss= 18395668480.00000 train_acc= 0.16502 time= 1.77171
Epoch: 0241 train_loss= 18981662720.00000 train_acc= 0.13672 time= 1.78774
Epoch: 0242 train_loss= 48100102144.00000 train_acc= 0.13591 time= 1.75540
Epoch: 0243 train_loss= 29457027072.00000 train_acc= 0.13750 time= 1.79226
Epoch: 0244 train_loss= 24991068160.00000 train_acc= 0.13497 time= 1.74929
Epoch: 0245 train_loss= 16395302912.00000 train_acc= 0.13415 time= 1.81281
Epoch: 0246 train_loss= 18003767296.00000 train_acc= 0.13406 time= 1.75525
Epoch: 0247 train_loss= 17183520768.00000 train_acc= 0.13332 time= 1.75933
Epoch: 0248 train_loss= 61255532544.00000 train_acc= 0.13129 time= 1.79373
Epoch: 0249 train_loss= 16023424000.00000 train_acc= 0.13215 time= 1.82283
Epoch: 0250 train_loss= 19489175552.00000 train_acc= 0.13035 time= 1.77441
Epoch: 0251 train_loss= 19173511168.00000 train_acc= 0.13158 time= 1.82330
Epoch: 0252 train_loss= 17003520000.00000 train_acc= 0.13145 time= 1.80369
Epoch: 0253 train_loss= 71997202432.00000 train_acc= 0.13182 time= 1.80892
Epoch: 0254 train_loss= 30654447616.00000 train_acc= 0.12787 time= 1.81543
Epoch: 0255 train_loss= 24669499392.00000 train_acc= 0.13050 time= 1.84068
Epoch: 0256 train_loss= 34049169408.00000 train_acc= 0.13063 time= 1.74296
Epoch: 0257 train_loss= 17127560192.00000 train_acc= 0.13258 time= 1.81591
Epoch: 0258 train_loss= 49402191872.00000 train_acc= 0.13223 time= 1.74929
Epoch: 0259 train_loss= 30839246848.00000 train_acc= 0.13041 time= 1.81034
Epoch: 0260 train_loss= 17976725504.00000 train_acc= 0.13088 time= 1.78558
Epoch: 0261 train_loss= 39192813568.00000 train_acc= 0.12902 time= 1.74718
Epoch: 0262 train_loss= 33325162496.00000 train_acc= 0.13231 time= 1.73342
Epoch: 0263 train_loss= 30619418624.00000 train_acc= 0.13134 time= 1.77602
Epoch: 0264 train_loss= 57578647552.00000 train_acc= 0.12990 time= 1.78660
Epoch: 0265 train_loss= 53684940800.00000 train_acc= 0.12682 time= 1.79948
Epoch: 0266 train_loss= 19349792768.00000 train_acc= 0.13109 time= 1.81754
Epoch: 0267 train_loss= 15671463936.00000 train_acc= 0.12993 time= 1.80467
Epoch: 0268 train_loss= 22808989696.00000 train_acc= 0.12849 time= 1.81175
Epoch: 0269 train_loss= 46906667008.00000 train_acc= 0.13280 time= 1.76575
Epoch: 0270 train_loss= 37567782912.00000 train_acc= 0.13237 time= 1.78150
Epoch: 0271 train_loss= 15025710080.00000 train_acc= 0.12835 time= 1.74321
Epoch: 0272 train_loss= 14393528320.00000 train_acc= 0.12691 time= 1.75896
Epoch: 0273 train_loss= 13847353344.00000 train_acc= 0.13097 time= 1.78464
Epoch: 0274 train_loss= 16348912640.00000 train_acc= 0.12863 time= 1.76864
Epoch: 0275 train_loss= 29116602368.00000 train_acc= 0.12814 time= 1.79011
Epoch: 0276 train_loss= 16860131328.00000 train_acc= 0.12950 time= 1.81196
Epoch: 0277 train_loss= 79028477952.00000 train_acc= 0.13009 time= 1.79351
Epoch: 0278 train_loss= 17739327488.00000 train_acc= 0.12842 time= 1.79088
Epoch: 0279 train_loss= 25960640512.00000 train_acc= 0.13071 time= 1.81053
Epoch: 0280 train_loss= 39149379584.00000 train_acc= 0.13134 time= 1.73370
Epoch: 0281 train_loss= 14412069888.00000 train_acc= 0.12881 time= 1.80566
Epoch: 0282 train_loss= 31910203392.00000 train_acc= 0.13384 time= 1.77570
Epoch: 0283 train_loss= 2943121096704.00000 train_acc= 0.25104 time= 1.82462
Epoch: 0284 train_loss= 29661777920.00000 train_acc= 0.12994 time= 1.74717
Epoch: 0285 train_loss= 13208859648.00000 train_acc= 0.13139 time= 1.75928
Epoch: 0286 train_loss= 20305268736.00000 train_acc= 0.13059 time= 1.78567
Epoch: 0287 train_loss= 36406087680.00000 train_acc= 0.13081 time= 1.77484
Epoch: 0288 train_loss= 46969352192.00000 train_acc= 0.13273 time= 1.79206
Epoch: 0289 train_loss= 25245526016.00000 train_acc= 0.12817 time= 1.77488
Epoch: 0290 train_loss= 14970500096.00000 train_acc= 0.12844 time= 1.73443
Epoch: 0291 train_loss= 56271355904.00000 train_acc= 0.12913 time= 1.84021
Epoch: 0292 train_loss= 18895853568.00000 train_acc= 0.12751 time= 1.79679
Epoch: 0293 train_loss= 37897838592.00000 train_acc= 0.12956 time= 1.78067
Epoch: 0294 train_loss= 14232375296.00000 train_acc= 0.12912 time= 1.78612
Epoch: 0295 train_loss= 23660578816.00000 train_acc= 0.13162 time= 1.79738
Epoch: 0296 train_loss= 53736452096.00000 train_acc= 0.12813 time= 1.78784
Epoch: 0297 train_loss= 25472012288.00000 train_acc= 0.12682 time= 1.81424
Epoch: 0298 train_loss= 45045436416.00000 train_acc= 0.12595 time= 1.80525
Epoch: 0299 train_loss= 34591531008.00000 train_acc= 0.12509 time= 1.78102
Epoch: 0300 train_loss= 16307359744.00000 train_acc= 0.12412 time= 1.76705
Optimization Finished!
Model: [1.6260650851777636,8.178642948093106e-15]
Epoch: 0001 train_loss= 95.25851 train_acc= 0.12256 time= 3.14145
Epoch: 0002 train_loss= 1421444832476627206144.00000 train_acc= 0.49663 time= 1.75528
Epoch: 0003 train_loss= nan train_acc= 0.99972 time= 1.74628
Epoch: 0004 train_loss= nan train_acc= 0.99972 time= 1.73682
Epoch: 0005 train_loss= nan train_acc= 0.99972 time= 1.72794
Epoch: 0006 train_loss= nan train_acc= 0.99972 time= 1.78585
Epoch: 0007 train_loss= nan train_acc= 0.99972 time= 1.77092
Epoch: 0008 train_loss= nan train_acc= 0.99972 time= 1.73350
Epoch: 0009 train_loss= nan train_acc= 0.99972 time= 1.76276
Epoch: 0010 train_loss= nan train_acc= 0.99972 time= 1.79173
Epoch: 0011 train_loss= nan train_acc= 0.99972 time= 1.79588
Epoch: 0012 train_loss= nan train_acc= 0.99972 time= 1.80658
Epoch: 0013 train_loss= nan train_acc= 0.99972 time= 1.74935
Epoch: 0014 train_loss= nan train_acc= 0.99972 time= 1.75816
Epoch: 0015 train_loss= nan train_acc= 0.99972 time= 1.77753
Epoch: 0016 train_loss= nan train_acc= 0.99972 time= 1.79182
Epoch: 0017 train_loss= nan train_acc= 0.99972 time= 1.79461
Epoch: 0018 train_loss= nan train_acc= 0.99972 time= 1.72259
Epoch: 0019 train_loss= nan train_acc= 0.99972 time= 1.77873
Epoch: 0020 train_loss= nan train_acc= 0.99972 time= 1.81180
Epoch: 0021 train_loss= nan train_acc= 0.99972 time= 1.77908
Epoch: 0022 train_loss= nan train_acc= 0.99972 time= 1.80185
Epoch: 0023 train_loss= nan train_acc= 0.99972 time= 1.78100
Epoch: 0024 train_loss= nan train_acc= 0.99972 time= 1.80022
Epoch: 0025 train_loss= nan train_acc= 0.99972 time= 1.75738
Epoch: 0026 train_loss= nan train_acc= 0.99972 time= 1.76934
Epoch: 0027 train_loss= nan train_acc= 0.99972 time= 1.75855
Epoch: 0028 train_loss= nan train_acc= 0.99972 time= 1.80670
Epoch: 0029 train_loss= nan train_acc= 0.99972 time= 1.79912
Epoch: 0030 train_loss= nan train_acc= 0.99972 time= 1.73411
Epoch: 0031 train_loss= nan train_acc= 0.99972 time= 1.78386
Epoch: 0032 train_loss= nan train_acc= 0.99972 time= 1.76478
Epoch: 0033 train_loss= nan train_acc= 0.99972 time= 1.78696
Epoch: 0034 train_loss= nan train_acc= 0.99972 time= 1.78914
Epoch: 0035 train_loss= nan train_acc= 0.99972 time= 1.76164
Epoch: 0036 train_loss= nan train_acc= 0.99972 time= 1.78688
Epoch: 0037 train_loss= nan train_acc= 0.99972 time= 1.75398
Epoch: 0038 train_loss= nan train_acc= 0.99972 time= 1.79659
Epoch: 0039 train_loss= nan train_acc= 0.99972 time= 1.80301
Epoch: 0040 train_loss= nan train_acc= 0.99972 time= 1.77781
Epoch: 0041 train_loss= nan train_acc= 0.99972 time= 1.75518
Epoch: 0042 train_loss= nan train_acc= 0.99972 time= 1.74720
Epoch: 0043 train_loss= nan train_acc= 0.99972 time= 1.78671
Epoch: 0044 train_loss= nan train_acc= 0.99972 time= 1.79586
Epoch: 0045 train_loss= nan train_acc= 0.99972 time= 1.75518
Epoch: 0046 train_loss= nan train_acc= 0.99972 time= 1.77830
Epoch: 0047 train_loss= nan train_acc= 0.99972 time= 1.80274
Epoch: 0048 train_loss= nan train_acc= 0.99972 time= 1.79954
Epoch: 0049 train_loss= nan train_acc= 0.99972 time= 1.73253
Epoch: 0050 train_loss= nan train_acc= 0.99972 time= 1.78436
Epoch: 0051 train_loss= nan train_acc= 0.99972 time= 1.78891
Epoch: 0052 train_loss= nan train_acc= 0.99972 time= 1.73758
Epoch: 0053 train_loss= nan train_acc= 0.99972 time= 1.80712
Epoch: 0054 train_loss= nan train_acc= 0.99972 time= 1.73221
Epoch: 0055 train_loss= nan train_acc= 0.99972 time= 1.76741
Epoch: 0056 train_loss= nan train_acc= 0.99972 time= 1.74771
Epoch: 0057 train_loss= nan train_acc= 0.99972 time= 1.73767
Epoch: 0058 train_loss= nan train_acc= 0.99972 time= 1.81883
Epoch: 0059 train_loss= nan train_acc= 0.99972 time= 1.73414
Epoch: 0060 train_loss= nan train_acc= 0.99972 time= 1.77323
Epoch: 0061 train_loss= nan train_acc= 0.99972 time= 1.77913
Epoch: 0062 train_loss= nan train_acc= 0.99972 time= 1.80529
Epoch: 0063 train_loss= nan train_acc= 0.99972 time= 1.74744
Epoch: 0064 train_loss= nan train_acc= 0.99972 time= 1.79576
Epoch: 0065 train_loss= nan train_acc= 0.99972 time= 1.74522
Epoch: 0066 train_loss= nan train_acc= 0.99972 time= 1.79114
Epoch: 0067 train_loss= nan train_acc= 0.99972 time= 1.74450
Epoch: 0068 train_loss= nan train_acc= 0.99972 time= 1.75779
Epoch: 0069 train_loss= nan train_acc= 0.99972 time= 1.74733
Epoch: 0070 train_loss= nan train_acc= 0.99972 time= 1.81653
Epoch: 0071 train_loss= nan train_acc= 0.99972 time= 1.78943
Epoch: 0072 train_loss= nan train_acc= 0.99972 time= 1.77729
Epoch: 0073 train_loss= nan train_acc= 0.99972 time= 1.75102
Epoch: 0074 train_loss= nan train_acc= 0.99972 time= 1.76044
Epoch: 0075 train_loss= nan train_acc= 0.99972 time= 1.76336
Epoch: 0076 train_loss= nan train_acc= 0.99972 time= 1.76660
Epoch: 0077 train_loss= nan train_acc= 0.99972 time= 1.74465
Epoch: 0078 train_loss= nan train_acc= 0.99972 time= 1.76829
Epoch: 0079 train_loss= nan train_acc= 0.99972 time= 1.74771
Epoch: 0080 train_loss= nan train_acc= 0.99972 time= 1.75848
Epoch: 0081 train_loss= nan train_acc= 0.99972 time= 1.80390
Epoch: 0082 train_loss= nan train_acc= 0.99972 time= 1.72608
Epoch: 0083 train_loss= nan train_acc= 0.99972 time= 1.72388
Epoch: 0084 train_loss= nan train_acc= 0.99972 time= 1.74351
Epoch: 0085 train_loss= nan train_acc= 0.99972 time= 1.78564
Epoch: 0086 train_loss= nan train_acc= 0.99972 time= 1.78581
Epoch: 0087 train_loss= nan train_acc= 0.99972 time= 1.82135
Epoch: 0088 train_loss= nan train_acc= 0.99972 time= 1.76923
Epoch: 0089 train_loss= nan train_acc= 0.99972 time= 1.80395
Epoch: 0090 train_loss= nan train_acc= 0.99972 time= 1.71694
Epoch: 0091 train_loss= nan train_acc= 0.99972 time= 1.76489
Epoch: 0092 train_loss= nan train_acc= 0.99972 time= 1.84092
Epoch: 0093 train_loss= nan train_acc= 0.99972 time= 1.74907
Epoch: 0094 train_loss= nan train_acc= 0.99972 time= 1.75934
Epoch: 0095 train_loss= nan train_acc= 0.99972 time= 1.74961
Epoch: 0096 train_loss= nan train_acc= 0.99972 time= 1.74864
Epoch: 0097 train_loss= nan train_acc= 0.99972 time= 1.74710
Epoch: 0098 train_loss= nan train_acc= 0.99972 time= 1.76866
Epoch: 0099 train_loss= nan train_acc= 0.99972 time= 1.77400
Epoch: 0100 train_loss= nan train_acc= 0.99972 time= 1.77880
Epoch: 0101 train_loss= nan train_acc= 0.99972 time= 1.78998
Epoch: 0102 train_loss= nan train_acc= 0.99972 time= 1.71025
Epoch: 0103 train_loss= nan train_acc= 0.99972 time= 1.80151
Epoch: 0104 train_loss= nan train_acc= 0.99972 time= 1.76638
Epoch: 0105 train_loss= nan train_acc= 0.99972 time= 1.79853
Epoch: 0106 train_loss= nan train_acc= 0.99972 time= 1.73196
Epoch: 0107 train_loss= nan train_acc= 0.99972 time= 1.75149
Epoch: 0108 train_loss= nan train_acc= 0.99972 time= 1.79873
Epoch: 0109 train_loss= nan train_acc= 0.99972 time= 1.76273
Epoch: 0110 train_loss= nan train_acc= 0.99972 time= 1.74153
Epoch: 0111 train_loss= nan train_acc= 0.99972 time= 1.79554
Epoch: 0112 train_loss= nan train_acc= 0.99972 time= 1.75122
Epoch: 0113 train_loss= nan train_acc= 0.99972 time= 1.77928
Epoch: 0114 train_loss= nan train_acc= 0.99972 time= 1.73881
Epoch: 0115 train_loss= nan train_acc= 0.99972 time= 1.73818
Epoch: 0116 train_loss= nan train_acc= 0.99972 time= 1.74253
Epoch: 0117 train_loss= nan train_acc= 0.99972 time= 1.76118
Epoch: 0118 train_loss= nan train_acc= 0.99972 time= 1.74047
Epoch: 0119 train_loss= nan train_acc= 0.99972 time= 1.76303
Epoch: 0120 train_loss= nan train_acc= 0.99972 time= 1.77433
Epoch: 0121 train_loss= nan train_acc= 0.99972 time= 1.76762
Epoch: 0122 train_loss= nan train_acc= 0.99972 time= 1.78680
Epoch: 0123 train_loss= nan train_acc= 0.99972 time= 1.80512
Epoch: 0124 train_loss= nan train_acc= 0.99972 time= 1.78102
Epoch: 0125 train_loss= nan train_acc= 0.99972 time= 1.75456
Epoch: 0126 train_loss= nan train_acc= 0.99972 time= 1.77411
Epoch: 0127 train_loss= nan train_acc= 0.99972 time= 1.74150
Epoch: 0128 train_loss= nan train_acc= 0.99972 time= 1.80546
Epoch: 0129 train_loss= nan train_acc= 0.99972 time= 1.80095
Epoch: 0130 train_loss= nan train_acc= 0.99972 time= 1.78401
Epoch: 0131 train_loss= nan train_acc= 0.99972 time= 1.77989
Epoch: 0132 train_loss= nan train_acc= 0.99972 time= 1.72875
Epoch: 0133 train_loss= nan train_acc= 0.99972 time= 1.79843
Epoch: 0134 train_loss= nan train_acc= 0.99972 time= 1.78736
Epoch: 0135 train_loss= nan train_acc= 0.99972 time= 1.76881
Epoch: 0136 train_loss= nan train_acc= 0.99972 time= 1.76623
Epoch: 0137 train_loss= nan train_acc= 0.99972 time= 1.78871
Epoch: 0138 train_loss= nan train_acc= 0.99972 time= 1.77211
Epoch: 0139 train_loss= nan train_acc= 0.99972 time= 1.79582
Epoch: 0140 train_loss= nan train_acc= 0.99972 time= 1.73572
Epoch: 0141 train_loss= nan train_acc= 0.99972 time= 1.76848
Epoch: 0142 train_loss= nan train_acc= 0.99972 time= 1.77831
Epoch: 0143 train_loss= nan train_acc= 0.99972 time= 1.79252
Epoch: 0144 train_loss= nan train_acc= 0.99972 time= 1.81132
Epoch: 0145 train_loss= nan train_acc= 0.99972 time= 1.81985
Epoch: 0146 train_loss= nan train_acc= 0.99972 time= 1.76078
Epoch: 0147 train_loss= nan train_acc= 0.99972 time= 1.79927
Epoch: 0148 train_loss= nan train_acc= 0.99972 time= 1.76087
Epoch: 0149 train_loss= nan train_acc= 0.99972 time= 1.77715
Epoch: 0150 train_loss= nan train_acc= 0.99972 time= 1.74786
Epoch: 0151 train_loss= nan train_acc= 0.99972 time= 1.76415
Epoch: 0152 train_loss= nan train_acc= 0.99972 time= 1.76867
Epoch: 0153 train_loss= nan train_acc= 0.99972 time= 1.76551
Epoch: 0154 train_loss= nan train_acc= 0.99972 time= 1.80761
Epoch: 0155 train_loss= nan train_acc= 0.99972 time= 1.77201
Epoch: 0156 train_loss= nan train_acc= 0.99972 time= 1.74636
Epoch: 0157 train_loss= nan train_acc= 0.99972 time= 1.76036
Epoch: 0158 train_loss= nan train_acc= 0.99972 time= 1.77411
Epoch: 0159 train_loss= nan train_acc= 0.99972 time= 1.77589
Epoch: 0160 train_loss= nan train_acc= 0.99972 time= 1.76051
Epoch: 0161 train_loss= nan train_acc= 0.99972 time= 1.74803
Epoch: 0162 train_loss= nan train_acc= 0.99972 time= 1.75327
Epoch: 0163 train_loss= nan train_acc= 0.99972 time= 1.75497
Epoch: 0164 train_loss= nan train_acc= 0.99972 time= 1.80790
Epoch: 0165 train_loss= nan train_acc= 0.99972 time= 1.80016
Epoch: 0166 train_loss= nan train_acc= 0.99972 time= 1.75495
Epoch: 0167 train_loss= nan train_acc= 0.99972 time= 1.77689
Epoch: 0168 train_loss= nan train_acc= 0.99972 time= 1.79683
Epoch: 0169 train_loss= nan train_acc= 0.99972 time= 1.77680
Epoch: 0170 train_loss= nan train_acc= 0.99972 time= 1.78950
Epoch: 0171 train_loss= nan train_acc= 0.99972 time= 1.74868
Epoch: 0172 train_loss= nan train_acc= 0.99972 time= 1.77888
Epoch: 0173 train_loss= nan train_acc= 0.99972 time= 1.80610
Epoch: 0174 train_loss= nan train_acc= 0.99972 time= 1.74645
Epoch: 0175 train_loss= nan train_acc= 0.99972 time= 1.80706
Epoch: 0176 train_loss= nan train_acc= 0.99972 time= 1.76454
Epoch: 0177 train_loss= nan train_acc= 0.99972 time= 1.77464
Epoch: 0178 train_loss= nan train_acc= 0.99972 time= 1.72218
Epoch: 0179 train_loss= nan train_acc= 0.99972 time= 1.79115
Epoch: 0180 train_loss= nan train_acc= 0.99972 time= 1.77395
Epoch: 0181 train_loss= nan train_acc= 0.99972 time= 1.76938
Epoch: 0182 train_loss= nan train_acc= 0.99972 time= 1.77538
Epoch: 0183 train_loss= nan train_acc= 0.99972 time= 1.80218
Epoch: 0184 train_loss= nan train_acc= 0.99972 time= 1.79045
Epoch: 0185 train_loss= nan train_acc= 0.99972 time= 1.77258
Epoch: 0186 train_loss= nan train_acc= 0.99972 time= 1.76623
Epoch: 0187 train_loss= nan train_acc= 0.99972 time= 1.80895
Epoch: 0188 train_loss= nan train_acc= 0.99972 time= 1.77690
Epoch: 0189 train_loss= nan train_acc= 0.99972 time= 1.76005
Epoch: 0190 train_loss= nan train_acc= 0.99972 time= 1.74438
Epoch: 0191 train_loss= nan train_acc= 0.99972 time= 1.78083
Epoch: 0192 train_loss= nan train_acc= 0.99972 time= 1.77827
Epoch: 0193 train_loss= nan train_acc= 0.99972 time= 1.81518
Epoch: 0194 train_loss= nan train_acc= 0.99972 time= 1.72309
Epoch: 0195 train_loss= nan train_acc= 0.99972 time= 1.74316
Epoch: 0196 train_loss= nan train_acc= 0.99972 time= 1.79014
Epoch: 0197 train_loss= nan train_acc= 0.99972 time= 1.79277
Epoch: 0198 train_loss= nan train_acc= 0.99972 time= 1.74269
Epoch: 0199 train_loss= nan train_acc= 0.99972 time= 1.76628
Epoch: 0200 train_loss= nan train_acc= 0.99972 time= 1.77754
Epoch: 0201 train_loss= nan train_acc= 0.99972 time= 1.79015
Epoch: 0202 train_loss= nan train_acc= 0.99972 time= 1.74562
Epoch: 0203 train_loss= nan train_acc= 0.99972 time= 1.79819
Epoch: 0204 train_loss= nan train_acc= 0.99972 time= 1.77395
Epoch: 0205 train_loss= nan train_acc= 0.99972 time= 1.74753
Epoch: 0206 train_loss= nan train_acc= 0.99972 time= 1.76956
Epoch: 0207 train_loss= nan train_acc= 0.99972 time= 1.74411
Epoch: 0208 train_loss= nan train_acc= 0.99972 time= 1.79168
Epoch: 0209 train_loss= nan train_acc= 0.99972 time= 1.78999
Epoch: 0210 train_loss= nan train_acc= 0.99972 time= 1.77149
Epoch: 0211 train_loss= nan train_acc= 0.99972 time= 1.79551
Epoch: 0212 train_loss= nan train_acc= 0.99972 time= 1.72463
Epoch: 0213 train_loss= nan train_acc= 0.99972 time= 1.79023
Epoch: 0214 train_loss= nan train_acc= 0.99972 time= 1.78429
Epoch: 0215 train_loss= nan train_acc= 0.99972 time= 1.76491
Epoch: 0216 train_loss= nan train_acc= 0.99972 time= 1.76132
Epoch: 0217 train_loss= nan train_acc= 0.99972 time= 1.79468
Epoch: 0218 train_loss= nan train_acc= 0.99972 time= 1.76758
Epoch: 0219 train_loss= nan train_acc= 0.99972 time= 1.72987
Epoch: 0220 train_loss= nan train_acc= 0.99972 time= 1.73738
Epoch: 0221 train_loss= nan train_acc= 0.99972 time= 1.76555
Epoch: 0222 train_loss= nan train_acc= 0.99972 time= 1.74206
Epoch: 0223 train_loss= nan train_acc= 0.99972 time= 1.76739
Epoch: 0224 train_loss= nan train_acc= 0.99972 time= 1.76249
Epoch: 0225 train_loss= nan train_acc= 0.99972 time= 1.74502
Epoch: 0226 train_loss= nan train_acc= 0.99972 time= 1.80497
Epoch: 0227 train_loss= nan train_acc= 0.99972 time= 1.81967
Epoch: 0228 train_loss= nan train_acc= 0.99972 time= 1.76034
Epoch: 0229 train_loss= nan train_acc= 0.99972 time= 1.73605
Epoch: 0230 train_loss= nan train_acc= 0.99972 time= 1.79035
Epoch: 0231 train_loss= nan train_acc= 0.99972 time= 1.77198
Epoch: 0232 train_loss= nan train_acc= 0.99972 time= 1.73373
Epoch: 0233 train_loss= nan train_acc= 0.99972 time= 1.73947
Epoch: 0234 train_loss= nan train_acc= 0.99972 time= 1.73591
Epoch: 0235 train_loss= nan train_acc= 0.99972 time= 1.74078
Epoch: 0236 train_loss= nan train_acc= 0.99972 time= 1.75280
Epoch: 0237 train_loss= nan train_acc= 0.99972 time= 1.74097
Epoch: 0238 train_loss= nan train_acc= 0.99972 time= 1.76310
Epoch: 0239 train_loss= nan train_acc= 0.99972 time= 1.74720
Epoch: 0240 train_loss= nan train_acc= 0.99972 time= 1.71511
Epoch: 0241 train_loss= nan train_acc= 0.99972 time= 1.76234
Epoch: 0242 train_loss= nan train_acc= 0.99972 time= 1.81028
Epoch: 0243 train_loss= nan train_acc= 0.99972 time= 1.78966
Epoch: 0244 train_loss= nan train_acc= 0.99972 time= 1.78810
Epoch: 0245 train_loss= nan train_acc= 0.99972 time= 1.80966
Epoch: 0246 train_loss= nan train_acc= 0.99972 time= 1.80109
Epoch: 0247 train_loss= nan train_acc= 0.99972 time= 1.73651
Epoch: 0248 train_loss= nan train_acc= 0.99972 time= 1.74456
Epoch: 0249 train_loss= nan train_acc= 0.99972 time= 1.78870
Epoch: 0250 train_loss= nan train_acc= 0.99972 time= 1.80586
Epoch: 0251 train_loss= nan train_acc= 0.99972 time= 1.79452
Epoch: 0252 train_loss= nan train_acc= 0.99972 time= 1.78530
Epoch: 0253 train_loss= nan train_acc= 0.99972 time= 1.72035
Epoch: 0254 train_loss= nan train_acc= 0.99972 time= 1.77836
Epoch: 0255 train_loss= nan train_acc= 0.99972 time= 1.81871
Epoch: 0256 train_loss= nan train_acc= 0.99972 time= 1.72931
Epoch: 0257 train_loss= nan train_acc= 0.99972 time= 1.80267
Epoch: 0258 train_loss= nan train_acc= 0.99972 time= 1.76127
Epoch: 0259 train_loss= nan train_acc= 0.99972 time= 1.73998
Epoch: 0260 train_loss= nan train_acc= 0.99972 time= 1.78996
Epoch: 0261 train_loss= nan train_acc= 0.99972 time= 1.79759
Epoch: 0262 train_loss= nan train_acc= 0.99972 time= 1.74517
Epoch: 0263 train_loss= nan train_acc= 0.99972 time= 1.78409
Epoch: 0264 train_loss= nan train_acc= 0.99972 time= 1.76905
Epoch: 0265 train_loss= nan train_acc= 0.99972 time= 1.74807
Epoch: 0266 train_loss= nan train_acc= 0.99972 time= 1.80712
Epoch: 0267 train_loss= nan train_acc= 0.99972 time= 1.76261
Epoch: 0268 train_loss= nan train_acc= 0.99972 time= 1.80695
Epoch: 0269 train_loss= nan train_acc= 0.99972 time= 1.74124
Epoch: 0270 train_loss= nan train_acc= 0.99972 time= 1.81428
Epoch: 0271 train_loss= nan train_acc= 0.99972 time= 1.72547
Epoch: 0272 train_loss= nan train_acc= 0.99972 time= 1.77260
Epoch: 0273 train_loss= nan train_acc= 0.99972 time= 1.80080
Epoch: 0274 train_loss= nan train_acc= 0.99972 time= 1.75968
Epoch: 0275 train_loss= nan train_acc= 0.99972 time= 1.73269
Epoch: 0276 train_loss= nan train_acc= 0.99972 time= 1.75199
Epoch: 0277 train_loss= nan train_acc= 0.99972 time= 1.78907
Epoch: 0278 train_loss= nan train_acc= 0.99972 time= 1.79497
Epoch: 0279 train_loss= nan train_acc= 0.99972 time= 1.77132
Epoch: 0280 train_loss= nan train_acc= 0.99972 time= 1.75913
Epoch: 0281 train_loss= nan train_acc= 0.99972 time= 1.74006
Epoch: 0282 train_loss= nan train_acc= 0.99972 time= 1.75436
Epoch: 0283 train_loss= nan train_acc= 0.99972 time= 1.73402
Epoch: 0284 train_loss= nan train_acc= 0.99972 time= 1.74980
Epoch: 0285 train_loss= nan train_acc= 0.99972 time= 1.76425
Epoch: 0286 train_loss= nan train_acc= 0.99972 time= 1.77917
Epoch: 0287 train_loss= nan train_acc= 0.99972 time= 1.74450
Epoch: 0288 train_loss= nan train_acc= 0.99972 time= 1.79313
Epoch: 0289 train_loss= nan train_acc= 0.99972 time= 1.78389
Epoch: 0290 train_loss= nan train_acc= 0.99972 time= 1.78332
Epoch: 0291 train_loss= nan train_acc= 0.99972 time= 1.74625
Epoch: 0292 train_loss= nan train_acc= 0.99972 time= 1.78854
Epoch: 0293 train_loss= nan train_acc= 0.99972 time= 1.74450
Epoch: 0294 train_loss= nan train_acc= 0.99972 time= 1.75291
Epoch: 0295 train_loss= nan train_acc= 0.99972 time= 1.75877
Epoch: 0296 train_loss= nan train_acc= 0.99972 time= 1.77294
Epoch: 0297 train_loss= nan train_acc= 0.99972 time= 1.74434
Epoch: 0298 train_loss= nan train_acc= 0.99972 time= 1.77379
Epoch: 0299 train_loss= nan train_acc= 0.99972 time= 1.73166
Epoch: 0300 train_loss= nan train_acc= 0.99972 time= 1.78034
Optimization Finished!
Model: [nan,nan]
Epoch: 0001 train_loss= 106.08018 train_acc= 0.16573 time= 3.14550
Epoch: 0002 train_loss= 236933850595328.00000 train_acc= 0.48074 time= 1.72768
Epoch: 0003 train_loss= 49403981824.00000 train_acc= 0.36107 time= 1.82855
Epoch: 0004 train_loss= 24893085188096.00000 train_acc= 0.39223 time= 1.75151
Epoch: 0005 train_loss= 380094283776.00000 train_acc= 0.29972 time= 1.73121
Epoch: 0006 train_loss= 517993168896.00000 train_acc= 0.19304 time= 1.77920
Epoch: 0007 train_loss= 615684702208.00000 train_acc= 0.16165 time= 1.71219
Epoch: 0008 train_loss= 10147829760.00000 train_acc= 0.06251 time= 1.72056
Epoch: 0009 train_loss= 9337193472.00000 train_acc= 0.06240 time= 1.75768
Epoch: 0010 train_loss= 379642688.00000 train_acc= 0.02129 time= 1.79812
Epoch: 0011 train_loss= 3206478336.00000 train_acc= 0.03629 time= 1.75216
Epoch: 0012 train_loss= 973381.50000 train_acc= 0.00573 time= 1.75120
Epoch: 0013 train_loss= 8961468.00000 train_acc= 0.00791 time= 1.74509
Epoch: 0014 train_loss= 41902.14062 train_acc= 0.00071 time= 1.78288
Epoch: 0015 train_loss= 18630086.00000 train_acc= 0.01300 time= 1.76345
Epoch: 0016 train_loss= 14197.02832 train_acc= 0.00059 time= 1.78903
Epoch: 0017 train_loss= 3114.62671 train_acc= 0.00040 time= 1.74006
Epoch: 0018 train_loss= 3120.63452 train_acc= 0.00028 time= 1.78015
Epoch: 0019 train_loss= 3255.22705 train_acc= 0.00028 time= 1.79846
Epoch: 0020 train_loss= 3434.46387 train_acc= 0.00028 time= 1.77784
Epoch: 0021 train_loss= 3624.52881 train_acc= 0.00028 time= 1.73781
Epoch: 0022 train_loss= 3796.56567 train_acc= 0.00028 time= 1.75173
Epoch: 0023 train_loss= 3934.23022 train_acc= 0.00028 time= 1.74165
Epoch: 0024 train_loss= 4032.16406 train_acc= 0.00028 time= 1.76482
Epoch: 0025 train_loss= 4092.97925 train_acc= 0.00028 time= 1.76559
Epoch: 0026 train_loss= 4123.93457 train_acc= 0.00028 time= 1.78333
Epoch: 0027 train_loss= 4136.18408 train_acc= 0.00028 time= 1.76608
Epoch: 0028 train_loss= 4139.98584 train_acc= 0.00028 time= 1.77956
Epoch: 0029 train_loss= 4141.10645 train_acc= 0.00028 time= 1.76479
Epoch: 0030 train_loss= 4141.05225 train_acc= 0.00028 time= 1.76637
Epoch: 0031 train_loss= 4143.17285 train_acc= 0.00028 time= 1.76400
Epoch: 0032 train_loss= 4148.59424 train_acc= 0.00028 time= 1.78218
Epoch: 0033 train_loss= 4157.96533 train_acc= 0.00028 time= 1.73208
Epoch: 0034 train_loss= 317548.00000 train_acc= 0.00260 time= 1.77471
Epoch: 0035 train_loss= 4191.47217 train_acc= 0.00028 time= 1.78421
Epoch: 0036 train_loss= 4536.33252 train_acc= 0.00034 time= 1.73082
Epoch: 0037 train_loss= 4222.73340 train_acc= 0.00028 time= 1.73464
Epoch: 0038 train_loss= 4230.84326 train_acc= 0.00028 time= 1.80460
Epoch: 0039 train_loss= 4233.58301 train_acc= 0.00028 time= 1.80500
Epoch: 0040 train_loss= 4232.52393 train_acc= 0.00028 time= 1.77617
Epoch: 0041 train_loss= 4229.24756 train_acc= 0.00028 time= 1.77745
Epoch: 0042 train_loss= 4225.33252 train_acc= 0.00028 time= 1.73709
Epoch: 0043 train_loss= 4221.24854 train_acc= 0.00028 time= 1.77407
Epoch: 0044 train_loss= 4216.93652 train_acc= 0.00028 time= 1.74754
Epoch: 0045 train_loss= 4212.17480 train_acc= 0.00028 time= 1.78311
Epoch: 0046 train_loss= 4207.40479 train_acc= 0.00028 time= 1.78728
Epoch: 0047 train_loss= 4202.48047 train_acc= 0.00028 time= 1.77555
Epoch: 0048 train_loss= 4196.96436 train_acc= 0.00028 time= 1.72374
Epoch: 0049 train_loss= 4190.17871 train_acc= 0.00028 time= 1.74836
Epoch: 0050 train_loss= 1467532.62500 train_acc= 0.00409 time= 1.80481
Epoch: 0051 train_loss= 4176.35693 train_acc= 0.00028 time= 1.77437
Epoch: 0052 train_loss= 4171.17090 train_acc= 0.00028 time= 1.77049
Epoch: 0053 train_loss= 4179.50684 train_acc= 0.00029 time= 1.72091
Epoch: 0054 train_loss= 4161.89746 train_acc= 0.00028 time= 1.79143
Epoch: 0055 train_loss= 4158.18945 train_acc= 0.00028 time= 1.79304
Epoch: 0056 train_loss= 4155.50391 train_acc= 0.00028 time= 1.73011
Epoch: 0057 train_loss= 4153.70605 train_acc= 0.00028 time= 1.73266
Epoch: 0058 train_loss= 23040.97656 train_acc= 0.00056 time= 1.75842
Epoch: 0059 train_loss= 4153.16455 train_acc= 0.00028 time= 1.75315
Epoch: 0060 train_loss= 4155.96729 train_acc= 0.00028 time= 1.72980
Epoch: 0061 train_loss= 4159.52295 train_acc= 0.00028 time= 1.72883
Epoch: 0062 train_loss= 4163.55859 train_acc= 0.00028 time= 1.75482
Epoch: 0063 train_loss= 4167.86328 train_acc= 0.00028 time= 1.76872
Epoch: 0064 train_loss= 4172.17627 train_acc= 0.00028 time= 1.73694
Epoch: 0065 train_loss= 4175.97266 train_acc= 0.00028 time= 1.74326
Epoch: 0066 train_loss= 4179.13965 train_acc= 0.00028 time= 1.78650
Epoch: 0067 train_loss= 4180.79980 train_acc= 0.00028 time= 1.78068
Epoch: 0068 train_loss= 4181.05371 train_acc= 0.00028 time= 1.74476
Epoch: 0069 train_loss= 4179.77344 train_acc= 0.00028 time= 1.72925
Epoch: 0070 train_loss= 4177.27441 train_acc= 0.00028 time= 1.75477
Epoch: 0071 train_loss= 4173.55908 train_acc= 0.00028 time= 1.78875
Epoch: 0072 train_loss= 4168.95654 train_acc= 0.00028 time= 1.75777
Epoch: 0073 train_loss= 4163.15283 train_acc= 0.00028 time= 1.80494
Epoch: 0074 train_loss= 4156.23682 train_acc= 0.00028 time= 1.75404
Epoch: 0075 train_loss= 4147.97119 train_acc= 0.00028 time= 1.77859
Epoch: 0076 train_loss= 4138.74512 train_acc= 0.00028 time= 1.73831
Epoch: 0077 train_loss= 4128.23633 train_acc= 0.00028 time= 1.73664
Epoch: 0078 train_loss= 4117.00732 train_acc= 0.00028 time= 1.79199
Epoch: 0079 train_loss= 4105.09082 train_acc= 0.00028 time= 1.75148
Epoch: 0080 train_loss= 4092.51538 train_acc= 0.00028 time= 1.79531
Epoch: 0081 train_loss= 716553.87500 train_acc= 0.00314 time= 1.78502
Epoch: 0082 train_loss= 4068.34644 train_acc= 0.00028 time= 1.80565
Epoch: 0083 train_loss= 4060.56274 train_acc= 0.00028 time= 1.77870
Epoch: 0084 train_loss= 4055.27295 train_acc= 0.00028 time= 1.74648
Epoch: 0085 train_loss= 4051.62793 train_acc= 0.00028 time= 1.73439
Epoch: 0086 train_loss= 4073.67603 train_acc= 0.00029 time= 1.75277
Epoch: 0087 train_loss= 286598.53125 train_acc= 0.00248 time= 1.77742
Epoch: 0088 train_loss= 4048.25781 train_acc= 0.00028 time= 1.72000
Epoch: 0089 train_loss= 4053.57642 train_acc= 0.00028 time= 1.72184
Epoch: 0090 train_loss= 4061.47607 train_acc= 0.00028 time= 1.78719
Epoch: 0091 train_loss= 780900480.00000 train_acc= 0.03614 time= 1.78639
Epoch: 0092 train_loss= 109544.42969 train_acc= 0.00209 time= 1.75026
Epoch: 0093 train_loss= 4104.54248 train_acc= 0.00028 time= 1.72610
Epoch: 0094 train_loss= 4131.80420 train_acc= 0.00028 time= 1.72642
Epoch: 0095 train_loss= 4163.54688 train_acc= 0.00028 time= 1.80659
Epoch: 0096 train_loss= 5332.16016 train_acc= 0.00037 time= 1.78118
Epoch: 0097 train_loss= 4235.61035 train_acc= 0.00028 time= 1.74092
Epoch: 0098 train_loss= 4276.73193 train_acc= 0.00028 time= 1.73924
Epoch: 0099 train_loss= 4318.14648 train_acc= 0.00028 time= 1.79029
Epoch: 0100 train_loss= 4357.39453 train_acc= 0.00028 time= 1.73384
Epoch: 0101 train_loss= 4392.64844 train_acc= 0.00028 time= 1.75053
Epoch: 0102 train_loss= 4422.78809 train_acc= 0.00028 time= 1.76147
Epoch: 0103 train_loss= 4447.33838 train_acc= 0.00028 time= 1.78172
Epoch: 0104 train_loss= 4466.46729 train_acc= 0.00028 time= 1.77765
Epoch: 0105 train_loss= 4480.86182 train_acc= 0.00028 time= 1.73948
Epoch: 0106 train_loss= 4491.51367 train_acc= 0.00028 time= 1.72749
Epoch: 0107 train_loss= 4499.31299 train_acc= 0.00028 time= 1.77249
Epoch: 0108 train_loss= 4504.85986 train_acc= 0.00028 time= 1.74441
Epoch: 0109 train_loss= 4509.18994 train_acc= 0.00028 time= 1.78024
Epoch: 0110 train_loss= 4512.45264 train_acc= 0.00028 time= 1.80394
Epoch: 0111 train_loss= 4515.02100 train_acc= 0.00028 time= 1.76407
Epoch: 0112 train_loss= 4516.83789 train_acc= 0.00028 time= 1.78626
Epoch: 0113 train_loss= 4517.73730 train_acc= 0.00028 time= 1.79307
Epoch: 0114 train_loss= 4517.58545 train_acc= 0.00028 time= 1.75547
Epoch: 0115 train_loss= 4516.03076 train_acc= 0.00028 time= 1.75394
Epoch: 0116 train_loss= 4512.80615 train_acc= 0.00028 time= 1.75130
Epoch: 0117 train_loss= 4507.95215 train_acc= 0.00028 time= 1.71867
Epoch: 0118 train_loss= 4501.29395 train_acc= 0.00028 time= 1.79449
Epoch: 0119 train_loss= 4493.02051 train_acc= 0.00028 time= 1.73570
Epoch: 0120 train_loss= 4483.27295 train_acc= 0.00028 time= 1.75714
Epoch: 0121 train_loss= 4472.28809 train_acc= 0.00028 time= 1.76167
Epoch: 0122 train_loss= 4460.38232 train_acc= 0.00028 time= 1.75008
Epoch: 0123 train_loss= 4447.74072 train_acc= 0.00028 time= 1.74605
Epoch: 0124 train_loss= 4434.68506 train_acc= 0.00028 time= 1.78259
Epoch: 0125 train_loss= 4421.36035 train_acc= 0.00028 time= 1.78831
Epoch: 0126 train_loss= 4407.75635 train_acc= 0.00028 time= 1.76155
Epoch: 0127 train_loss= 4394.17090 train_acc= 0.00028 time= 1.75833
Epoch: 0128 train_loss= 4380.52588 train_acc= 0.00028 time= 1.77381
Epoch: 0129 train_loss= 4366.58105 train_acc= 0.00028 time= 1.77914
Epoch: 0130 train_loss= 4352.50342 train_acc= 0.00028 time= 1.77532
Epoch: 0131 train_loss= 4338.29834 train_acc= 0.00028 time= 1.77580
Epoch: 0132 train_loss= 4323.77686 train_acc= 0.00028 time= 1.75980
Epoch: 0133 train_loss= 4308.96680 train_acc= 0.00028 time= 1.76204
Epoch: 0134 train_loss= 4293.97461 train_acc= 0.00028 time= 1.73440
Epoch: 0135 train_loss= 4278.79053 train_acc= 0.00028 time= 1.73888
Epoch: 0136 train_loss= 4263.49219 train_acc= 0.00028 time= 1.74593
Epoch: 0137 train_loss= 4248.19189 train_acc= 0.00028 time= 1.75540
Epoch: 0138 train_loss= 4232.66504 train_acc= 0.00028 time= 1.74861
Epoch: 0139 train_loss= 4217.43457 train_acc= 0.00028 time= 1.73863
Epoch: 0140 train_loss= 4202.19971 train_acc= 0.00028 time= 1.75263
Epoch: 0141 train_loss= 4187.06104 train_acc= 0.00028 time= 1.76424
Epoch: 0142 train_loss= 4172.02930 train_acc= 0.00028 time= 1.77056
Epoch: 0143 train_loss= 4157.05273 train_acc= 0.00028 time= 1.76806
Epoch: 0144 train_loss= 4142.31885 train_acc= 0.00028 time= 1.79689
Epoch: 0145 train_loss= 4127.68408 train_acc= 0.00028 time= 1.77078
Epoch: 0146 train_loss= 4113.12549 train_acc= 0.00028 time= 1.75863
Epoch: 0147 train_loss= 4098.65674 train_acc= 0.00028 time= 1.78892
Epoch: 0148 train_loss= 4084.34766 train_acc= 0.00028 time= 1.79984
Epoch: 0149 train_loss= 4069.93628 train_acc= 0.00028 time= 1.79760
Epoch: 0150 train_loss= 4055.78979 train_acc= 0.00028 time= 1.76511
Epoch: 0151 train_loss= 4041.69971 train_acc= 0.00028 time= 1.79755
Epoch: 0152 train_loss= 4027.65942 train_acc= 0.00028 time= 1.73776
Epoch: 0153 train_loss= 4013.79956 train_acc= 0.00028 time= 1.73829
Epoch: 0154 train_loss= 4000.18750 train_acc= 0.00028 time= 1.77718
Epoch: 0155 train_loss= 3986.60059 train_acc= 0.00028 time= 1.77014
Epoch: 0156 train_loss= 3973.18140 train_acc= 0.00028 time= 1.78727
Epoch: 0157 train_loss= 3959.86646 train_acc= 0.00028 time= 1.77745
Epoch: 0158 train_loss= 3946.74561 train_acc= 0.00028 time= 1.74246
Epoch: 0159 train_loss= 3933.79321 train_acc= 0.00028 time= 1.78378
Epoch: 0160 train_loss= 3920.83911 train_acc= 0.00028 time= 1.80854
Epoch: 0161 train_loss= 3908.17822 train_acc= 0.00028 time= 1.78322
Epoch: 0162 train_loss= 3895.68066 train_acc= 0.00028 time= 1.77296
Epoch: 0163 train_loss= 3883.19629 train_acc= 0.00028 time= 1.76590
Epoch: 0164 train_loss= 3870.81665 train_acc= 0.00028 time= 1.78010
Epoch: 0165 train_loss= 3858.52832 train_acc= 0.00028 time= 1.75533
Epoch: 0166 train_loss= 3846.47070 train_acc= 0.00028 time= 1.72033
Epoch: 0167 train_loss= 3834.50879 train_acc= 0.00028 time= 1.75149
Epoch: 0168 train_loss= 3822.58472 train_acc= 0.00028 time= 1.72473
Epoch: 0169 train_loss= 3810.95752 train_acc= 0.00028 time= 1.77197
Epoch: 0170 train_loss= 3799.35889 train_acc= 0.00028 time= 1.73931
Epoch: 0171 train_loss= 3787.93091 train_acc= 0.00028 time= 1.72246
Epoch: 0172 train_loss= 3776.56494 train_acc= 0.00028 time= 1.80098
Epoch: 0173 train_loss= 3765.31323 train_acc= 0.00028 time= 1.80074
Epoch: 0174 train_loss= 3754.31519 train_acc= 0.00028 time= 1.78470
Epoch: 0175 train_loss= 3743.22534 train_acc= 0.00028 time= 1.72936
Epoch: 0176 train_loss= 3732.36646 train_acc= 0.00028 time= 1.77316
Epoch: 0177 train_loss= 3721.58228 train_acc= 0.00028 time= 1.73195
Epoch: 0178 train_loss= 3710.92456 train_acc= 0.00028 time= 1.76651
Epoch: 0179 train_loss= 3700.36035 train_acc= 0.00028 time= 1.74984
Epoch: 0180 train_loss= 3689.90747 train_acc= 0.00028 time= 1.75665
Epoch: 0181 train_loss= 3679.56567 train_acc= 0.00028 time= 1.75943
Epoch: 0182 train_loss= 3669.41553 train_acc= 0.00028 time= 1.77433
Epoch: 0183 train_loss= 3659.15088 train_acc= 0.00028 time= 1.72226
Epoch: 0184 train_loss= 3649.12256 train_acc= 0.00028 time= 1.77285
Epoch: 0185 train_loss= 3639.04712 train_acc= 0.00028 time= 1.77998
Epoch: 0186 train_loss= 3629.16553 train_acc= 0.00028 time= 1.78519
Epoch: 0187 train_loss= 3619.52393 train_acc= 0.00028 time= 1.74387
Epoch: 0188 train_loss= 3609.70923 train_acc= 0.00028 time= 1.76488
Epoch: 0189 train_loss= 3600.21729 train_acc= 0.00028 time= 1.73446
Epoch: 0190 train_loss= 3590.65430 train_acc= 0.00028 time= 1.77644
Epoch: 0191 train_loss= 3581.16650 train_acc= 0.00028 time= 1.76432
Epoch: 0192 train_loss= 3571.81226 train_acc= 0.00028 time= 1.76568
Epoch: 0193 train_loss= 3562.62695 train_acc= 0.00028 time= 1.75098
Epoch: 0194 train_loss= 3553.42505 train_acc= 0.00028 time= 1.77505
Epoch: 0195 train_loss= 3544.40234 train_acc= 0.00028 time= 1.73268
Epoch: 0196 train_loss= 3535.28931 train_acc= 0.00028 time= 1.79977
Epoch: 0197 train_loss= 3526.40942 train_acc= 0.00028 time= 1.75181
Epoch: 0198 train_loss= 3517.54126 train_acc= 0.00028 time= 1.79846
Epoch: 0199 train_loss= 3508.74365 train_acc= 0.00028 time= 1.77085
Epoch: 0200 train_loss= 3500.04590 train_acc= 0.00028 time= 1.73991
Epoch: 0201 train_loss= 3491.48169 train_acc= 0.00028 time= 1.77944
Epoch: 0202 train_loss= 3482.83594 train_acc= 0.00028 time= 1.77017
Epoch: 0203 train_loss= 3474.34448 train_acc= 0.00028 time= 1.79607
Epoch: 0204 train_loss= 3465.89966 train_acc= 0.00028 time= 1.73836
Epoch: 0205 train_loss= 3457.56226 train_acc= 0.00028 time= 1.77237
Epoch: 0206 train_loss= 3449.28076 train_acc= 0.00028 time= 1.77311
Epoch: 0207 train_loss= 3441.00830 train_acc= 0.00028 time= 1.75132
Epoch: 0208 train_loss= 3432.88989 train_acc= 0.00028 time= 1.78741
Epoch: 0209 train_loss= 3424.74023 train_acc= 0.00028 time= 1.77528
Epoch: 0210 train_loss= 3416.76245 train_acc= 0.00028 time= 1.82730
Epoch: 0211 train_loss= 3408.78174 train_acc= 0.00028 time= 1.76257
Epoch: 0212 train_loss= 3400.90625 train_acc= 0.00028 time= 1.76653
Epoch: 0213 train_loss= 3393.08472 train_acc= 0.00028 time= 1.75521
Epoch: 0214 train_loss= 3385.27222 train_acc= 0.00028 time= 1.76196
Epoch: 0215 train_loss= 3377.47534 train_acc= 0.00028 time= 1.80135
Epoch: 0216 train_loss= 3369.80640 train_acc= 0.00028 time= 1.76658
Epoch: 0217 train_loss= 3362.28052 train_acc= 0.00028 time= 1.72724
Epoch: 0218 train_loss= 3354.74756 train_acc= 0.00028 time= 1.76623
Epoch: 0219 train_loss= 3347.18091 train_acc= 0.00028 time= 1.73453
Epoch: 0220 train_loss= 3339.70654 train_acc= 0.00028 time= 1.78215
Epoch: 0221 train_loss= 3332.35400 train_acc= 0.00028 time= 1.76254
Epoch: 0222 train_loss= 3325.07593 train_acc= 0.00028 time= 1.73269
Epoch: 0223 train_loss= 3317.83569 train_acc= 0.00028 time= 1.79138
Epoch: 0224 train_loss= 3310.56592 train_acc= 0.00028 time= 1.74711
Epoch: 0225 train_loss= 3303.39478 train_acc= 0.00028 time= 1.75897
Epoch: 0226 train_loss= 3296.15942 train_acc= 0.00028 time= 1.76428
Epoch: 0227 train_loss= 3289.15894 train_acc= 0.00028 time= 1.81030
Epoch: 0228 train_loss= 3282.22192 train_acc= 0.00028 time= 1.77906
Epoch: 0229 train_loss= 3275.21216 train_acc= 0.00028 time= 1.72566
Epoch: 0230 train_loss= 3268.26880 train_acc= 0.00028 time= 1.80449
Epoch: 0231 train_loss= 3261.41797 train_acc= 0.00028 time= 1.79003
Epoch: 0232 train_loss= 3254.55566 train_acc= 0.00028 time= 1.78607
Epoch: 0233 train_loss= 3247.78662 train_acc= 0.00028 time= 1.76961
Epoch: 0234 train_loss= 3241.05811 train_acc= 0.00028 time= 1.77850
Epoch: 0235 train_loss= 3234.43091 train_acc= 0.00028 time= 1.73630
Epoch: 0236 train_loss= 3227.72729 train_acc= 0.00028 time= 1.74186
Epoch: 0237 train_loss= 3221.13696 train_acc= 0.00028 time= 1.77627
Epoch: 0238 train_loss= 3214.57715 train_acc= 0.00028 time= 1.78226
Epoch: 0239 train_loss= 3208.11816 train_acc= 0.00028 time= 1.82458
Epoch: 0240 train_loss= 3201.61792 train_acc= 0.00028 time= 1.77048
Epoch: 0241 train_loss= 3195.12939 train_acc= 0.00028 time= 1.78706
Epoch: 0242 train_loss= 3188.90649 train_acc= 0.00028 time= 1.77866
Epoch: 0243 train_loss= 3182.49927 train_acc= 0.00028 time= 1.79332
Epoch: 0244 train_loss= 3176.21436 train_acc= 0.00028 time= 1.76621
Epoch: 0245 train_loss= 3169.91016 train_acc= 0.00028 time= 1.77046
Epoch: 0246 train_loss= 3163.76660 train_acc= 0.00028 time= 1.74723
Epoch: 0247 train_loss= 3157.52783 train_acc= 0.00028 time= 1.72562
Epoch: 0248 train_loss= 3151.41211 train_acc= 0.00028 time= 1.77942
Epoch: 0249 train_loss= 3145.32861 train_acc= 0.00028 time= 1.71674
Epoch: 0250 train_loss= 3139.27197 train_acc= 0.00028 time= 1.79772
Epoch: 0251 train_loss= 3133.29370 train_acc= 0.00028 time= 1.77621
Epoch: 0252 train_loss= 3127.30908 train_acc= 0.00028 time= 1.80806
Epoch: 0253 train_loss= 3121.42700 train_acc= 0.00028 time= 1.75356
Epoch: 0254 train_loss= 3115.43237 train_acc= 0.00028 time= 1.76960
Epoch: 0255 train_loss= 3109.63916 train_acc= 0.00028 time= 1.79653
Epoch: 0256 train_loss= 3103.77295 train_acc= 0.00028 time= 1.76293
Epoch: 0257 train_loss= 3098.04907 train_acc= 0.00028 time= 1.79191
Epoch: 0258 train_loss= 3092.31812 train_acc= 0.00028 time= 1.77482
Epoch: 0259 train_loss= 3086.58569 train_acc= 0.00028 time= 1.78606
Epoch: 0260 train_loss= 3080.87158 train_acc= 0.00028 time= 1.75456
Epoch: 0261 train_loss= 3075.26147 train_acc= 0.00028 time= 1.77252
Epoch: 0262 train_loss= 3069.66626 train_acc= 0.00028 time= 1.75120
Epoch: 0263 train_loss= 3064.17529 train_acc= 0.00028 time= 1.77611
Epoch: 0264 train_loss= 3058.57935 train_acc= 0.00028 time= 1.76058
Epoch: 0265 train_loss= 3053.08350 train_acc= 0.00028 time= 1.75382
Epoch: 0266 train_loss= 3047.60083 train_acc= 0.00028 time= 1.72879
Epoch: 0267 train_loss= 3042.16455 train_acc= 0.00028 time= 1.75613
Epoch: 0268 train_loss= 3036.82227 train_acc= 0.00028 time= 1.77583
Epoch: 0269 train_loss= 3031.38306 train_acc= 0.00028 time= 1.75758
Epoch: 0270 train_loss= 3026.02026 train_acc= 0.00028 time= 1.82025
Epoch: 0271 train_loss= 3020.74829 train_acc= 0.00028 time= 1.77383
Epoch: 0272 train_loss= 3015.54150 train_acc= 0.00028 time= 1.77850
Epoch: 0273 train_loss= 3010.24072 train_acc= 0.00028 time= 1.76383
Epoch: 0274 train_loss= 3005.07568 train_acc= 0.00028 time= 1.76415
Epoch: 0275 train_loss= 2999.92944 train_acc= 0.00028 time= 1.77410
Epoch: 0276 train_loss= 2994.86157 train_acc= 0.00028 time= 1.80859
Epoch: 0277 train_loss= 2989.76465 train_acc= 0.00028 time= 1.75517
Epoch: 0278 train_loss= 2984.66235 train_acc= 0.00028 time= 1.77925
Epoch: 0279 train_loss= 2979.56421 train_acc= 0.00028 time= 1.73138
Epoch: 0280 train_loss= 2974.52563 train_acc= 0.00028 time= 1.73433
Epoch: 0281 train_loss= 2969.53760 train_acc= 0.00028 time= 1.75405
Epoch: 0282 train_loss= 2964.65649 train_acc= 0.00028 time= 1.81714
Epoch: 0283 train_loss= 2959.71704 train_acc= 0.00028 time= 1.74282
Epoch: 0284 train_loss= 2954.77222 train_acc= 0.00028 time= 1.76154
Epoch: 0285 train_loss= 2949.91382 train_acc= 0.00028 time= 1.77411
Epoch: 0286 train_loss= 2945.16602 train_acc= 0.00028 time= 1.76633
Epoch: 0287 train_loss= 2940.28979 train_acc= 0.00028 time= 1.76829
Epoch: 0288 train_loss= 2935.40088 train_acc= 0.00028 time= 1.75393
Epoch: 0289 train_loss= 2930.72192 train_acc= 0.00028 time= 1.73021
Epoch: 0290 train_loss= 2925.89258 train_acc= 0.00028 time= 1.76997
Epoch: 0291 train_loss= 2921.26978 train_acc= 0.00028 time= 1.73799
Epoch: 0292 train_loss= 2916.55322 train_acc= 0.00028 time= 1.73956
Epoch: 0293 train_loss= 2911.96509 train_acc= 0.00028 time= 1.78958
Epoch: 0294 train_loss= 2907.38721 train_acc= 0.00028 time= 1.75079
Epoch: 0295 train_loss= 2902.73413 train_acc= 0.00028 time= 1.78468
Epoch: 0296 train_loss= 2898.18311 train_acc= 0.00028 time= 1.80039
Epoch: 0297 train_loss= 2893.66113 train_acc= 0.00028 time= 1.79372
Epoch: 0298 train_loss= 2889.17139 train_acc= 0.00028 time= 1.76179
Epoch: 0299 train_loss= 2884.69800 train_acc= 0.00028 time= 1.79460
Epoch: 0300 train_loss= 2880.28931 train_acc= 0.00028 time= 1.75941
Optimization Finished!
Model: [1.6260599314397641,-1.2160642863064263e-13]
Epoch: 0001 train_loss= 168188.04688 train_acc= 0.28592 time= 3.10791
Epoch: 0002 train_loss= 728358474130024830150377472.00000 train_acc= 0.49911 time= 1.73454
Epoch: 0003 train_loss= nan train_acc= 0.99972 time= 1.78446
Epoch: 0004 train_loss= nan train_acc= 0.99972 time= 1.73262
Epoch: 0005 train_loss= nan train_acc= 0.99972 time= 1.81194
Epoch: 0006 train_loss= nan train_acc= 0.99972 time= 1.76210
Epoch: 0007 train_loss= nan train_acc= 0.99972 time= 1.74797
Epoch: 0008 train_loss= nan train_acc= 0.99972 time= 1.79668
Epoch: 0009 train_loss= nan train_acc= 0.99972 time= 1.78021
Epoch: 0010 train_loss= nan train_acc= 0.99972 time= 1.78815
Epoch: 0011 train_loss= nan train_acc= 0.99972 time= 1.79316
Epoch: 0012 train_loss= nan train_acc= 0.99972 time= 1.72272
Epoch: 0013 train_loss= nan train_acc= 0.99972 time= 1.71987
Epoch: 0014 train_loss= nan train_acc= 0.99972 time= 1.72093
Epoch: 0015 train_loss= nan train_acc= 0.99972 time= 1.78926
Epoch: 0016 train_loss= nan train_acc= 0.99972 time= 1.78875
Epoch: 0017 train_loss= nan train_acc= 0.99972 time= 1.78353
Epoch: 0018 train_loss= nan train_acc= 0.99972 time= 1.77685
Epoch: 0019 train_loss= nan train_acc= 0.99972 time= 1.74343
Epoch: 0020 train_loss= nan train_acc= 0.99972 time= 1.79952
Epoch: 0021 train_loss= nan train_acc= 0.99972 time= 1.74764
Epoch: 0022 train_loss= nan train_acc= 0.99972 time= 1.81053
Epoch: 0023 train_loss= nan train_acc= 0.99972 time= 1.79258
Epoch: 0024 train_loss= nan train_acc= 0.99972 time= 1.72751
Epoch: 0025 train_loss= nan train_acc= 0.99972 time= 1.72139
Epoch: 0026 train_loss= nan train_acc= 0.99972 time= 1.79300
Epoch: 0027 train_loss= nan train_acc= 0.99972 time= 1.72613
Epoch: 0028 train_loss= nan train_acc= 0.99972 time= 1.78603
Epoch: 0029 train_loss= nan train_acc= 0.99972 time= 1.75023
Epoch: 0030 train_loss= nan train_acc= 0.99972 time= 1.73535
Epoch: 0031 train_loss= nan train_acc= 0.99972 time= 1.79868
Epoch: 0032 train_loss= nan train_acc= 0.99972 time= 1.77513
Epoch: 0033 train_loss= nan train_acc= 0.99972 time= 1.78825
Epoch: 0034 train_loss= nan train_acc= 0.99972 time= 1.79835
Epoch: 0035 train_loss= nan train_acc= 0.99972 time= 1.79595
Epoch: 0036 train_loss= nan train_acc= 0.99972 time= 1.78290
Epoch: 0037 train_loss= nan train_acc= 0.99972 time= 1.76897
Epoch: 0038 train_loss= nan train_acc= 0.99972 time= 1.82783
Epoch: 0039 train_loss= nan train_acc= 0.99972 time= 1.72797
Epoch: 0040 train_loss= nan train_acc= 0.99972 time= 1.74888
Epoch: 0041 train_loss= nan train_acc= 0.99972 time= 1.77265
Epoch: 0042 train_loss= nan train_acc= 0.99972 time= 1.77893
Epoch: 0043 train_loss= nan train_acc= 0.99972 time= 1.77343
Epoch: 0044 train_loss= nan train_acc= 0.99972 time= 1.82054
Epoch: 0045 train_loss= nan train_acc= 0.99972 time= 1.78503
Epoch: 0046 train_loss= nan train_acc= 0.99972 time= 1.74541
Epoch: 0047 train_loss= nan train_acc= 0.99972 time= 1.73735
Epoch: 0048 train_loss= nan train_acc= 0.99972 time= 1.80602
Epoch: 0049 train_loss= nan train_acc= 0.99972 time= 1.76750
Epoch: 0050 train_loss= nan train_acc= 0.99972 time= 1.79728
Epoch: 0051 train_loss= nan train_acc= 0.99972 time= 1.72671
Epoch: 0052 train_loss= nan train_acc= 0.99972 time= 1.77622
Epoch: 0053 train_loss= nan train_acc= 0.99972 time= 1.79792
Epoch: 0054 train_loss= nan train_acc= 0.99972 time= 1.75768
Epoch: 0055 train_loss= nan train_acc= 0.99972 time= 1.77292
Epoch: 0056 train_loss= nan train_acc= 0.99972 time= 1.78784
Epoch: 0057 train_loss= nan train_acc= 0.99972 time= 1.76470
Epoch: 0058 train_loss= nan train_acc= 0.99972 time= 1.74393
Epoch: 0059 train_loss= nan train_acc= 0.99972 time= 1.77661
Epoch: 0060 train_loss= nan train_acc= 0.99972 time= 1.77959
Epoch: 0061 train_loss= nan train_acc= 0.99972 time= 1.77385
Epoch: 0062 train_loss= nan train_acc= 0.99972 time= 1.75373
Epoch: 0063 train_loss= nan train_acc= 0.99972 time= 1.76935
Epoch: 0064 train_loss= nan train_acc= 0.99972 time= 1.81240
Epoch: 0065 train_loss= nan train_acc= 0.99972 time= 1.74884
Epoch: 0066 train_loss= nan train_acc= 0.99972 time= 1.80015
Epoch: 0067 train_loss= nan train_acc= 0.99972 time= 1.75488
Epoch: 0068 train_loss= nan train_acc= 0.99972 time= 1.77015
Epoch: 0069 train_loss= nan train_acc= 0.99972 time= 1.71938
Epoch: 0070 train_loss= nan train_acc= 0.99972 time= 1.78975
Epoch: 0071 train_loss= nan train_acc= 0.99972 time= 1.79201
Epoch: 0072 train_loss= nan train_acc= 0.99972 time= 1.80908
Epoch: 0073 train_loss= nan train_acc= 0.99972 time= 1.77416
Epoch: 0074 train_loss= nan train_acc= 0.99972 time= 1.78734
Epoch: 0075 train_loss= nan train_acc= 0.99972 time= 1.74831
Epoch: 0076 train_loss= nan train_acc= 0.99972 time= 1.77119
Epoch: 0077 train_loss= nan train_acc= 0.99972 time= 1.74457
Epoch: 0078 train_loss= nan train_acc= 0.99972 time= 1.73779
Epoch: 0079 train_loss= nan train_acc= 0.99972 time= 1.78543
Epoch: 0080 train_loss= nan train_acc= 0.99972 time= 1.79505
Epoch: 0081 train_loss= nan train_acc= 0.99972 time= 1.79679
Epoch: 0082 train_loss= nan train_acc= 0.99972 time= 1.81079
Epoch: 0083 train_loss= nan train_acc= 0.99972 time= 1.76167
Epoch: 0084 train_loss= nan train_acc= 0.99972 time= 1.78396
Epoch: 0085 train_loss= nan train_acc= 0.99972 time= 1.74977
Epoch: 0086 train_loss= nan train_acc= 0.99972 time= 1.77713
Epoch: 0087 train_loss= nan train_acc= 0.99972 time= 1.80044
Epoch: 0088 train_loss= nan train_acc= 0.99972 time= 1.76129
Epoch: 0089 train_loss= nan train_acc= 0.99972 time= 1.71812
Epoch: 0090 train_loss= nan train_acc= 0.99972 time= 1.79094
Epoch: 0091 train_loss= nan train_acc= 0.99972 time= 1.74635
Epoch: 0092 train_loss= nan train_acc= 0.99972 time= 1.76494
Epoch: 0093 train_loss= nan train_acc= 0.99972 time= 1.72860
Epoch: 0094 train_loss= nan train_acc= 0.99972 time= 1.75165
Epoch: 0095 train_loss= nan train_acc= 0.99972 time= 1.76926
Epoch: 0096 train_loss= nan train_acc= 0.99972 time= 1.77509
Epoch: 0097 train_loss= nan train_acc= 0.99972 time= 1.73643
Epoch: 0098 train_loss= nan train_acc= 0.99972 time= 1.75020
Epoch: 0099 train_loss= nan train_acc= 0.99972 time= 1.76002
Epoch: 0100 train_loss= nan train_acc= 0.99972 time= 1.74578
Epoch: 0101 train_loss= nan train_acc= 0.99972 time= 1.78793
Epoch: 0102 train_loss= nan train_acc= 0.99972 time= 1.73867
Epoch: 0103 train_loss= nan train_acc= 0.99972 time= 1.76404
Epoch: 0104 train_loss= nan train_acc= 0.99972 time= 1.74842
Epoch: 0105 train_loss= nan train_acc= 0.99972 time= 1.80468
Epoch: 0106 train_loss= nan train_acc= 0.99972 time= 1.78226
Epoch: 0107 train_loss= nan train_acc= 0.99972 time= 1.73033
Epoch: 0108 train_loss= nan train_acc= 0.99972 time= 1.73594
Epoch: 0109 train_loss= nan train_acc= 0.99972 time= 1.79192
Epoch: 0110 train_loss= nan train_acc= 0.99972 time= 1.75471
Epoch: 0111 train_loss= nan train_acc= 0.99972 time= 1.79993
Epoch: 0112 train_loss= nan train_acc= 0.99972 time= 1.74448
Epoch: 0113 train_loss= nan train_acc= 0.99972 time= 1.73114
Epoch: 0114 train_loss= nan train_acc= 0.99972 time= 1.80914
Epoch: 0115 train_loss= nan train_acc= 0.99972 time= 1.76185
Epoch: 0116 train_loss= nan train_acc= 0.99972 time= 1.72863
Epoch: 0117 train_loss= nan train_acc= 0.99972 time= 1.77923
Epoch: 0118 train_loss= nan train_acc= 0.99972 time= 1.77502
Epoch: 0119 train_loss= nan train_acc= 0.99972 time= 1.74834
Epoch: 0120 train_loss= nan train_acc= 0.99972 time= 1.82713
Epoch: 0121 train_loss= nan train_acc= 0.99972 time= 1.78106
Epoch: 0122 train_loss= nan train_acc= 0.99972 time= 1.79348
Epoch: 0123 train_loss= nan train_acc= 0.99972 time= 1.76308
Epoch: 0124 train_loss= nan train_acc= 0.99972 time= 1.79947
Epoch: 0125 train_loss= nan train_acc= 0.99972 time= 1.78122
Epoch: 0126 train_loss= nan train_acc= 0.99972 time= 1.75275
Epoch: 0127 train_loss= nan train_acc= 0.99972 time= 1.79428
Epoch: 0128 train_loss= nan train_acc= 0.99972 time= 1.76083
Epoch: 0129 train_loss= nan train_acc= 0.99972 time= 1.74947
Epoch: 0130 train_loss= nan train_acc= 0.99972 time= 1.81624
Epoch: 0131 train_loss= nan train_acc= 0.99972 time= 1.74309
Epoch: 0132 train_loss= nan train_acc= 0.99972 time= 1.78192
Epoch: 0133 train_loss= nan train_acc= 0.99972 time= 1.79884
Epoch: 0134 train_loss= nan train_acc= 0.99972 time= 1.78457
Epoch: 0135 train_loss= nan train_acc= 0.99972 time= 1.73717
Epoch: 0136 train_loss= nan train_acc= 0.99972 time= 1.80290
Epoch: 0137 train_loss= nan train_acc= 0.99972 time= 1.77169
Epoch: 0138 train_loss= nan train_acc= 0.99972 time= 1.72641
Epoch: 0139 train_loss= nan train_acc= 0.99972 time= 1.75002
Epoch: 0140 train_loss= nan train_acc= 0.99972 time= 1.72154
Epoch: 0141 train_loss= nan train_acc= 0.99972 time= 1.74192
Epoch: 0142 train_loss= nan train_acc= 0.99972 time= 1.73336
Epoch: 0143 train_loss= nan train_acc= 0.99972 time= 1.79296
Epoch: 0144 train_loss= nan train_acc= 0.99972 time= 1.73945
Epoch: 0145 train_loss= nan train_acc= 0.99972 time= 1.75992
Epoch: 0146 train_loss= nan train_acc= 0.99972 time= 1.79481
Epoch: 0147 train_loss= nan train_acc= 0.99972 time= 1.79287
Epoch: 0148 train_loss= nan train_acc= 0.99972 time= 1.76446
Epoch: 0149 train_loss= nan train_acc= 0.99972 time= 1.72002
Epoch: 0150 train_loss= nan train_acc= 0.99972 time= 1.74549
Epoch: 0151 train_loss= nan train_acc= 0.99972 time= 1.74136
Epoch: 0152 train_loss= nan train_acc= 0.99972 time= 1.77757
Epoch: 0153 train_loss= nan train_acc= 0.99972 time= 1.74166
Epoch: 0154 train_loss= nan train_acc= 0.99972 time= 1.78937
Epoch: 0155 train_loss= nan train_acc= 0.99972 time= 1.73074
Epoch: 0156 train_loss= nan train_acc= 0.99972 time= 1.76501
Epoch: 0157 train_loss= nan train_acc= 0.99972 time= 1.80491
Epoch: 0158 train_loss= nan train_acc= 0.99972 time= 1.80176
Epoch: 0159 train_loss= nan train_acc= 0.99972 time= 1.77608
Epoch: 0160 train_loss= nan train_acc= 0.99972 time= 1.76117
Epoch: 0161 train_loss= nan train_acc= 0.99972 time= 1.77627
Epoch: 0162 train_loss= nan train_acc= 0.99972 time= 1.72023
Epoch: 0163 train_loss= nan train_acc= 0.99972 time= 1.76623
Epoch: 0164 train_loss= nan train_acc= 0.99972 time= 1.77103
Epoch: 0165 train_loss= nan train_acc= 0.99972 time= 1.77556
Epoch: 0166 train_loss= nan train_acc= 0.99972 time= 1.79820
Epoch: 0167 train_loss= nan train_acc= 0.99972 time= 1.73872
Epoch: 0168 train_loss= nan train_acc= 0.99972 time= 1.78198
Epoch: 0169 train_loss= nan train_acc= 0.99972 time= 1.71944
Epoch: 0170 train_loss= nan train_acc= 0.99972 time= 1.79580
Epoch: 0171 train_loss= nan train_acc= 0.99972 time= 1.76062
Epoch: 0172 train_loss= nan train_acc= 0.99972 time= 1.80948
Epoch: 0173 train_loss= nan train_acc= 0.99972 time= 1.80510
Epoch: 0174 train_loss= nan train_acc= 0.99972 time= 1.73217
Epoch: 0175 train_loss= nan train_acc= 0.99972 time= 1.78344
Epoch: 0176 train_loss= nan train_acc= 0.99972 time= 1.79194
Epoch: 0177 train_loss= nan train_acc= 0.99972 time= 1.77267
Epoch: 0178 train_loss= nan train_acc= 0.99972 time= 1.78960
Epoch: 0179 train_loss= nan train_acc= 0.99972 time= 1.76982
Epoch: 0180 train_loss= nan train_acc= 0.99972 time= 1.72333
Epoch: 0181 train_loss= nan train_acc= 0.99972 time= 1.79866
Epoch: 0182 train_loss= nan train_acc= 0.99972 time= 1.84717
Epoch: 0183 train_loss= nan train_acc= 0.99972 time= 1.78563
Epoch: 0184 train_loss= nan train_acc= 0.99972 time= 1.73928
Epoch: 0185 train_loss= nan train_acc= 0.99972 time= 1.79867
Epoch: 0186 train_loss= nan train_acc= 0.99972 time= 1.77602
Epoch: 0187 train_loss= nan train_acc= 0.99972 time= 1.72524
Epoch: 0188 train_loss= nan train_acc= 0.99972 time= 1.80162
Epoch: 0189 train_loss= nan train_acc= 0.99972 time= 1.75482
Epoch: 0190 train_loss= nan train_acc= 0.99972 time= 1.78364
Epoch: 0191 train_loss= nan train_acc= 0.99972 time= 1.81106
Epoch: 0192 train_loss= nan train_acc= 0.99972 time= 1.74794
Epoch: 0193 train_loss= nan train_acc= 0.99972 time= 1.81327
Epoch: 0194 train_loss= nan train_acc= 0.99972 time= 1.79453
Epoch: 0195 train_loss= nan train_acc= 0.99972 time= 1.80669
Epoch: 0196 train_loss= nan train_acc= 0.99972 time= 1.75146
Epoch: 0197 train_loss= nan train_acc= 0.99972 time= 1.75312
Epoch: 0198 train_loss= nan train_acc= 0.99972 time= 1.77584
Epoch: 0199 train_loss= nan train_acc= 0.99972 time= 1.76778
Epoch: 0200 train_loss= nan train_acc= 0.99972 time= 1.75237
Epoch: 0201 train_loss= nan train_acc= 0.99972 time= 1.80228
Epoch: 0202 train_loss= nan train_acc= 0.99972 time= 1.82325
Epoch: 0203 train_loss= nan train_acc= 0.99972 time= 1.75220
Epoch: 0204 train_loss= nan train_acc= 0.99972 time= 1.72837
Epoch: 0205 train_loss= nan train_acc= 0.99972 time= 1.81298
Epoch: 0206 train_loss= nan train_acc= 0.99972 time= 1.79271
Epoch: 0207 train_loss= nan train_acc= 0.99972 time= 1.75151
Epoch: 0208 train_loss= nan train_acc= 0.99972 time= 1.71901
Epoch: 0209 train_loss= nan train_acc= 0.99972 time= 1.77082
Epoch: 0210 train_loss= nan train_acc= 0.99972 time= 1.81370
Epoch: 0211 train_loss= nan train_acc= 0.99972 time= 1.76292
Epoch: 0212 train_loss= nan train_acc= 0.99972 time= 1.78359
Epoch: 0213 train_loss= nan train_acc= 0.99972 time= 1.76137
Epoch: 0214 train_loss= nan train_acc= 0.99972 time= 1.77220
Epoch: 0215 train_loss= nan train_acc= 0.99972 time= 1.76622
Epoch: 0216 train_loss= nan train_acc= 0.99972 time= 1.78564
Epoch: 0217 train_loss= nan train_acc= 0.99972 time= 1.77788
Epoch: 0218 train_loss= nan train_acc= 0.99972 time= 1.73883
Epoch: 0219 train_loss= nan train_acc= 0.99972 time= 1.76623
Epoch: 0220 train_loss= nan train_acc= 0.99972 time= 1.80698
Epoch: 0221 train_loss= nan train_acc= 0.99972 time= 1.77980
Epoch: 0222 train_loss= nan train_acc= 0.99972 time= 1.75226
Epoch: 0223 train_loss= nan train_acc= 0.99972 time= 1.75975
Epoch: 0224 train_loss= nan train_acc= 0.99972 time= 1.80093
Epoch: 0225 train_loss= nan train_acc= 0.99972 time= 1.79002
Epoch: 0226 train_loss= nan train_acc= 0.99972 time= 1.78287
Epoch: 0227 train_loss= nan train_acc= 0.99972 time= 1.78840
Epoch: 0228 train_loss= nan train_acc= 0.99972 time= 1.75477
Epoch: 0229 train_loss= nan train_acc= 0.99972 time= 1.77305
Epoch: 0230 train_loss= nan train_acc= 0.99972 time= 1.79983
Epoch: 0231 train_loss= nan train_acc= 0.99972 time= 1.78435
Epoch: 0232 train_loss= nan train_acc= 0.99972 time= 1.80204
Epoch: 0233 train_loss= nan train_acc= 0.99972 time= 1.80803
Epoch: 0234 train_loss= nan train_acc= 0.99972 time= 1.75555
Epoch: 0235 train_loss= nan train_acc= 0.99972 time= 1.77850
Epoch: 0236 train_loss= nan train_acc= 0.99972 time= 1.75336
Epoch: 0237 train_loss= nan train_acc= 0.99972 time= 1.78677
Epoch: 0238 train_loss= nan train_acc= 0.99972 time= 1.77438
Epoch: 0239 train_loss= nan train_acc= 0.99972 time= 1.77601
Epoch: 0240 train_loss= nan train_acc= 0.99972 time= 1.78410
Epoch: 0241 train_loss= nan train_acc= 0.99972 time= 1.75695
Epoch: 0242 train_loss= nan train_acc= 0.99972 time= 1.77195
Epoch: 0243 train_loss= nan train_acc= 0.99972 time= 1.80459
Epoch: 0244 train_loss= nan train_acc= 0.99972 time= 1.76855
Epoch: 0245 train_loss= nan train_acc= 0.99972 time= 1.74756
Epoch: 0246 train_loss= nan train_acc= 0.99972 time= 1.77919
Epoch: 0247 train_loss= nan train_acc= 0.99972 time= 1.72476
Epoch: 0248 train_loss= nan train_acc= 0.99972 time= 1.73527
Epoch: 0249 train_loss= nan train_acc= 0.99972 time= 1.76423
Epoch: 0250 train_loss= nan train_acc= 0.99972 time= 1.76581
Epoch: 0251 train_loss= nan train_acc= 0.99972 time= 1.77572
Epoch: 0252 train_loss= nan train_acc= 0.99972 time= 1.75869
Epoch: 0253 train_loss= nan train_acc= 0.99972 time= 1.75007
Epoch: 0254 train_loss= nan train_acc= 0.99972 time= 1.80593
Epoch: 0255 train_loss= nan train_acc= 0.99972 time= 1.79182
Epoch: 0256 train_loss= nan train_acc= 0.99972 time= 1.73124
Epoch: 0257 train_loss= nan train_acc= 0.99972 time= 1.75661
Epoch: 0258 train_loss= nan train_acc= 0.99972 time= 1.74585
Epoch: 0259 train_loss= nan train_acc= 0.99972 time= 1.73257
Epoch: 0260 train_loss= nan train_acc= 0.99972 time= 1.78063
Epoch: 0261 train_loss= nan train_acc= 0.99972 time= 1.74339
Epoch: 0262 train_loss= nan train_acc= 0.99972 time= 1.81622
Epoch: 0263 train_loss= nan train_acc= 0.99972 time= 1.76160
Epoch: 0264 train_loss= nan train_acc= 0.99972 time= 1.82865
Epoch: 0265 train_loss= nan train_acc= 0.99972 time= 1.75646
Epoch: 0266 train_loss= nan train_acc= 0.99972 time= 1.77916
Epoch: 0267 train_loss= nan train_acc= 0.99972 time= 1.84170
Epoch: 0268 train_loss= nan train_acc= 0.99972 time= 1.77651
Epoch: 0269 train_loss= nan train_acc= 0.99972 time= 1.81618
Epoch: 0270 train_loss= nan train_acc= 0.99972 time= 1.74121
Epoch: 0271 train_loss= nan train_acc= 0.99972 time= 1.81112
Epoch: 0272 train_loss= nan train_acc= 0.99972 time= 1.73002
Epoch: 0273 train_loss= nan train_acc= 0.99972 time= 1.75401
Epoch: 0274 train_loss= nan train_acc= 0.99972 time= 1.79199
Epoch: 0275 train_loss= nan train_acc= 0.99972 time= 1.75591
Epoch: 0276 train_loss= nan train_acc= 0.99972 time= 1.79801
Epoch: 0277 train_loss= nan train_acc= 0.99972 time= 1.79032
Epoch: 0278 train_loss= nan train_acc= 0.99972 time= 1.76272
Epoch: 0279 train_loss= nan train_acc= 0.99972 time= 1.77598
Epoch: 0280 train_loss= nan train_acc= 0.99972 time= 1.75603
Epoch: 0281 train_loss= nan train_acc= 0.99972 time= 1.77316
Epoch: 0282 train_loss= nan train_acc= 0.99972 time= 1.78107
Epoch: 0283 train_loss= nan train_acc= 0.99972 time= 1.79905
Epoch: 0284 train_loss= nan train_acc= 0.99972 time= 1.75090
Epoch: 0285 train_loss= nan train_acc= 0.99972 time= 1.76937
Epoch: 0286 train_loss= nan train_acc= 0.99972 time= 1.78678
Epoch: 0287 train_loss= nan train_acc= 0.99972 time= 1.79623
Epoch: 0288 train_loss= nan train_acc= 0.99972 time= 1.80857
Epoch: 0289 train_loss= nan train_acc= 0.99972 time= 1.78837
Epoch: 0290 train_loss= nan train_acc= 0.99972 time= 1.76283
Epoch: 0291 train_loss= nan train_acc= 0.99972 time= 1.79010
Epoch: 0292 train_loss= nan train_acc= 0.99972 time= 1.76206
Epoch: 0293 train_loss= nan train_acc= 0.99972 time= 1.77249
Epoch: 0294 train_loss= nan train_acc= 0.99972 time= 1.75472
Epoch: 0295 train_loss= nan train_acc= 0.99972 time= 1.78943
Epoch: 0296 train_loss= nan train_acc= 0.99972 time= 1.73144
Epoch: 0297 train_loss= nan train_acc= 0.99972 time= 1.81090
Epoch: 0298 train_loss= nan train_acc= 0.99972 time= 1.80792
Epoch: 0299 train_loss= nan train_acc= 0.99972 time= 1.78491
Epoch: 0300 train_loss= nan train_acc= 0.99972 time= 1.77998
Optimization Finished!
Model: [nan,nan]
10908
walk_path ./baselines/FairWalk/tmp/10908_0_6443_0.walk
training done
Model: [1.6161103569372826,3.212230894594339e-06]
10958
walk_path ./baselines/FairWalk/tmp/10958_1_369_0.walk
training done
Model: [1.6160829316542407,3.3921347807860924e-06]
10886
walk_path ./baselines/FairWalk/tmp/10886_2_7714_0.walk
training done
Model: [1.6157922015941235,3.4407096357626065e-06]
10892
walk_path ./baselines/FairWalk/tmp/10892_3_2218_0.walk
training done
Model: [1.6160265361097825,3.2224477811570406e-06]
10913
walk_path ./baselines/FairWalk/tmp/10913_4_1684_0.walk
training done
Model: [1.6160198037560771,3.1806809628682313e-06]
